\section{Future Directions}
\label{sec:future_directions}

OpenMP has come far in its first twenty years, but that doesn't mean it's done.
Now and into the future OpenMP continues to innovate, and this section will
describe some of the new capabilities that are in the works for upcoming
versions of the specification.

\subsection{Device Extensions}
\label{sub:device_extensions}

While OpenMP introduced support for offloading to target devices in version 4.0
and subsequently expanded on the support significantly in 4.5, the space is
changing quickly and many more extensions and refinements are in the works for
5.0.  Quite possibly the biggest shifts have been in how memory is managed,
where more and more devices support a unified cache-coherent memory space
while others continue to require explicit memory management to function.
Bridging this gap to allow for both cases has become critical for portability
and for productivity.  Two features are in the works, each to address
programmability on one of the two types of systems, each without preventing use
of the other.

First, in order to make use of coherent memory between the host and a target
device, the user needs a way to assert to the compiler that they expect that
behavior, and that they only intend to run on hardware that can provide it.  To
address this need, OpenMP is going to include a new directive called
\texttt{requires} that allows OpenMP, or a vendor, to specify a set of rules for
a given requirement and users to specify that their code will only function
correctly if those requirements are met.  This way, conforming subsets of the
OpenMP specification can be defined, and the first one will be to support
systems that do not require memory to be explicitly mapped into a data
environment for target devices.  For example, the code in
Figure~\ref{fig:unified} is only valid for systems with a unified view of
memory, and is non-conforming in OpenMP up to 4.5, but with the requirement it
becomes a conforming program for implementations that can meet the requirement.

\begin{figure}
\begin{minted}{c}
#pragma omp requires unified_shared_memory
void foo() {
  struct list {void *data; struct list *next;};
  struct list *l = make_linked_list();
#pragma omp target
  {
    struct list *cur;
    while(cur) {
      do_something_with_data(cur->data);
      cur = cur->next;
    }
  }
}
\end{minted}
\caption{A requires directive asserting the need for a unified memory space}
\label{fig:unified}
\end{figure}

The second feature addresses handling complex data structures, like the linked
list in Figure~\ref{fig:unified}, on systems that don't or can't provide
coherent unified memory.  As of OpenMP 4.5, the only way to make such structures
work is to map each individual piece of the structure and to fix up pointers as
necessary on the device either with explicit assignments or by using mapping
constructs to attach them.  This process is verbose, complex and error prone for
large and complex structures, and to make matters worse it mas to be replicated
throughout the code to have the desired effect in some codes.  To alleviate this
burden, we're developing a way for users to declare their own mappers, which are
descriptors for how to map a variable and all of its children or associated
data.  The \texttt{declare mapper} directive will allow existing map clauses
used to map the members of structures and attach pointers to be collected in
one place and re-used wherever they're needed.  Beyond that, each phase of the
mapping process will be replaceable with user-defined expressions or functions
written in the base language to allow for structures too complex to be handled
with existing constructs to be handled by serialization and deserialization as
they might be for transmission over a network.


\subsection{Enabling Language-Level Outlining}
\label{sub:enabling_language_level_outlining}

As we discussed in Section~\ref{sub:outlining} outlining, or extraction of code
into functions by the compiler, is one of the core mechanisms used by OpenMP.
Some languages provide a mechanism for this directly in the form of closures or,
at least in the case of C++, lambdas.  The attraction of these constructs,
especially for the writers of libraries and parallel frameworks, comes from the
fact that they allow abstract patterns and behaviors to be implemented once
while giving users the ability to pass an arbitrarily complex bit of code and
associated data into the pattern to be executed.  Much of OpenMP could be
implemented as a library in modern C++, if with less guarantees to the compiler
and less flexibility given to the implementer, with the use of lambdas.
Frameworks like Kokkos~\cite{kokkos} and RAJA~\cite{raja} exploit this mechanism
to create flexible looping constructs, like the one in Figure~\ref{fig:raja},
that can be compiled for host devices, targets or any number of parallel
backends depending on compile time arguments.

\begin{figure}
\begin{minted}{c}
RAJA::forall<omp_parallel_for>(
    RAJA::range(0,N),
    [=](int a) {
      // loop body
});
\end{minted}
\caption{A C++ lambda supplying the loop body for a parallel for loop}
\label{fig:raja}
\end{figure}
   
Up to this point OpenMP implementations have commonly used outlining as a way to
implement the requirements of the specification, but the resulting functions
have never been exposed to the user as something they could rely on or call.
Given how useful lambdas have proven however, it may be time to change that.
We're investigating the possibility of extending the \texttt{task} directive to
make it possible to create a form of "callable task" or OpenMP closure object
that would be portable across C, C++ and Fortran.  The advantage of this would
be a major reduction in the amount of work it takes to make an arbitrary
callable object with state in C and Fortran, and allow libraries to be
implemented that would provide functionality like that of Kokkos and RAJA to all
three languages.  Challenges remain however, particularly how to integrate the
functionality well into OpenMP and how to make it as efficient as possible at
runtime.  The simple solution of generating a structure, or derived type, and
a function pointer is quite portable and would integrate well with established
libraries, but is unlikely to optimize well for constructs that will be called
many times.  Despite the challenges, giving users control of outlining could be
a major step forward for OpenMP.

\subsection{Iterators}
\label{sub:iterators}

One emerging need in the usage of OpenMP is the ability to increase the dynamic
nature of OpenMP description (its effects are mostly dynamic). For example, the
depend clause allows to express that a task or a target construct has
a dependence on different elements of an array. You can express this today by
writing multiple clauses which can easily become tedious and error prone if it
is more than a few clauses. Furthermore, if the number of clauses would depend
on a runtime decision, like if this is a corner cell or an inner cell, it would
be impossible to describe in a single directive. The same reasoning could be
applied to the map clause in target directives where you would like to describe
different elements of an array.
   
To overcome this lack of expressiveness OpenMP iterators are being developed.
They allow to iterate through a range of values and evaluate the same clause
multiple times with each value in the range. Furthermore, this range can be
described at runtime which allows to vary both the number clauses and their
content for a given directive. Figure~\ref{fig:iterators} shows how the iterator
feature can be used to express a variable number of dependences on a \emph{task}
construct.

\begin{figure}
\begin{minted}{c}
void func( double *a, int N )
{
#pragma omp task depend(inout:a[i]:i=0:N)
   work(a);
}
\end{minted}
\caption{Example of task dependencies with iterators}
\label{fig:iterators}
\end{figure}
   
One could see this as first step towards providing OpenMP with metaprogramming
capabilities that would allow were possibly to construct the directives either
at compile time or runtime instead of only allowing them to be statically typed
by a programmer.
   

