\subsection{Tasking Extensions}
\label{sub:tasking}

%% BRONIS: We should  cover 4.0 and 4.5 tasking extensions
%% BRONIS: Specifically: Discuss task dependences, taskgroup and taskloop

%% STEPHEN: Introduce the problem with OpenMP 3.x

Directives to support asynchronous task parallelism were first introduced in OpenMP 3.0, and the initial design rationale for this capability is explained in an article by Ayguad\'{e} et al.~\cite{ayguade2009tpds}.  Along with task generation using the \texttt{task} construct, task synchronization is provided using the \texttt{taskwait} construct and barriers.  The \texttt{taskwait} construct specifies a wait on the completion of child tasks of the current task, and a barrier requires complete execution of all tasks in the current parallel region before any threads in the team are allowed to continue execution beyond the barrier.  In many instances, these simple synchronization mechanisms lack the expressiveness to fully expose all available application parallelism.  OpenMP 4 addresses such limitations with two additional synchronization mechanisms, task dependences and task groups.


%% SMATEO: this is a bit ugly, but it's the only way I know to do it :D
\begin{figure}

\newsavebox{\firstExample}
\newsavebox{\secondExample}

\begin{lrbox}{\firstExample}
\begin{minipage}{0.45\columnwidth}
\begin{minted}[fontsize=\small]{c}
void fun1(int *x) {
#pragma omp task
    (*x)++;

#pragma omp taskwait

#pragma omp task
    print(*x);
}
\end{minted}
\end{minipage}
\end{lrbox}

\begin{lrbox}{\secondExample}
\begin{minipage}{0.48\columnwidth}
\begin{minted}[fontsize=\small]{c}
void fun2(int *x) {
#pragma omp task \
  depend(inout: x[0])
    (*x)++;

#pragma omp task \
  depend(in: x[0])
    print(*x);
}
\end{minted}
\end{minipage}
\end{lrbox}



\subfloat[][OpenMP 3.0]{\usebox{\firstExample}}
~
~
~
~
\subfloat[][OpenMP 4.0]{\usebox{\secondExample}}

\centering{\subfloat{\includegraphics[width=0.5\columnwidth]{pics/intro_tasking_ex1_legend.png}}}
\addtocounter{subfigure}{-1}

\subfloat[][]{\includegraphics[width=0.45\columnwidth]{pics/intro_tasking_ex1_omp3.png}}
~
\subfloat[][]{\includegraphics[width=0.45\columnwidth]{pics/intro_tasking_ex1_omp4.png}}
\caption{Example of parallelization using task dependences.\label{fig:CodeTaskDeps}}
\end{figure}

%% STEPHEN: Explain task dependences (with example, space permitting)
%% STEPHEN: Use example of program with and without dependences, possibly Sergi's

%% STEPHEN: Sergi to provide performance results

%% STEPHEN: Discuss task group (example needed or not?)

Recall that all child tasks of the current task must compete at a \texttt{taskwait} construct.  The \texttt{taskgroup} construct allows the current task to wait on only subset of its child tasks, while other child tasks may continue executing beyond the synchronization point.  Additionally, the current task waits on all descendant tasks of the child tasks in the task group, a behavior may be termed deep synchronization.  Because child tasks of the current task can be excluded from a task group, those tasks could perform long-running background activities that proceed alongside successive computational kernels.

%% STEPHEN: Michael to discuss taskloop (with example, space permitting)

%% STEPHEN: Mention task priorities briefly?




% the subsubsection is just for my orientation and can be removed.
\subsubsection{Taskloop}
\label{sec:Taskloop}

Support for task-based loops, or \emph{taskloops} for short, is  an extension that was made in OpenMP 4.5 to ease using the tasking model with loop-based parallelism.
While it was always possible to manually cut a loop into chunks and assign them to OpenMP tasks, it was a cumbersome and error-prone code transformation process that had to be applied by the programmer.
The OpenMP~4.0 \code{taskloop} construct provides syntactic sugar to automatically transform a loop into a parallel loop using OpenMP task.

\begin{figure}
\begin{minted}{c}
void sapxy_tasks(float* a, float* b,
                 float s, size_t n)
{
  size_t i;
#pragma omp taskloop simd \
            num_tasks(NTASKS) \
            shared(a,b) firstprivate(s)
  for (i = 0; i < n; i++) {
    a[i] = a[i] * b[i] * s;
  }
}
\end{minted}
\caption{Example for using the \code{taskloop} construct.\label{fig:TaskloopExample}}
\end{figure}

Figure~\ref{fig:TaskloopExample} shows how to apply the \code{taskloop} construct to parallelize a \emph{saxpy} operation.
The \code{num\_tasks} clause is used to specify how many OpenMP tasks shall be created for the sapxy loop.
Alternatively, programmers can use the \code{grainsize} clause to inform the OpenMP implementation about the minimal number of loop iterations per task.
The \code{taskloop} construct is also available as a combined construct to use SIMD instructions for the tasks resulting from the loop.
