%% Created using Papers on Tue, 08 Jul 2014.
%% http://papersapp.com/papers/

%%papers etc. after this line
@inproceedings{Frangieh:2010ky,
author = {Frangieh, T and Chandrasekharan, A and Rajagopalan, S and Iskander, Y and Craven, S and Patterson, C},
title = {{PATIS:} Using Partial Configuration to Improve Static {FPGA} Design Productivity},
crossref = {ipdpsw},
year = {2010},
doi = {10.1109/IPDPSW.2010.5470755},
read = {Yes},
rating = {0},
date-added = {2011-04-24T01:26:56GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Reconfigurable hardware development and debugging tools aspire to provide software-like productivity. A major impediment, however, is the lack of a module linkage capability permitting hardware blocks to be compiled concurrently, limiting the effective use of multi-core and multiprocessor platforms. Although modular and incremental design flows can reuse the layouts of unmodified blocks, non-local changes to the logical hierarchy or physical layout, or addition of debug circuitry, generally force complete re-implementation. We describe the PATIS dynamic floorplanner, targeting development environments in which some circuit speed and area optimization may be sacrificed for improved implementation and debug turnaround. The floorplan consists of partial modules with structured physical interfaces observable through configuration readback rather than synthesized logic analysis circuitry, allowing module ports to be passively probed without disturbing the layout. Although PATIS supports incremental design, complete re-implementation is still rapid because the partial bitstream for each block is generated by independent and concurrent invocations of the standard Xilinx tools running on separate cores or hosts. A continuous background task proactively generates floorplan variants to accelerate global layout changes. The partial reconfiguration design flow is easier to automate in PATIS because run-time module swapping is not required, suggesting that partial reconfiguration may serve a useful role in large-scale static design.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5470755&queryText%3D%2810+1109+ipdpsw+2010+5470755%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Frangieh/PATIS_Using_partial_configuration_to_improve_static_FPGA_design_productivity_2010_Frangieh.pdf},
file = {{PATIS_Using_partial_configuration_to_improve_static_FPGA_design_productivity_2010_Frangieh.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Frangieh/PATIS_Using_partial_configuration_to_improve_static_FPGA_design_productivity_2010_Frangieh.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPSW.2010.5470755}}
}

@inproceedings{scogland2008ais,
author = {Scogland, Thomas R W and Balaji, Pavan and Feng, Wu{-chun} and Narayanaswamy, Ganesh},
title = {{Asymmetric Interactions in Symmetric Multi-Core Systems: Analysis, Enhancements and Evaluation}},
crossref = {supercomputing},
year = {2008},
doi = {10.1109/SC.2008.5219748},
read = {Yes},
rating = {0},
date-added = {2011-03-22T21:37:36GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Multi-core architectures have spurred the rapid growth in high-end computing systems. While the vast majority of such multi-core processors contain symmetric hardware components, their interaction with systems software, in particular the communication stack, results in a remarkable amount of asymmetry in the effective capability of the different cores. In this paper, we analyze such interactions and propose a novel management library called SyMMer (Systems Mapping Manager) that monitors these interactions and dynamically manages the mapping of processes on processor cores to transparently improve application performance. Together with a detailed description of the SyMMer library, we also present performance evaluation comparing SyMMer to a vanilla communication library using various micro-benchmarks as well as popular applications and scientific libraries. Experimental results demonstrate more than a two-fold improvement in communication time and 10-15\% improvement in overall application performance.},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5219748},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Scogland/Asymmetric_Interactions_in_Symmetric_Multi-Core_Systems_Analysis_Enhancements_and_Evaluation_2008_Scogland.pdf},
file = {{Asymmetric_Interactions_in_Symmetric_Multi-Core_Systems_Analysis_Enhancements_and_Evaluation_2008_Scogland.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Scogland/Asymmetric_Interactions_in_Symmetric_Multi-Core_Systems_Analysis_Enhancements_and_Evaluation_2008_Scogland.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SC.2008.5219748}}
}

@inproceedings{feng-hppac09-green500,
author = {Feng, Wu{-chun} and Scogland, Thomas R W},
title = {{The Green500 List: Year One}},
crossref = {hppac},
year = {2009},
publisher = { IEEE Computer Society},
address = {Rome, Italy},
month = may,
read = {Yes},
rating = {0},
date-added = {2011-03-22T21:37:36GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {The latest release of the Green500 List in November 2008 marked its one-year anniversary. As such, this paper aims to provide an analysis and retrospective examination of the Green500 List in order to understand how the list has evolved and what trends},
url = {http://portal.acm.org/citation.cfm?id=1586640.1587551&coll=DL&dl=GUIDE&CFID=14773409&CFTOKEN=25196381},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Feng/The_Green500_List_Year_One_2009_Feng.pdf},
file = {{The_Green500_List_Year_One_2009_Feng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Feng/The_Green500_List_Year_One_2009_Feng.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6D77B604-9E2D-46FC-BF72-5E7220384A11}}
}

@article{McCarthy:1960gu,
author = {McCarthy, John},
title = {{Recursive functions symbolic expressions and their computation by machine, Part I}},
journal = {Communications of the ACM},
year = {1960},
volume = {3},
number = {4},
pages = {184--195},
month = apr,
doi = {10.1145/367177.367199},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:40:02GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {1. Introduction A programming system called LISP (for lASt Processor) has been developed for the IBM 704 computer by the Artificial Intelligence group at MIT The system was designed to facilitate experiments with a proposed system called the Advice Taker, whereby a ...},
url = {http://portal.acm.org/citation.cfm?doid=367177.367199},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1960/McCarthy/Recursive_functions_symbolic_expressions_and_their_computation_by_machine_Part_I_1960_McCarthy.pdf},
file = {{Recursive_functions_symbolic_expressions_and_their_computation_by_machine_Part_I_1960_McCarthy.pdf:/Users/njustn/Dropbox/Papers2/Articles/1960/McCarthy/Recursive_functions_symbolic_expressions_and_their_computation_by_machine_Part_I_1960_McCarthy.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/367177.367199}}
}

@inproceedings{archuleta-ipdps09-datamining,
author = {Archuleta, Jeremy and Cao, Yong and Scogland, Thomas R W and Feng, Wu{-chun}},
title = {{Multi-dimensional Characterization of Temporal Data Mining on Graphics Processors}},
crossref = {ipdps},
year = {2009},
pages = {1--12},
keywords = {ipdps11-omp-co},
doi = {10.1109/IPDPS.2009.5161049},
read = {Yes},
rating = {0},
date-added = {2011-03-22T21:37:36GMT},
date-modified = {2014-07-05T18:23:49GMT},
abstract = {Through the algorithmic design patterns of data parallelism and task parallelism, the graphics processing unit (GPU) offers the potential to vastly accelerate discovery and innovation across a multitude of disciplines. For example, the exponential growth in data volume now presents an obstacle for high-throughput data mining in fields such as neuroscience and bioinformatics. As such, we present a characterization of a MapReduced-based data-mining application on a general-purpose GPU (GPGPU). Using neuroscience as the application vehicle, the results of our multi-dimensional performance evaluation show that a ldquoone-size-fits-allrdquo approach maps poorly across different GPGPU cards. Rather, a high-performance implementation on the GPGPU should factor in the 1) problem size, 2) type of GPU, 3) type of algorithm, and 4) data-access method when determining the type and level of parallelism. To guide the GPGPU programmer towards optimal performance within such a broad design space, we provide eight general performance characterizations of our data-mining application. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5161049&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_DOI%3A10.1109%2FIPDPS.2009.5161049%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Archuleta/Multi-dimensional_Characterization_of_Temporal_Data_Mining_on_Graphics_Processors_2009_Archuleta.pdf},
file = {{Multi-dimensional_Characterization_of_Temporal_Data_Mining_on_Graphics_Processors_2009_Archuleta.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Archuleta/Multi-dimensional_Characterization_of_Temporal_Data_Mining_on_Graphics_Processors_2009_Archuleta.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5161049}}
}

@article{berkelaar2003lp_solve,
author = {Berkelaar, Michel and Eikland, Kjell and Notebaert, Peter and {Others}},
title = {{lp\_solve: Open-Source (Mixed-Integer) Linear Programming System}},
journal = {Eindhoven U. of Technology},
year = {2004},
rating = {0},
date-added = {2014-07-05T18:42:19GMT},
date-modified = {2014-07-05T19:34:00GMT},
url = {http://lpsolve.sourceforge.net/},
uri = {\url{papers2://publication/uuid/1DC21752-C0FC-4E3E-9165-11A7516FC6B5}}
}

@webpage{peruse,
title = {{PERUSE}},
url = {http://www.mpi-peruse.org/},
publisher = {http://www.mpi-peruse.org/},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T20:40:44GMT},
uri = {\url{papers2://publication/uuid/5A57B7C9-0BAC-403D-AD01-4C6F27FD20B3}}
}

@inproceedings{Endo:2010gj,
author = {Endo, T and {Nukada}},
title = {{Linpack evaluation on a supercomputer with heterogeneous accelerators}},
crossref = {ipdps},
year = {2010},
pages = {1--8},
doi = {10.1109/IPDPS.2010.5470353},
read = {Yes},
rating = {0},
date-added = {2011-03-22T21:43:04GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {We report Linpack benchmark results on the TSUBAME supercomputer, a large scale heterogeneous system equipped with NVIDIA Tesla GPUs and ClearSpeed SIMD accelerators. With all of 10,480 Opteron cores, 640 Xeon cores, 648 ClearSpeed accelerators and 624 NVIDIA Tesla GPUs, we have achieved 87.01TFlops, which is the third record as a heterogeneous system in the world. This paper describes careful tuning and load balancing method required to achieve this performance. On the other hand, since the peak speed is 163 TFlops, the efficiency is 53\%, which is lower than other systems. This paper also analyses this gap from the aspect of system architecture.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5470353&queryText%3D%28linpack+evaluation+on+a+supercomputer+with+heterogeneous+accelerators%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Endo/Linpack_evaluation_on_a_supercomputer_with_heterogeneous_accelerators_2010_Endo.pdf},
file = {{Linpack_evaluation_on_a_supercomputer_with_heterogeneous_accelerators_2010_Endo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Endo/Linpack_evaluation_on_a_supercomputer_with_heterogeneous_accelerators_2010_Endo.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2010.5470353}}
}

@misc{mpip,
title = {{mpiP}},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://mpip.sourceforge.net},
uri = {\url{papers2://publication/uuid/DD5FB0EC-5CF3-4C5E-A453-D16389C465A0}}
}

@article{Spafford:vt,
author = {Spafford, K and Meredith, J and Vetter, J},
title = {{Two Algorithms for Sorting On Heterogeneous Clusters}},
journal = {lzy-s-prct.googlecode.com
},
read = {Yes},
rating = {0},
date-added = {2012-07-09T01:55:03GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {... Kyle Spafford , Jeremy Meredith, Jeffrey Vetter Future Technologies Group Oak Ridge National Laboratory spaffordkl ... evaluation has two primary aims: to compare the performance of the two sorting  algorithms and explore how they map to a heterogeneous  architecture . ... 
},
url = {http://lzy-s-prct.googlecode.com/files/pap481s2.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Spafford/Two_Algorithms_for_Sorting_On_Heterogeneous_Clusters__Spafford.pdf},
file = {{Two_Algorithms_for_Sorting_On_Heterogeneous_Clusters__Spafford.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Spafford/Two_Algorithms_for_Sorting_On_Heterogeneous_Clusters__Spafford.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/069F798C-3CC3-47A6-A56A-281B78F52EE2}}
}

@inproceedings{chai-ccgrid2007-multicore,
author = {Chai, L and Gao, Q and Panda, Dhabaleswar K},
title = {{Understanding the Impact of Multi-Core Architecture in Cluster Computing: A Case Study with Intel Dual-Core System}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2007},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T20:14:14GMT},
uri = {\url{papers2://publication/uuid/E93A75D9-6253-450C-8AC3-53BB99DD5105}}
}

@phdthesis{Cederman:2011vi,
author = {Cederman, Daniel},
title = {{Concurrent Algorithms and Data Structures for Many-Core Processors}},
school = {Chalmers University of Technology},
year = {2011},
publisher = {Chalmers University of Technology},
keywords = {Important},
isbn = {9173855030},
read = {Yes},
rating = {0},
date-added = {2013-07-21T15:22:50GMT},
date-modified = {2014-04-30T18:16:18GMT},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.2805&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2011/Cederman/Concurrent_Algorithms_and_Data_Structures_for_Many-Core_Processors_2011_Cederman.pdf},
file = {{Concurrent_Algorithms_and_Data_Structures_for_Many-Core_Processors_2011_Cederman.pdf:/Users/njustn/Dropbox/Papers2/Books/2011/Cederman/Concurrent_Algorithms_and_Data_Structures_for_Many-Core_Processors_2011_Cederman.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/76D07115-5ED3-4468-864E-301631B57E9C}}
}

@misc{myrinet,
title = {{Myrinet home page}},
author = {{Myricom}},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:19:08GMT},
url = {http://www.myri.com/},
uri = {\url{papers2://publication/uuid/7D7DE569-31A5-4A6A-AFEC-8B60C5F71D41}}
}

@inproceedings{DBLP:conf/ccgrid/2007,
title = {{Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGrid 2007), 14-17 May 2007, Rio de Janeiro, Brazil}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2007},
publisher = {IEEE Computer Society},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T20:14:14GMT},
uri = {\url{papers2://publication/uuid/F60AEFD0-189F-438D-A9E2-4A1C0C0D453B}}
}

@inproceedings{Humphrey:2012do,
author = {Humphrey, Alan and Meng, Qingyu and Berzins, Martin and Harman, Todd},
title = {{Radiation modeling using the Uintah heterogeneous CPU/GPU runtime system}},
booktitle = {the 1st Conference of the Extreme Science and Engineering Discovery Environment},
year = {2012},
pages = {1},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/2335755.2335791},
isbn = {9781450316026},
rating = {0},
date-added = {2013-07-21T15:24:29GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://dl.acm.org/citation.cfm?doid=2335755.2335791},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Humphrey/Radiation_modeling_using_the_Uintah_heterogeneous_CPUGPU_runtime_system_2012_Humphrey.pdf},
file = {{Radiation_modeling_using_the_Uintah_heterogeneous_CPUGPU_runtime_system_2012_Humphrey.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Humphrey/Radiation_modeling_using_the_Uintah_heterogeneous_CPUGPU_runtime_system_2012_Humphrey.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2335755.2335791}}
}

@article{Cederman:2013vf,
author = {Cederman, Daniel and Gidenstam, Anders and Ha, Phuong and Sundell, H{\aa}kan and Papatriantafilou, Marina and Tsigas, Philippas},
title = {{Lock-free Concurrent Data Structures}},
journal = {arXiv preprint arXiv:1302.2757},
year = {2013},
eprint = {10966012753019018213related:5Rsamn8aL5gJ},
eprinttype = {scholar},
rating = {0},
date-added = {2013-07-21T15:29:41GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://arxiv.org/abs/1302.2757},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Cederman/Lock-free_Concurrent_Data_Structures_2013_Cederman.pdf},
file = {{Lock-free_Concurrent_Data_Structures_2013_Cederman.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Cederman/Lock-free_Concurrent_Data_Structures_2013_Cederman.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A5CBA1FC-3F99-4880-9CD1-A4FC936DF01D}}
}

@inproceedings{Kogan:2011tr,
author = {Kogan, Alex and Petrank, Erez},
title = {{Wait-free queues with multiple enqueuers and dequeuers}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2011},
pages = {223--234},
publisher = {ACM},
isbn = {1450301193},
read = {Yes},
rating = {0},
date-added = {2013-07-21T15:30:12GMT},
date-modified = {2014-07-05T17:36:15GMT},
url = {http://dl.acm.org/citation.cfm?id=1941585},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Kogan/Wait-free_queues_with_multiple_enqueuers_and_dequeuers_2011_Kogan.pdf},
file = {{Wait-free_queues_with_multiple_enqueuers_and_dequeuers_2011_Kogan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Kogan/Wait-free_queues_with_multiple_enqueuers_and_dequeuers_2011_Kogan.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CC88C2A5-24E5-4C06-A758-6549C0CEE709}}
}

@article{Anonymous:cLpzRi2o,
title = {{Reducing GPU Offload Latency via Fine-Grained CPU-GPU Synchronization}},
year = {2013},
pages = {1--12},
month = jan,
rating = {0},
date-added = {2013-07-21T15:30:21GMT},
date-modified = {2014-07-05T18:32:04GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Unknown/Reducing_GPU_Offload_Latency_via_Fine-Grained_CPU-GPU_Synchronization_2013.pdf},
file = {{Reducing_GPU_Offload_Latency_via_Fine-Grained_CPU-GPU_Synchronization_2013.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Unknown/Reducing_GPU_Offload_Latency_via_Fine-Grained_CPU-GPU_Synchronization_2013.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/70BA7346-2DA8-4F02-9C1F-F317B1CBFFD3}}
}

@inproceedings{Li:2007en,
author = {Li, T and Baumberger, D and Koufaty, D A and Hahn, S},
title = {{Efficient Operating System Scheduling for Performance-Asymmetric Multi-Core Architectures}},
crossref = {supercomputing},
year = {2007},
pages = {1--11},
doi = {10.1145/1362622.1362694},
read = {Yes},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Recent research advocates asymmetric multi - core architectures , where cores in the same processor can have different performance . These architectures support single-threaded performance and multithreaded throughput at lower costs (eg, die size and power). However, they also ...},
url = {http://portal.acm.org/citation.cfm?id=1362694},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Li/Efficient_Operating_System_Scheduling_for_Performance-Asymmetric_Multi-Core_Architectures_2007_Li.pdf},
file = {{Efficient_Operating_System_Scheduling_for_Performance-Asymmetric_Multi-Core_Architectures_2007_Li.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Li/Efficient_Operating_System_Scheduling_for_Performance-Asymmetric_Multi-Core_Architectures_2007_Li.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1362622.1362694}}
}

@inproceedings{Kogan:2012vv,
author = {Kogan, Alex and Petrank, Erez},
title = {{A methodology for creating fast wait-free data structures}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2012},
publisher = {ACM},
month = feb,
doi = {10.1145/2145816.2145835},
read = {Yes},
rating = {0},
date-added = {2013-07-21T15:30:22GMT},
date-modified = {2014-07-05T17:36:15GMT},
abstract = {Lock-freedom is a progress guarantee that ensures overall program progress. Wait-freedom is a stronger progress guarantee that ensures the progress of each thread in the program. While many practical lock-free algorithms exist, wait-free algorithms are},
url = {http://portal.acm.org/citation.cfm?id=2145816.2145835&coll=DL&dl=ACM&CFID=235641177&CFTOKEN=70799411},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Kogan/A_methodology_for_creating_fast_wait-free_data_structures_2012_Kogan.pdf},
file = {{A_methodology_for_creating_fast_wait-free_data_structures_2012_Kogan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Kogan/A_methodology_for_creating_fast_wait-free_data_structures_2012_Kogan.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2145816.2145835}}
}

@article{Hong:2011ux,
author = {Hong, Sungpack and Oguntebi, Tayo and Olukotun, Kunle},
title = {{Efficient parallel graph exploration on multi-core CPU and GPU}},
year = {2011},
pages = {78--88},
publisher = {IEEE},
isbn = {1457717948},
rating = {0},
date-added = {2013-07-21T15:30:34GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6113790},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Hong/Efficient_parallel_graph_exploration_on_multi-core_CPU_and_GPU_2011_Hong.pdf},
file = {{Efficient_parallel_graph_exploration_on_multi-core_CPU_and_GPU_2011_Hong.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Hong/Efficient_parallel_graph_exploration_on_multi-core_CPU_and_GPU_2011_Hong.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/8033F622-D190-479F-8608-B7225EAC67D4}}
}

@inproceedings{dennis-rait,
author = {Dalessandro, D and Wyckoff, P and Montry, G},
title = {{Initial Performance Evaluation of the NetEffect 10 Gigabit iWARP Adapter}},
booktitle = {RAIT '06},
year = {2006},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:08:29GMT},
uri = {\url{papers2://publication/uuid/48630A2A-6184-4A16-B3A8-F961138CAF9D}}
}

@inproceedings{gepner:multicore,
author = {Gepner, P and Kowalik, M F},
title = {{Multi-Core Processors: New Way to Achieve High System Performance.}},
booktitle = {PARELEC},
year = {2006},
pages = {9--13},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:08:29GMT},
uri = {\url{papers2://publication/uuid/023C96F7-8E07-4393-BA13-EA27E3601D65}}
}

@article{anderson-retas2006-scheduling,
author = {Anderson, J H and Calandrino, J M and Devi, U C},
title = {{Real-Time Scheduling on Multicore Platforms}},
journal = {Proceedings of the 12th IEEE Real-Time and Embedded Technology and Applications Symposium},
year = {2006},
pages = {179--190},
doi = {10.1109/RTAS.2006.35},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:30GMT},
uri = {\url{papers2://publication/doi/10.1109/RTAS.2006.35}}
}

@article{hurwitz-feng,
author = {Hurwitz, J and Feng, Wu{-chun}},
title = {{Analyzing MPI performance over 10-Gigabit ethernet}},
journal = {J. Parallel Distrib. Comput.},
year = {2005},
pages = {1253--1260},
address = {Orlando, FL, USA},
publisher = {Academic Press, Inc.},
doi = {http://dx.doi.org/10.1016/j.jpdc.2005.04.011},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:31GMT},
uri = {\url{papers2://publication/doi/http://dx.doi.org/10.1016/j.jpdc.2005.04.011}}
}

@techreport{iwarp:ddp,
author = {Shah, H and Pinkerton, J and Recio, R and Culley, P},
title = {{Direct Data Placement Over Reliable Transports}},
year = {2005},
month = feb,
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:30:53GMT},
url = {http://www.ietf.org/internet-drafts/draft-ietf-rddp-ddp-04.txt},
uri = {\url{papers2://publication/uuid/F30563FC-2F23-4C1E-BA18-70DF6865A627}}
}

@misc{infiniband,
title = {{InfiniBand Trade Association}},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.infinibandta.org/},
uri = {\url{papers2://publication/uuid/3E2694B7-50F2-4D36-AC82-743B28472EDA}}
}

@misc{intel-terascale,
title = {{Intel Terascale Research}},
rating = {0},
date-added = {2014-07-05T19:08:29GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.intel.com/research/platform/terascale/teraflops.htm},
uri = {\url{papers2://publication/uuid/E50F6105-9772-4291-A161-614CCE64E485}}
}

@misc{mpi-forum,
title = {{Message Passing Interface Forum}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.mpi-forum.org},
uri = {\url{papers2://publication/uuid/E7442DEA-EF10-4DB0-A717-5DA042C61200}}
}

@article{Lauterbach:2009ur,
author = {Lauterbach, C and Garland, M and Sengupta, S},
title = {{Fast BVH construction on GPUs}},
journal = {Computer Graphics {\ldots}},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:23:30GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {We present two novel parallel algorithms for rapidly constructing bounding volume hierarchies on manycore GPUs . The first uses a linear ordering derived from spatial Morton codes to build hierarchies extremely quickly and with high parallel scalability. The second is a top-down ...},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01377.x/full},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Lauterbach/Fast_BVH_construction_on_GPUs_2009_Lauterbach.pdf},
file = {{Fast_BVH_construction_on_GPUs_2009_Lauterbach.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Lauterbach/Fast_BVH_construction_on_GPUs_2009_Lauterbach.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/B1CE2166-1792-4AE4-8713-D796C309DFB9}}
}

@misc{multicore-technology,
title = {{Multicore Technology}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:31:08GMT},
url = {http://www.dell.com/downloads/global/power/ps2q05-20050103-Fruehe.pdf},
uri = {\url{papers2://publication/uuid/209D9556-B855-4B12-8081-07B5654F9368}}
}

@article{Goecks:2010ea,
author = {Goecks, Jeremy and Nekrutenko, Anton and Taylor, James and Galaxy Team, The},
title = {{Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences}},
journal = {Genome Biology},
year = {2010},
volume = {11},
number = {8},
pages = {R86},
publisher = {BioMed Central Ltd},
doi = {10.1186/gb-2010-11-8-r86},
pmid = {20738864},
language = {English},
rating = {0},
date-added = {2013-12-02T20:15:46GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. Galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. Galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. Galaxy Pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis.},
url = {http://genomebiology.com/2010/11/8/R86},
uri = {\url{papers2://publication/doi/10.1186/gb-2010-11-8-r86}}
}

@article{gromacs,
author = {Berendsen, H J C and van der Spoel, D and van Drunen, R},
title = {{GROMACS: A Message-Passing Parallel Molecular Dynamics Implementation}},
journal = {Computer Physics Communications},
year = {1995},
volume = {91},
number = {1-3},
pages = {43--56},
month = sep,
doi = {10.1016/0010-4655(95)00042-E},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:29:26GMT},
url = {http://dx.doi.org/10.1016/0010-4655(95)00042-E},
uri = {\url{papers2://publication/doi/10.1016/0010-4655(95)00042-E}}
}

@inproceedings{nabeel-bicob13-genome-analysis-cloud,
author = {Mohamed, Nabeel M and Lin, Heshan and Feng, Wu{-chun}},
title = {{Accelerating Data-Intensive Genome Analysis in the Cloud}},
booktitle = {5th International Conference on Bioinformatics and Computational Biology (BICoB)},
year = {2013},
address = {Honolulu, Hawaii, USA},
month = mar,
rating = {0},
date-added = {2013-12-02T20:19:30GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/9C73D96E-8971-490A-986C-9CF831AAE9FF}}
}

@inproceedings{fedorova:usenix,
author = {Fedorova, A and Seltzer, M I and Small, C and Nussbaum, D},
title = {{Performance of Multithreaded Chip Multiprocessors and Implications for Operating System Design.}},
booktitle = {USENIX Annual Technical Conference, General Track},
year = {2005},
pages = {395--398},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:30GMT},
uri = {\url{papers2://publication/uuid/FB105F6A-AF35-48C5-AE79-3179258FF1A6}}
}

@inproceedings{Esmaeilzadeh:2011hx,
author = {Esmaeilzadeh, Hadi and Cao, Ting and Xi, Yang and Blackburn, Stephen M and McKinley, Kathryn S},
title = {{Looking back on the language and hardware revolutions: measured power, performance, and scaling}},
booktitle = {International Conference on Architectural Support for Programming Languages and Operating Systems},
year = {2011},
publisher = {ACM},
month = mar,
doi = {10.1145/1950365.1950402},
rating = {0},
date-added = {2012-03-26T14:03:15GMT},
date-modified = {2014-07-05T20:27:05GMT},
abstract = {This paper reports and analyzes measured chip power and performance on five process technology generations executing 61 diverse benchmarks with a rigorous methodology. We measure representative Intel IA32 processors with technologies ranging from 130nm},
url = {http://portal.acm.org/citation.cfm?id=1950365.1950402&coll=DL&dl=ACM&CFID=93667862&CFTOKEN=16735740},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Esmaeilzadeh/Looking_back_on_the_language_and_hardware_revolutions_measured_power_performance_and_scaling_2011_Esmaeilzadeh.pdf},
file = {{Looking_back_on_the_language_and_hardware_revolutions_measured_power_performance_and_scaling_2011_Esmaeilzadeh.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Esmaeilzadeh/Looking_back_on_the_language_and_hardware_revolutions_measured_power_performance_and_scaling_2011_Esmaeilzadeh.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1950365.1950402}}
}

@article{Sadedin:2012wd,
author = {Sadedin, S P and Pope, B and Oshlack, A},
title = {{Bpipe: a tool for running and managing bioinformatics pipelines}},
journal = {Bioinformatics},
year = {2012},
rating = {0},
date-added = {2013-12-02T20:21:05GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Summary: Bpipe is a simple, dedicated programming language for defining and executing bioinformatics pipelines . It specializes in enabling users to turn existing pipelines based on shell scripts or command line tools into highly flexible, adaptable and maintainable ... 
},
url = {http://bioinformatics.oxfordjournals.org/content/28/11/1525.short},
uri = {\url{papers2://publication/uuid/8785A44C-9E77-48C0-AD2B-26F0F4E21E0F}}
}

@article{FFTW05,
author = {Frigo, M and Johnson, S G},
title = {{The Design and Implementation of FFTW3}},
journal = {Proceedings of the IEEE},
year = {2005},
volume = {93},
number = {2},
pages = {216--231},
annote = {special issue on "Program Generation, Optimization and Platform Adaptation"},
read = {Yes},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T20:29:22GMT},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=1386650&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1386650},
uri = {\url{papers2://publication/uuid/48139D90-5E92-48A0-8094-966CFDCF6329}}
}

@techreport{fedorova-techreport-cache-aware,
author = {Fedorova, A and Seltzer, M and Smith, M D},
title = {{Cache-Fair Thread Scheduling for Multicore Processors}},
year = {2006},
number = {TR-17-06},
month = oct,
publisher = {Division of Engineering and Applied Sciences, Harvard University},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T20:21:44GMT},
uri = {\url{papers2://publication/uuid/AF5CCD8B-BBEC-4749-9305-180800BAC6AC}}
}

@misc{intel-quadcore,
title = {{Intel Core 2 Extreme quad-core processor}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.intel.com/products/processor/core2xe/qc\_prod\_brief.pdf},
uri = {\url{papers2://publication/uuid/6F268E89-5095-415D-B9DD-BB438E6BE318}}
}

@misc{mpe,
title = {{MPE : MPI Parallel Environment}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www-unix.mcs.anl.gov/perfvis/download/index.htm},
uri = {\url{papers2://publication/uuid/D43D6BBC-F9AB-4496-8EB3-DD39CD4364C2}}
}

@inproceedings{Fatica:2009vu,
author = {Fatica, M},
title = {{Accelerating linpack with CUDA on heterogenous clusters}},
booktitle = {Annual Workshop on General Purpose Processing with Graphics Processing Units},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-03-22T21:46:46GMT},
date-modified = {2014-07-05T17:33:36GMT},
abstract = {1. INTRODUCTION The Linpack benchmark is very popular in the HPC space, because it is used as a performance measure for ranking supercomputers in the TOP500 list of the world's fastest computers [1]. The Top 500 list was created in 1993 and it is updated twice a year at the ...},
url = {http://portal.acm.org/citation.cfm?id=1513901},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Fatica/Accelerating_linpack_with_CUDA_on_heterogenous_clusters_2009_Fatica.pdf},
file = {{Accelerating_linpack_with_CUDA_on_heterogenous_clusters_2009_Fatica.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Fatica/Accelerating_linpack_with_CUDA_on_heterogenous_clusters_2009_Fatica.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2628F8A8-2289-4D16-A424-EA6372735108}}
}

@article{Jablin:2012ta,
author = {Jablin, T.B. and Jablin, J.A. and Prabhu, P. and Liu, F. and August, David I},
title = {{Dynamically Managed Data for CPU-GPU Architectures}},
journal = {Proceedings of the 2012 International Symposium on Code Generation and Optimization (CGO)},
year = {2012},
rating = {0},
date-added = {2012-03-27T20:09:11GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://liberty.princeton.edu/Publications/cgo12_dymand.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Jablin/Dynamically_Managed_Data_for_CPU-GPU_Architectures_2012_Jablin.pdf},
file = {{Dynamically_Managed_Data_for_CPU-GPU_Architectures_2012_Jablin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Jablin/Dynamically_Managed_Data_for_CPU-GPU_Architectures_2012_Jablin.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/89783F9A-4DE8-4477-B121-721618488D67}}
}

@inproceedings{tz-queue,
author = {Tsigas, Philippas and Zhang, Yi},
title = {{A simple, fast and scalable non-blocking concurrent FIFO queue for shared memory multiprocessor systems}},
booktitle = {ACM Symposium on Parallelism in Algorithms and Architectures},
year = {2001},
publisher = {ACM},
month = jul,
doi = {10.1145/378580.378611},
read = {Yes},
rating = {0},
date-added = {2013-02-10T18:02:02GMT},
date-modified = {2014-07-05T17:45:25GMT},
abstract = {A non-blocking FIFO queue algorithm for multiprocessor shared memory systems is presented in this paper. The algorithm is very simple, fast and scales very well in both symmetric and non-symmetric multiprocessor shared memory systems. Experiments on},
url = {http://portal.acm.org/citation.cfm?id=378580.378611&coll=DL&dl=ACM&CFID=235641177&CFTOKEN=70799411},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2001/Tsigas/A_simple_fast_and_scalable_non-blocking_concurrent_FIFO_queue_for_shared_memory_multiprocessor_systems_2001_Tsigas.pdf},
file = {{A_simple_fast_and_scalable_non-blocking_concurrent_FIFO_queue_for_shared_memory_multiprocessor_systems_2001_Tsigas.pdf:/Users/njustn/Dropbox/Papers2/Articles/2001/Tsigas/A_simple_fast_and_scalable_non-blocking_concurrent_FIFO_queue_for_shared_memory_multiprocessor_systems_2001_Tsigas.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/378580.378611}}
}

@inproceedings{Cantanzaro:koi6LUiG,
author = {Cantanzaro, Bryan and Keller, Alexander and Garland, Michael},
title = {{A Decomposition for In-place Array Transposition}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
rating = {0},
date-added = {2013-12-19T20:40:39GMT},
date-modified = {2014-07-05T17:36:15GMT},
url = {https://research.nvidia.com/publication/decomposition-place-array-transposition},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Cantanzaro/A_Decomposition_for_In-place_Array_Transposition__Cantanzaro.pdf},
file = {{A_Decomposition_for_In-place_Array_Transposition__Cantanzaro.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Cantanzaro/A_Decomposition_for_In-place_Array_Transposition__Cantanzaro.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/9288BA2D-4886-44EE-9F5F-CCCCF52CB2A0}}
}

@inproceedings{anderson:rtss,
author = {Anderson, J H and Calandrino, J M},
title = {{Parallel Real-Time Task Scheduling on Multicore Platforms}},
booktitle = {RTSS '06},
year = {2006},
pages = {89--100},
publisher = {IEEE Computer Society},
address = {Washington, DC, USA},
doi = {\url{http://dx.doi.org/10.1109/RTSS.2006.32}},
isbn = {0-7695-2761-2},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:31GMT}
}

@article{lammps-95a,
author = {Plimpton, S},
title = {{Fast Parallel Algorithms for Short-Range Molecular Dynamics}},
journal = {J. Comput. Phys.},
year = {1995},
volume = {117},
number = {1},
pages = {1--19},
address = {San Diego, CA, USA},
publisher = {Academic Press Professional, Inc.},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:31GMT},
uri = {\url{papers2://publication/uuid/2739553C-1251-4207-AAB6-C6C86BA37291}}
}

@techreport{iwarp:verbs,
author = {Hilland, J and Culley, P and Pinkerton, J and Recio, R},
title = {{RDMA Protocol Verbs Specification}},
year = {2003},
month = apr,
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:30GMT},
url = {http://www.rdmaconsortium.org/home/draft-hilland-iwarp-verbs-v1.0-RDMAC.pdf},
uri = {\url{papers2://publication/uuid/A00B269E-3BA1-4D89-AABC-8ED617EC5BE1}}
}

@misc{tilera-tile64,
title = {{Tilera TILE64 Processor Family}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:32:51GMT},
url = {http://www.tilera.com/pdf/ProBrief\_Tile64\_Web.pdf},
uri = {\url{papers2://publication/uuid/0F21CD2A-DBCF-447E-81B3-EE66A048B279}}
}

@misc{10ge-alliance,
title = {{10-Gigabit Ethernet Alliance}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.ethernetalliance.org/},
uri = {\url{papers2://publication/uuid/5FDA7815-6472-4462-A969-7A1C6083DF7C}}
}

@misc{ibm-cell,
title = {{IBM Cell processor}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.research.ibm.com/cell/},
uri = {\url{papers2://publication/uuid/E2C2E052-5164-44B5-9363-852D3D6F4FB3}}
}

@techreport{tcp-rfc,
author = {Postel, J},
title = {{Transmission Control Protocol}},
year = {1981},
month = sep,
annote = {DARPA Internet Program Protocol Specification},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:08:30GMT},
uri = {\url{papers2://publication/uuid/7682B352-95D8-41A1-AE86-309B9ADDD1AA}}
}

@misc{mpich2,
title = {{MPICH2: High Performance and Portable Message Passing}},
author = {Laboratory, Argonne National},
howpublished = {http://www.mcs.anl.gov/research/projects/mpich2},
publisher = {http://www.mcs.anl.gov/research/projects/mpich2},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T20:38:05GMT},
url = {http://www.mcs.anl.gov/research/projects/mpich2},
uri = {\url{papers2://publication/uuid/1AEF1432-9945-4DF0-8A44-815E23EC114A}}
}

@misc{lammps-site,
title = {{LAMMPS}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://lammps.sandia.gov/index.html},
uri = {\url{papers2://publication/uuid/F8F77C4A-47D1-4B26-88F7-7FB9AA7FCEEE}}
}

@misc{papi,
title = {{PAPI}},
howpublished = {http://icl.cs.utk.edu/papi/},
publisher = {http://icl.cs.utk.edu/papi/},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T21:16:40GMT},
url = {http://icl.cs.utk.edu/papi/},
uri = {\url{papers2://publication/uuid/46622CD9-F01C-43CC-AA01-AEB65F64EFCC}}
}

@article{Birrell:1983wu,
author = {Birrell, AD and Nelson, BJ},
title = {{Implementing remote procedure calls}},
journal = {ACM SIGOPS Operating Systems Review},
year = {1983},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:05:28GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {Remote procedure calls ( RpC ) are a useful paradigm for providing communication across a network between programs written in a high level language. This paper describes a package, written as part of the Cedar project, providing a remote procedure call facility. The paper ...},
url = {http://doi.ieeecomputersociety.org/10.1145/800217.806609},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1983/Birrell/Implementing_remote_procedure_calls_1983_Birrell.pdf},
file = {{Implementing_remote_procedure_calls_1983_Birrell.pdf:/Users/njustn/Dropbox/Papers2/Articles/1983/Birrell/Implementing_remote_procedure_calls_1983_Birrell.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/EB540395-DD1C-4F7E-94CB-1526E1339215}}
}

@misc{amd-quadcore,
title = {{AMD Quad-core Opteron processor}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://multicore.amd.com/us-en/quadcore/},
uri = {\url{papers2://publication/uuid/8339C85E-8505-49AF-B9DD-6E0C8758D55C}}
}

@inproceedings{Narayanaswamy:2007br,
author = {Narayanaswamy, Ganesh and Balaji, Pavan and Feng, Wu{-chun}},
title = {{An Analysis of 10-Gigabit Ethernet Protocol Stacks in Multicore Environments}},
booktitle = {15th International Symposium on High-Performance Interconnects (HotI 2007)},
year = {2007},
pages = {109--116},
organization = {IEEE Computer Society Washington, DC, USA},
address = {Palo Alto, California},
month = aug,
affiliation = {IEEE Computer Society Washington, DC, USA},
doi = {10.1109/HOTI.2007.14},
read = {Yes},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:10:31GMT},
abstract = {This paper analyzes the interactions between the protocol stack (TCP/IP or iWARP over 10-Gigabit Ethernet) and its multicore environment. Specifically, for host-based protocols such as TCP/IP, we notice that a significant amount of processing is statically assigned to a single core, resulting in an imbalance of load on the different cores of the system and adversely impacting the performance of many applications. For host-offloaded protocols such as iWARP, on the other hand, the portions of the communication stack that are performed on the host, such as buffering of messages and memory copies, are closely tied with the associated process, and hence do not create such load imbalances. Thus, in this paper, we demonstrate that by intelligently mapping different processes of an application to specific cores, the imbalance created by the TCP/IP protocol stack can be largely countered and application performance significantly improved. At the same time, since the load is a better balanced in host-offloaded protocols such as iWARP, such mapping does not adversely affect their performance, thus keeping the mapping generic enough to be used with multiple protocol stacks.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=4296814&queryText%3D%28an+analysis+of+10+gigabit+ethernet+protocol+stacks+in+multicore+environments%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Narayanaswamy/An_Analysis_of_10-Gigabit_Ethernet_Protocol_Stacks_in_Multicore_Environments_2007_Narayanaswamy.pdf},
file = {{An_Analysis_of_10-Gigabit_Ethernet_Protocol_Stacks_in_Multicore_Environments_2007_Narayanaswamy.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Narayanaswamy/An_Analysis_of_10-Gigabit_Ethernet_Protocol_Stacks_in_Multicore_Environments_2007_Narayanaswamy.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/HOTI.2007.14}}
}

@misc{rdmac,
title = {{RDMA Consortium}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.rdmaconsortium.org},
uri = {\url{papers2://publication/uuid/536540B7-4F80-4551-8CC8-D3516D9C2029}}
}

@misc{sun-niagara,
title = {{Sun Niagara}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.sun.com/processors/UltraSPARC-T1/},
uri = {\url{papers2://publication/uuid/E39EE177-3141-43AC-86CE-3596BF8DE58D}}
}

@techreport{iwarp:mpa,
author = {Culley, P and Elzur, U and Recio, R and Bailey, S and Carrier, J},
title = {{Marker PDU Aligned Framing for TCP Specification}},
year = {2004},
month = feb,
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:33:15GMT},
url = {http://www.ietf.org/internet-drafts/draft-ietf-rddp-mpa-02.txt},
uri = {\url{papers2://publication/uuid/9F82B389-525F-4A0A-A4E8-B0E5C5F378F7}}
}

@techreport{iwarp:rdmap,
author = {Recio, R and Culley, P and Garcia, D and Hilland, J and Metzler, B},
title = {{An RDMA Protocol Specification}},
year = {2005},
month = apr,
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:30:24GMT},
url = {http://www.ietf.org/internet-drafts/draft-ietf-rddp-rdmap-04.txt},
uri = {\url{papers2://publication/uuid/A6A3E1D1-7F23-4FAE-8E5E-AF3C2EA2363E}}
}

@article{Shelburne:2010cg,
author = {Shelburne, M and Patterson, C and Athanas, P and Jones, M and Martin, B and Fong, R},
title = {{MetaWire: using FPGA configuration circuitry to emulate a network-on-chip}},
journal = {IET Computers {\&} Digital Techniques},
year = {2010},
volume = {4},
number = {3},
pages = {159},
doi = {10.1049/iet-cdt.2009.0009},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-04-24T01:31:22GMT},
date-modified = {2014-04-17T19:10:03GMT},
url = {http://link.aip.org/link/ICDTA6/v4/i3/p159/s1&Agg=doi},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Shelburne/MetaWire_using_FPGA_configuration_circuitry_to_emulate_a_network-on-chip_2010_Shelburne.pdf},
file = {{MetaWire_using_FPGA_configuration_circuitry_to_emulate_a_network-on-chip_2010_Shelburne.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Shelburne/MetaWire_using_FPGA_configuration_circuitry_to_emulate_a_network-on-chip_2010_Shelburne.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1049/iet-cdt.2009.0009}}
}

@misc{rapport-kilocore,
title = {{Rapport KC256}},
rating = {0},
date-added = {2014-07-05T19:08:30GMT},
date-modified = {2014-07-05T19:20:32GMT},
url = {http://www.rapportincorporated.com/pdfs/Rapport%20-%20KC256%20Technical%20Overview.pdf},
uri = {\url{papers2://publication/uuid/7AC892AC-A227-4137-BB07-4ECACF825995}}
}

@article{Bordawekar:2010tr,
author = {Bordawekar, Rajesh R and Bondhugula, U},
title = {{Can CPUs Match GPUs on Performance with Productivity?: Experiences with Optimizing a FLOP-intensive Application on CPUs and GPU}},
journal = {IBM Reseach Report RC25033}},
year = {2010},
read = {Yes},
rating = {0},
date-added = {2011-04-02T14:11:30GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {In this work, we evaluate performance of a real-world image processing application that uses a cross-correlation algorithm to compare a given image with a reference one. The algorithm processes individual images represented as 2-dimensional matrices of single-},
url = {http://domino.research.ibm.com/library/cyberdig.nsf/0/efe521ab23a0d28b85257784004dc9dd?OpenDocument&Highlight=0,Bordawekar},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Bordawekar/Can_CPUs_Match_GPUs_on_Performance_with_Productivity_Experiences_with_Optimizing_a_FLOP-intensive_Application_on_CPUs_and_GPU_2010_Bordawekar.pdf},
file = {{Can_CPUs_Match_GPUs_on_Performance_with_Productivity_Experiences_with_Optimizing_a_FLOP-intensive_Application_on_CPUs_and_GPU_2010_Bordawekar.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Bordawekar/Can_CPUs_Match_GPUs_on_Performance_with_Productivity_Experiences_with_Optimizing_a_FLOP-intensive_Application_on_CPUs_and_GPU_2010_Bordawekar.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F91D054E-82CB-4E86-9B09-5E6145CDE14E}}
}

@article{vanAmesfoort:15vk,
author = {van Amesfoort, AS and Varbanescu, AL},
title = {{Metrics to Characterize Parallel Applications}}},
year = {15},
read = {Yes},
rating = {0},
date-added = {2011-04-24T14:04:39GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Abstract. When computer architects re-invented parallelism through multi-core processors, application parallelization became mandatory. The challenge of ``mass-parallelization'' forced the software community to re- act quickly. Unfortunately, instead of tackling such a large-scale problem ...},
url = {http://www.pds.ewi.tudelft.nl/~afoort/publ/cpc10/metrics-cpc10.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/15/van_Amesfoort/Metrics_to_Characterize_Parallel_Applications%7D_15_van_Amesfoort.pdf},
file = {{Metrics_to_Characterize_Parallel_Applications}_15_van_Amesfoort.pdf:/Users/njustn/Dropbox/Papers2/Articles/15/van_Amesfoort/Metrics_to_Characterize_Parallel_Applications}_15_van_Amesfoort.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/982D4EB6-8427-45C9-9C5D-59F38032E92C}}
}

@article{Zhou:2008vp,
author = {Zhou, K and Hou, Q and Wang, R},
title = {{Real-time kd-tree construction on graphics hardware}},
journal = {ACM Transactions on Graphics},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:24:10GMT},
date-modified = {2014-07-05T18:30:53GMT},
url = {http://portal.acm.org/citation.cfm?id=1409079},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Zhou/Real-time_kd-tree_construction_on_graphics_hardware_2008_Zhou.pdf},
file = {{Real-time_kd-tree_construction_on_graphics_hardware_2008_Zhou.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Zhou/Real-time_kd-tree_construction_on_graphics_hardware_2008_Zhou.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/0517A7D4-B57B-47E0-9A2C-14DB8162C8E2}}
}

@incollection{Beyer:2011ib,
author = {Beyer, James C and Stotzer, Eric J and Hart, Alistair and de Supinski, Bronis R},
title = {{OpenMP for Accelerators}},
booktitle = {Lecture Notes in Computer Science: OpenMP in the Petascale Era},
pages = {108--121},
publisher = {Springer Berlin Heidelberg},
doi = {10.1007/978-3-642-21487-5_9},
isbn = {978-3-642-21487-5},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-07-05T19:58:25GMT},
date-modified = {2014-07-05T20:43:31GMT},
url = {http://link.springer.com/chapter/10.1007/978-3-642-21487-5_9},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-21487-5_9}}
}

@techreport{AugThiNamWac10RR7240,
author = {Augonnet, C{\'e}dric and Thibault, Samuel and Namyst, Raymond},
title = {{StarPU: a Runtime System for Scheduling Tasks over Accelerator-Based Multicore Machines}},
institution = {Laboratoire Bordelais de Recherche en Informatique - {LaBRI}, {RUNTIME} - INRIA Bordeaux - Sud-Ouest},
year = {2010},
number = {RR-7240},
month = mar,
publisher = {INRIA},
affiliation = {Laboratoire Bordelais de Recherche en Informatique - {LaBRI}, {RUNTIME} - INRIA Bordeaux - Sud-Ouest},
read = {Yes},
rating = {0},
date-added = {2011-04-06T17:05:14GMT},
date-modified = {2014-07-05T18:30:36GMT},
url = {http://hal.inria.fr/inria-00467677},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Reports/2010/Augonnet/StarPU_a_Runtime_System_for_Scheduling_Tasks_over_Accelerator-Based_Multicore_Machines_2010_Augonnet.pdf},
file = {{StarPU_a_Runtime_System_for_Scheduling_Tasks_over_Accelerator-Based_Multicore_Machines_2010_Augonnet.pdf:/Users/njustn/Dropbox/Papers2/Reports/2010/Augonnet/StarPU_a_Runtime_System_for_Scheduling_Tasks_over_Accelerator-Based_Multicore_Machines_2010_Augonnet.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DCC82964-CB7C-4F9E-BC9D-7189CA7D9FC3}}
}

@article{VonBehren:2003un,
author = {Von Behren, R and Condit, J and Zhou, F},
title = {{Capriccio: scalable threads for internet services}},
journal = {ACM SIGOPS Operating Systems Review},
year = {2003},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:39:09GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {ABSTRACT This paper presents Capriccio , a scalable thread package for use with high-concurrency servers. While recent work has advocated event-based systems, we believe that thread - based systems can provide a simpler programming model that achieves equivalent or superior ...},
url = {http://portal.acm.org/citation.cfm?id=945471},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/Von_Behren/Capriccio_scalable_threads_for_internet_services_2003_Von_Behren.pdf},
file = {{Capriccio_scalable_threads_for_internet_services_2003_Von_Behren.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/Von_Behren/Capriccio_scalable_threads_for_internet_services_2003_Von_Behren.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E93EF21F-FA7F-4B34-A0BC-50507DCE14C2}}
}

@article{Rossbach:2007wh,
author = {Rossbach, CJ and Hofmann, OS and Porter, DE},
title = {{TxLinux: using and managing hardware transactional memory in an operating system}},
journal = {{\ldots} on Operating {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:44:10GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {ABSTRACT TxLinux is a variant of Linux that is the first operating system to use hardware transactional memory (HTM) as a synchronization primitive, and the first to manage HTM in the scheduler. This paper describes and measures TxLinux and discusses two innovations in detail: ...},
url = {http://portal.acm.org/citation.cfm?id=1294271},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Rossbach/TxLinux_using_and_managing_hardware_transactional_memory_in_an_operating_system_2007_Rossbach.pdf},
file = {{TxLinux_using_and_managing_hardware_transactional_memory_in_an_operating_system_2007_Rossbach.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Rossbach/TxLinux_using_and_managing_hardware_transactional_memory_in_an_operating_system_2007_Rossbach.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/9124C633-2566-49B8-9907-A69A87C01FDE}}
}

@article{Xiao:2010wb,
author = {Xiao, Shucai and Feng, Wu{-chun}},
title = {{Inter-block GPU communication via fast barrier synchronization}},
year = {2010},
pages = {1--12},
publisher = {IEEE},
isbn = {1424464420},
rating = {0},
date-added = {2013-02-14T01:52:45GMT},
date-modified = {2014-07-05T17:55:52GMT},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5470477},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Xiao/Inter-block_GPU_communication_via_fast_barrier_synchronization_2010_Xiao.pdf},
file = {{Inter-block_GPU_communication_via_fast_barrier_synchronization_2010_Xiao.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Xiao/Inter-block_GPU_communication_via_fast_barrier_synchronization_2010_Xiao.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/ECA65EC0-19CF-44AC-AB87-966B1173D504}}
}

@inproceedings{Jiang:2012kk,
author = {Jiang, Wei and Agrawal, Gagan},
title = {{MATE-CG: A MapReduce-Like Framework for Accelerating Data-Intensive Computations on Heterogeneous Clusters }},
  crossref = {ipdps},
year = {2012},
pages = {1--12},
address = {Shanghai},
month = apr,
doi = {10.1109/IPDPS.2012.65},
read = {Yes},
rating = {0},
date-added = {2012-07-10T20:27:47GMT},
date-modified = {2014-07-05T17:43:45GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Jiang/MATE-CG_A_MapReduce-Like_Framework_for_Accelerating_Data-Intensive_Computations_on_Heterogeneous_Clusters_2012_Jiang.pdf},
file = {{MATE-CG_A_MapReduce-Like_Framework_for_Accelerating_Data-Intensive_Computations_on_Heterogeneous_Clusters_2012_Jiang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Jiang/MATE-CG_A_MapReduce-Like_Framework_for_Accelerating_Data-Intensive_Computations_on_Heterogeneous_Clusters_2012_Jiang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2012.65}}
}

@article{Liao:2007uu,
author = {Liao, Chunhua and Hernandez, Oscar and Chapman, Barbara and Chen, Wenguang and Zheng, Weimin},
title = {{OpenUH: an Optimizing, Portable OpenMP Compiler: Research Articles}},
journal = {Concurrency and Computation: Practice and Experience},
year = {2007},
volume = {19},
number = {18},
month = dec,
publisher = { John Wiley and Sons Ltd},
read = {Yes},
rating = {0},
date-added = {2013-02-24T18:53:01GMT},
date-modified = {2014-07-05T20:57:09GMT},
abstract = {OpenMP has gained wide popularity as an API for parallel programming on shared memory and distributed shared memory platforms. Despite its broad availability, there remains a need for a portable, robust, open source, optimizing OpenMP compiler for C/C++/Fortran},
url = {http://portal.acm.org/citation.cfm?id=1298358.1298361&coll=DL&dl=GUIDE&CFID=282072352&CFTOKEN=64653692},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Liao/OpenUH_an_Optimizing_Portable_OpenMP_Compiler_Research_Articles_2007_Liao-1.pdf},
file = {{OpenUH_an_Optimizing_Portable_OpenMP_Compiler_Research_Articles_2007_Liao-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Liao/OpenUH_an_Optimizing_Portable_OpenMP_Compiler_Research_Articles_2007_Liao-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1C6EE856-834E-447D-866E-EA950922321C}}
}

@inproceedings{Rane:2012hm,
author = {Rane, Ashay and Browne, James},
title = {{Enhancing performance optimization of multicore chips and multichip nodes with data structure metrics}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2012},
publisher = {ACM},
month = sep,
doi = {10.1145/2370816.2370838},
rating = {0},
date-added = {2013-02-25T15:24:56GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {Program performance optimization is usually based solely on measurements of execution behavior of code segments using hardware performance counters. However, memory access patterns are critical performance limiting factors for today's multicore chips},
url = {http://portal.acm.org/citation.cfm?id=2370816.2370838&coll=DL&dl=ACM&CFID=282072352&CFTOKEN=64653692},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Rane/Enhancing_performance_optimization_of_multicore_chips_and_multichip_nodes_with_data_structure_metrics_2012_Rane.pdf},
file = {{Enhancing_performance_optimization_of_multicore_chips_and_multichip_nodes_with_data_structure_metrics_2012_Rane.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Rane/Enhancing_performance_optimization_of_multicore_chips_and_multichip_nodes_with_data_structure_metrics_2012_Rane.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2370816.2370838}}
}

@inproceedings{Becchi:2012fx,
author = {Becchi, Michela and Sajjapongse, Kittisak and Graves, Ian and Procter, Adam and Ravi, Vignesh and Chakradhar, Srimat},
title = {{A virtual memory based runtime to support multi-tenancy in clusters with GPUs}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2012},
publisher = {ACM},
month = jun,
doi = {10.1145/2287076.2287090},
read = {Yes},
rating = {0},
date-added = {2012-08-09T18:53:29GMT},
date-modified = {2014-07-05T17:42:14GMT},
abstract = {Graphics Processing Units (GPUs) are increasingly becoming part of HPC clusters. Nevertheless, cloud computing services and resource management frameworks targeting heterogeneous clusters including GPUs are still in their infancy. Further, GPU software},
url = {http://dl.acm.org/citation.cfm?id=2287090},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Becchi/A_virtual_memory_based_runtime_to_support_multi-tenancy_in_clusters_with_GPUs_2012_Becchi.pdf},
file = {{A_virtual_memory_based_runtime_to_support_multi-tenancy_in_clusters_with_GPUs_2012_Becchi.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Becchi/A_virtual_memory_based_runtime_to_support_multi-tenancy_in_clusters_with_GPUs_2012_Becchi.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2287076.2287090}}
}

@inproceedings{Ravi:2011km,
author = {Ravi, Vignesh T and Becchi, Michela and Agrawal, Gagan and Chakradhar, Srimat},
title = {{Supporting GPU sharing in cloud environments with a transparent runtime consolidation framework}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2011},
publisher = {ACM},
month = jun,
doi = {10.1145/1996130.1996160},
rating = {0},
date-added = {2012-08-09T18:54:21GMT},
date-modified = {2014-07-05T17:42:14GMT},
abstract = {Driven by the emergence of GPUs as a major player in high performance computing and the rapidly growing popularity of cloud environments, GPU instances are now being offered by cloud providers. The use of GPUs in a cloud environment, however, is still},
url = {http://tbex.twbbs.org/~tbex/pad/papers/GPU_cloud_cluster.pdf},
uri = {\url{papers2://publication/doi/10.1145/1996130.1996160}}
}

@inproceedings{Boyer:2009ct,
author = {Boyer, Michael and Tarjan, D and Acton, S T and Skadron, K Parallel Distributed Processing 2009 IPDPS 2009 IEEE International Symposium on},
title = {{Accelerating leukocyte tracking using CUDA: A case study in leveraging manycore coprocessors}},
crossref = {ipdps},
year = {2009},
pages = {1--12},
publisher = { IEEE Computer Society},
doi = {10.1109/IPDPS.2009.5160984},
read = {Yes},
rating = {0},
date-added = {2013-02-26T02:06:25GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {The availability of easily programmable manycore CPUs and GPUs has motivated investigations into how to best exploit their tremendous computational power for scientific computing. Here we demonstrate how a systems biology application - detection and tracking of white blood cells in video microscopy - can be accelerated by 200times using a CUDA-capable GPU. Because the algorithms and implementation challenges are common to a wide range of applications, we discuss general techniques that allow programmers to make efficient use of a manycore GPU. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5160984&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Accelerating+Leukocyte+tracking+using+CUDA%3A+A+case+study+in+leveraging+manycore+coprocessors%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Boyer/Accelerating_leukocyte_tracking_using_CUDA_A_case_study_in_leveraging_manycore_coprocessors_2009_Boyer.pdf},
file = {{Accelerating_leukocyte_tracking_using_CUDA_A_case_study_in_leveraging_manycore_coprocessors_2009_Boyer.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Boyer/Accelerating_leukocyte_tracking_using_CUDA_A_case_study_in_leveraging_manycore_coprocessors_2009_Boyer.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5160984}}
}

@inproceedings{Krommydas:2013vp,
author = {Krommydas, Konstantinos and Scogland, Thomas R W and Feng, Wu{-chun}},
title = {{On the Programmability and Performance of Heterogeneous Platforms}},
booktitle = {International Conference on Parallel and Distributed Systems},
year = {2013},
address = {Gungam},
month = oct,
rating = {0},
date-added = {2014-01-12T17:00:05GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/24B51E34-D069-42AF-B4EB-4880969C8ECF}}
}

@inproceedings{Scogland:2014uu,
author = {Scogland, Thomas R W and Steffen, Craig P and Wilde, Torsten and Parent, Florent and Coghlan, Susan and Bates, Natalie and Feng, Wu{-chun} and Strohmaier, Erich},
title = {{A Power-Measurement Methodology for Large-Scale, High-Performance Computing}},
booktitle = {ACM/SPEC International Conference on Performance Engineering (ICPE)},
year = {2014},
month = mar,
annote = {test},
keywords = {Accepted, candidate for "Best Industrial Paper"},
rating = {0},
date-added = {2014-01-12T17:03:32GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/9B7B3251-ED1D-4C14-B025-B9A8E8A9DC5F}}
}

@inproceedings{Pickering:2014db,
author = {Pickering, Brent P and Charles, Jackson W and Scogland, Thomas R W and Feng, Wu{-chun} and Roy, Christopher J},
title = {{Directive-Based GPU Programming for Computational Fluid Dynamics}},
booktitle = {52nd Aerospace Sciences Meeting},
year = {2014},
publisher = {American Institute of Aeronautics and Astronautics},
address = {Reston, Virginia},
month = jan,
doi = {10.2514/6.2014-1131},
isbn = {978-1-62410-256-1},
rating = {0},
date-added = {2014-01-17T21:01:51GMT},
date-modified = {2014-07-05T17:55:52GMT},
url = {http://arc.aiaa.org/doi/abs/10.2514/6.2014-1131},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2014/Pickering/Directive-Based_GPU_Programming_for_Computational_Fluid_Dynamics_2014_Pickering.pdf},
file = {{Directive-Based_GPU_Programming_for_Computational_Fluid_Dynamics_2014_Pickering.pdf:/Users/njustn/Dropbox/Papers2/Articles/2014/Pickering/Directive-Based_GPU_Programming_for_Computational_Fluid_Dynamics_2014_Pickering.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.2514/6.2014-1131}}
}

@book{Anonymous:2012vl,
title = {{dl.acm.org}},
publisher = {Springer Berlin Heidelberg},
year = {2012},
address = {Berlin, Heidelberg},
isbn = {978-3-642-32820-6},
rating = {0},
date-added = {2014-01-18T23:22:19GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://dl.acm.org},
uri = {\url{papers2://publication/uuid/0CA16DAE-630D-48C5-A67F-2B93CD3CFD57}}
}

@inproceedings{Lee:2013ix,
author = {Lee, Janghaeng and Samadi, M and Park, Yongjun and Mahlke, S},
title = {{Transparent CPU-GPU collaboration for data-parallel kernels on heterogeneous systems}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2013},
pages = {245--255},
doi = {10.1109/PACT.2013.6618821},
read = {Yes},
rating = {0},
date-added = {2014-02-02T23:24:52GMT},
date-modified = {2014-07-05T17:37:18GMT},
abstract = {Heterogeneous computing on CPUs and GPUs has traditionally used fixed roles for each device: the GPU handles data parallel work by taking advantage of its massive number of cores while the CPU handles non data-parallel work, such as the sequential code or data transfer management. Unfortunately, this work distribution can be a poor solution as it under utilizes the CPU, has difficulty generalizing beyond the single CPU-GPU combination, and may waste a large fraction of time transferring data. Further, CPUs are performance competitive with GPUs on many workloads, thus simply partitioning work based on the fixed roles may be a poor choice. In this paper, we present the single kernel multiple devices (SKMD) system, a framework that transparently orchestrates collaborative execution of a single data-parallel kernel across multiple asymmetric CPUs and GPUs. The programmer is responsible for developing a single data-parallel kernel in OpenCL, while the system automatically partitions the workload across an arbitrary set of devices, generates kernels to execute the partial workloads, and efficiently merges the partial outputs together. The goal is performance improvement by maximally utilizing all available resources to execute the kernel. SKMD handles the difficult challenges of exposed data transfer costs and the performance variations GPUs have with respect to input size. On real hardware, SKMD achieves an average speedup of 29\% on a system with one multicore CPU and two asymmetric GPUs compared to a fastest device execution strategy for a set of popular OpenCL kernels. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6618821&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Transparent+CPU-GPU+Collaboration+for+Data-Parallel+Kernels+on+Heterogeneous+Systems%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Lee/Transparent_CPU-GPU_collaboration_for_data-parallel_kernels_on_heterogeneous_systems_2013_Lee.pdf},
file = {{Transparent_CPU-GPU_collaboration_for_data-parallel_kernels_on_heterogeneous_systems_2013_Lee.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Lee/Transparent_CPU-GPU_collaboration_for_data-parallel_kernels_on_heterogeneous_systems_2013_Lee.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/PACT.2013.6618821}}
}

@article{Morris:vl,
author = {Morris, J G and Gaster, B R and Howes, L},
title = {{Kite: Braided Parallelism for Heterogeneous Systems}},
journal = {benedictgaster.org
},
rating = {0},
date-added = {2013-02-28T00:43:19GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Abstract Modern processors are evolving into hybrid, heterogeneous processors with both CPU and GPU cores used for general purpose computation. Several languages, such as BrookGPU, CUDA, and more recently OpenCL, have been developed to harness the ... 
},
url = {http://benedictgaster.org/wp-content/uploads/2012/10/kite.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Morris/Kite_Braided_Parallelism_for_Heterogeneous_Systems__Morris.pdf},
file = {{Kite_Braided_Parallelism_for_Heterogeneous_Systems__Morris.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Morris/Kite_Braided_Parallelism_for_Heterogeneous_Systems__Morris.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/4AF901A0-D290-4EA1-85F9-9A5FAA333DCE}}
}

@incollection{Aldinucci:2012dc,
author = {Aldinucci, Marco and Danelutto, Marco and Kilpatrick, Peter and Meneghin, Massimiliano and Torquati, Massimo},
title = {{An Efficient Unbounded Lock-Free Queue for Multi-core Systems}},
booktitle = {dl.acm.org},
year = {2012},
pages = {662--673},
publisher = {Springer Berlin Heidelberg},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-32820-6_65},
isbn = {978-3-642-32820-6},
read = {Yes},
rating = {0},
date-added = {2014-01-18T23:22:19GMT},
date-modified = {2014-03-21T11:56:14GMT},
url = {http://www.springerlink.com/index/10.1007/978-3-642-32820-6_65},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2012/Aldinucci/An_Efficient_Unbounded_Lock-Free_Queue_for_Multi-core_Systems_2012_Aldinucci.pdf},
file = {{An_Efficient_Unbounded_Lock-Free_Queue_for_Multi-core_Systems_2012_Aldinucci.pdf:/Users/njustn/Dropbox/Papers2/Books/2012/Aldinucci/An_Efficient_Unbounded_Lock-Free_Queue_for_Multi-core_Systems_2012_Aldinucci.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-32820-6_65}}
}

@article{Ravi:2012dg,
author = {Ravi, V T and Becchi, Michela and Jiang, Wei and Agrawal, Gagan and Chakradhar, S},
title = {{Scheduling Concurrent Applications on a Cluster of CPU-GPU Nodes}},
journal = {Cluster, Cloud and Grid Computing (CCGrid), 2012 12th IEEE/ACM International Symposium on},
year = {2012},
pages = {140--147},
doi = {10.1109/CCGrid.2012.78},
rating = {0},
date-added = {2012-08-09T18:54:12GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Heterogeneous architectures comprising a multicore CPU and many-core GPU(s) are increasingly being used within cluster and cloud environments. In this paper, we study the problem of optimizing the overall throughput of a set of applications deployed on a cluster of such heterogeneous nodes. We consider two different scheduling formulations. In the first formulation, we consider jobs that can be executed on either the GPU or the CPU of a single node. In the second formulation, we consider jobs that can be executed on the CPU, GPU, or both, of any number of nodes in the system. We have developed scheduling schemes addressing both of the problems. In our evaluation, we first show that the schemes proposed for first formulation outperform a blind round-robin scheduler and approximate the performances of an ideal scheduler that involves an impractical exhaustive exploration of all possible schedules. Next, we show that the scheme proposed for the second formulation outperforms the best of existing schemes for heterogeneous clusters, TORQUE and MCT, by up to 42\%.},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6217415&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Authors%3A%22ravi%2C+V%22%29},
uri = {\url{papers2://publication/doi/10.1109/CCGrid.2012.78}}
}

@article{Reed:1984wi,
author = {Reed, S and Saltzer, JH and Reed, DP},
title = {{End-to-end arguments in system design}},
year = {1984},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:06:16GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {...  End -To- End  Arguments  In  System  Design (1984). ... BibTeX | Add To MetaCart. @MISC{And84end- to-endarguments, author = {Saltzer Reed And and JH Saltzer and DP Reed and DD Clark}, title = { End -To- End  Arguments  In  System  Design }, year = {1984} }. ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.1747},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1984/Reed/End-to-end_arguments_in_system_design_1984_Reed.pdf},
file = {{End-to-end_arguments_in_system_design_1984_Reed.pdf:/Users/njustn/Dropbox/Papers2/Articles/1984/Reed/End-to-end_arguments_in_system_design_1984_Reed.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/0107EC72-CA5A-47A7-914B-A1005D60F9A9}}
}

@inproceedings{Jiang:2010kh,
author = {Jiang, Wei and Ravi, V T and Agrawal, Gagan},
title = {{A Map-Reduce System with an Alternate API for Multi-core Environments}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2010},
pages = {84--93},
doi = {10.1109/CCGRID.2010.10},
rating = {0},
date-added = {2012-08-09T18:54:48GMT},
date-modified = {2014-07-05T20:14:14GMT},
abstract = {Map-reduce framework has received a significant attention and is being used for programming both large-scale clusters and multi-core systems. While the high productivity aspect of map-reduce has been well accepted, it is not clear if the API results in efficient implementations for different subclasses of data-intensive applications. In this paper, we present a system MATE (Map-reduce with an Alternate API), that provides a high-level, but distinct API. Particularly, our API includes a programmer-managed reduction object, which results in lower memory requirements at runtime for many data-intensive applications. MATE implements this API on top of the Phoenix system, a multi-core map-reduce implementation from Stanford. We evaluate our system using three data mining applications, and compare its performance to that of both Phoenix and Hadoop. Our results show that for all the three applications, MATE outperforms Phoenix and Hadoop. Despite achieving good scalability, MATE also maintains the easy-to-use API of map-reduce. Overall, we argue that, our approach, which is based on the generalized reduction structure, provides an alternate high-level API, leading to more efficient and scalable implementations. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5493489&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Authors%3A%22ravi%2C+V%22+AND+p_Authors%3A%22agrawal%2C+G%22%29},
uri = {\url{papers2://publication/doi/10.1109/CCGRID.2010.10}}
}

@inproceedings{Ravi:2011ie,
author = {Ravi, V T and Agrawal, Gagan},
title = {{A Dynamic Scheduling Framework for Emerging Heterogeneous Systems}},
booktitle = {International Conference on High Performance Computing (HiPC)},
year = {2011},
pages = {1--10},
doi = {10.1109/HiPC.2011.6152724},
read = {Yes},
rating = {0},
date-added = {2012-08-09T18:54:54GMT},
date-modified = {2014-07-05T21:04:30GMT},
abstract = {A trend that has materialized, and has given rise to much attention, is of the increasingly heterogeneous computing platforms. Recently, it has become very common for a desktop or a notebook computer to be equipped with both a multi-core CPU and a GPU. Application development for exploiting the aggregate computing power of such an environment is a major challenge today. Particularly, we need dynamic work distribution schemes that are adaptable to different computation and communication patterns in applications, and to various heterogeneous configurations. This paper describes a general dynamic scheduling framework for mapping applications with different communication patterns to heterogeneous architectures. We first make key observations about the architectural tradeoffs among heterogeneous resources and the communication pattern of an application, and then infer constraints for the dynamic scheduler. We then present a novel cost model for choosing the optimal chunk size in a heterogeneous configuration. Finally, based on general framework and cost model we provide optimized work distribution schemes to further improve the performance. View full abstract},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6152724},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Ravi/A_Dynamic_Scheduling_Framework_for_Emerging_Heterogeneous_Systems_2011_Ravi-1.pdf},
file = {{A_Dynamic_Scheduling_Framework_for_Emerging_Heterogeneous_Systems_2011_Ravi-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Ravi/A_Dynamic_Scheduling_Framework_for_Emerging_Heterogeneous_Systems_2011_Ravi-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/HiPC.2011.6152724}}
}

@book{Kudlur:2008in,
author = {Kudlur, Manjunath and Mahlke, Scott and Kudlur, Manjunath and Mahlke, Scott},
title = {{Orchestrating the Execution of Stream Programs on Multicore Platforms}},
publisher = {Programming Language Design and Implementation, PLDI},
year = {2008},
volume = {43},
address = {New York, New York, USA},
month = may,
doi = {10.1145/1379022.1375596},
isbn = {978-1-59593-860-2},
read = {Yes},
rating = {0},
date-added = {2014-02-02T23:26:21GMT},
date-modified = {2014-04-10T14:34:47GMT},
abstract = {Abstract While multicore hardware has become ubiquitous, explicitly parallel programming models and compiler techniques for exploiting parallelism on these systems have noticeably lagged behind. Stream programming is one model that has wide applicability in the ... 
},
url = {http://portal.acm.org/citation.cfm?doid=1375581.1375596},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2008/Kudlur/Orchestrating_the_Execution_of_Stream_Programs_on_Multicore_Platforms_2008_Kudlur.pdf},
file = {{Orchestrating_the_Execution_of_Stream_Programs_on_Multicore_Platforms_2008_Kudlur.pdf:/Users/njustn/Dropbox/Papers2/Books/2008/Kudlur/Orchestrating_the_Execution_of_Stream_Programs_on_Multicore_Platforms_2008_Kudlur.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1379022.1375596}}
}

@article{Hou:2008ti,
author = {Hou, Q and Zhou, K},
title = {{BSGP: bulk-synchronous GPU programming}},
journal = {ACM Transactions on Graphics},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:25:16GMT},
date-modified = {2014-07-05T18:30:53GMT},
url = {http://portal.acm.org/citation.cfm?id=1360618},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Hou/BSGP_bulk-synchronous_GPU_programming_2008_Hou.pdf},
file = {{BSGP_bulk-synchronous_GPU_programming_2008_Hou.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Hou/BSGP_bulk-synchronous_GPU_programming_2008_Hou.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/17E10E3A-19E1-4644-9802-4AB6B425263A}}
}

@article{Sridharan:2011tr,
author = {Sridharan, S. and Vetter, J.S. and Chamberlain, BL and Kogge, PM and Deitz, SJ},
title = {{A Scalable Implementation of Language-Based Software Transactional Memory for Distributed Memory Systems}},
year = {2011},
publisher = {Technical Report FTGTR-2011-02, Oak Ridge National Laboratory},
rating = {0},
date-added = {2012-03-27T20:20:11GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://ft.ornl.gov/pubs-archive/chplstm1-2011-tr.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Sridharan/A_Scalable_Implementation_of_Language-Based_Software_Transactional_Memory_for_Distributed_Memory_Systems_2011_Sridharan.pdf},
file = {{A_Scalable_Implementation_of_Language-Based_Software_Transactional_Memory_for_Distributed_Memory_Systems_2011_Sridharan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Sridharan/A_Scalable_Implementation_of_Language-Based_Software_Transactional_Memory_for_Distributed_Memory_Systems_2011_Sridharan.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/8051F703-8063-4BAB-8720-76CFA5789320}}
}

@article{Mikkilineni:2011ki,
author = {Mikkilineni, R and Seyler, I},
title = {{Parallax-A New Operating System for Scalable, Distributed, and Parallel Computing}},
journal = {Parallel and Distributed Processing {\ldots}},
year = {2011},
pages = {976--983},
doi = {10.1109/IPDPS.2011.247},
read = {Yes},
rating = {0},
date-added = {2013-03-01T14:13:19GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {Abstract Parallax , a new operating system , implements scalable , distributed , and parallel computing to take advantage of the new generation of 64-bit multi-core processors. Parallax uses the Distributed Intelligent Managed Element (DIME) network architecture, which ... 
},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6008946},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Mikkilineni/Parallax-A_New_Operating_System_for_Scalable_Distributed_and_Parallel_Computing_2011_Mikkilineni.pdf},
file = {{Parallax-A_New_Operating_System_for_Scalable_Distributed_and_Parallel_Computing_2011_Mikkilineni.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Mikkilineni/Parallax-A_New_Operating_System_for_Scalable_Distributed_and_Parallel_Computing_2011_Mikkilineni.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2011.247}}
}

@inproceedings{he2008mars,
author = {He, B and Fang, W and Luo, Q and Govindaraju, N K and Wang, T},
title = {{Mars: a MapReduce Framework on Graphics Processors}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2008},
pages = {260--269},
organization = {ACM New York, NY, USA},
affiliation = {ACM New York, NY, USA},
keywords = {GPU},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:00:09GMT},
date-modified = {2014-07-05T20:32:05GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/He/Mars_a_MapReduce_Framework_on_Graphics_Processors_2008_He-1.pdf},
file = {{Mars_a_MapReduce_Framework_on_Graphics_Processors_2008_He-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/He/Mars_a_MapReduce_Framework_on_Graphics_Processors_2008_He-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6E7C5915-F638-4D98-A4AF-6B91F7E0C059}}
}

@article{Wong2010,
author = {Wong, Henry and Papadopoulou, Misel-Myrto and Sadooghi-Alvandi, Maryam and Moshovos, Andreas},
title = {{Demystifying GPU microarchitecture through microbenchmarking}},
journal = {2010 IEEE International Symposium on Performance Analysis of Systems \{\&} Software (ISPASS)},
year = {2010},
pages = {235--246},
publisher = {Ieee},
keywords = {GPU},
doi = {10.1109/ISPASS.2010.5452013},
isbn = {978-1-4244-6023-6},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:00:09GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5452013},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Wong/Demystifying_GPU_microarchitecture_through_microbenchmarking_2010_Wong.pdf},
file = {{Demystifying_GPU_microarchitecture_through_microbenchmarking_2010_Wong.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Wong/Demystifying_GPU_microarchitecture_through_microbenchmarking_2010_Wong.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ISPASS.2010.5452013}}
}

@article{Balaji2009a,
author = {Balaji, Pavan and Chan, A and Thakur, R and Gropp, W. and Lusk, E},
title = {{Toward Message Passing for a Million Processes : Characterizing MPI on a Massive Scale Blue Gene / P}},
journal = {Computer Science-Research and Development},
year = {2009},
volume = {24},
number = {1},
pages = {11--19},
publisher = {Springer},
keywords = {P2CM-TPDS},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:02:17GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://www.springerlink.com/index/6X636491V5848255.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Balaji/Toward_Message_Passing_for_a_Million_Processes_Characterizing_MPI_on_a_Massive_Scale_Blue_Gene_P_2009_Balaji.pdf},
file = {{Toward_Message_Passing_for_a_Million_Processes_Characterizing_MPI_on_a_Massive_Scale_Blue_Gene_P_2009_Balaji.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Balaji/Toward_Message_Passing_for_a_Million_Processes_Characterizing_MPI_on_a_Massive_Scale_Blue_Gene_P_2009_Balaji.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/92F012F8-1B01-4935-A30F-E63AF56786F9}}
}

@inproceedings{Balaji2009,
author = {Balaji, Pavan and Naik, Harish and Desai, Narayan},
title = {{Understanding Network Saturation Behavior on Large-Scale Blue Gene/P Systems}},
booktitle = {International Conference on Parallel and Distributed Systems},
year = {2009},
pages = {586--593},
publisher = {Ieee},
keywords = {P2CM-TPDS},
doi = {10.1109/ICPADS.2009.117},
isbn = {978-1-4244-5788-5},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:02:17GMT},
date-modified = {2014-07-05T17:40:34GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5395352},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Balaji/Understanding_Network_Saturation_Behavior_on_Large-Scale_Blue_GeneP_Systems_2009_Balaji.pdf},
file = {{Understanding_Network_Saturation_Behavior_on_Large-Scale_Blue_GeneP_Systems_2009_Balaji.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Balaji/Understanding_Network_Saturation_Behavior_on_Large-Scale_Blue_GeneP_Systems_2009_Balaji.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPADS.2009.117}}
}

@inproceedings{Nikolopoulos,
author = {Nikolopoulos, D.S. and Papatheodorou, T.S. and Polychronopoulos, C.D. and Labarta, J. and Ayguad{\'e}, Eduard},
title = {{User-Level Dynamic Page Migration for Multiprogrammed Shared-Memory Multiprocessors}},
booktitle = {International Conference on Parallel Processing},
year = {2000},
keywords = {P2CM-TPDS},
doi = {10.1109/ICPP.2000.876083},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:02:17GMT},
date-modified = {2014-07-05T18:40:40GMT},
abstract = {This paper presents algorithms for improving the performance of parallel programs on multiprogrammed shared-memory NUMA multiprocessors, via the use of user-level dynamic page migration. The idea that drives the algorithms is that a page migration engine can perform accurate and timely page migrations in a multiprogrammed system if it can correlate page reference information with scheduling information obtained from the operating system. The necessary page migrations can be performed as a response to scheduling events that break the implicit association between threads and their memory affinity sets. We present two algorithms that use feedback from the kernel scheduler to aggressively migrate pages upon thread migrations. The first algorithm exploits the iterative nature of parallel programs, while the second targets generic codes without making assumptions on their structure. Performance evaluation on an SGI Origin2000 shows that our page migration algorithms provide substantial improvements in throughput of up to 264\% compared to the native IRIX 6.5.5 page placement and migration schemes View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=876083&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_DOI%3A10.1109%2FICPP.2000.876083%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Nikolopoulos/User-Level_Dynamic_Page_Migration_for_Multiprogrammed_Shared-Memory_Multiprocessors_2000_Nikolopoulos.pdf},
file = {{User-Level_Dynamic_Page_Migration_for_Multiprogrammed_Shared-Memory_Multiprocessors_2000_Nikolopoulos.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Nikolopoulos/User-Level_Dynamic_Page_Migration_for_Multiprogrammed_Shared-Memory_Multiprocessors_2000_Nikolopoulos.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPP.2000.876083}}
}

@inproceedings{Nikolopoulos2000,
author = {Nikolopoulos, Dimitrios S. and Papatheodorou, Theodore S. and Polychronopoulos, Constantine D. and Labarta, Jes{\'u}s and Ayguad{\'e}, Eduard},
title = {{A Case for User-Level Dynamic Page Migration}},
booktitle = {ACM International Conference on Supercomputing},
year = {2000},
publisher = {ACM},
month = may,
keywords = {P2CM-TPDS},
doi = {10.1145/335231.335243},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:02:17GMT},
date-modified = {2014-07-05T18:39:36GMT},
abstract = {This paper presents user-level dynamic page migration, a runtime technique which transparently enables parallel programs to tune their memory performance on distributed shared memory multiprocessors, with feedback obtained from dynamic},
url = {http://portal.acm.org/citation.cfm?id=335231.335243&coll=DL&dl=GUIDE&CFID=502875396&CFTOKEN=99908118},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Nikolopoulos/A_Case_for_User-Level_Dynamic_Page_Migration_2000_Nikolopoulos-1.pdf},
file = {{A_Case_for_User-Level_Dynamic_Page_Migration_2000_Nikolopoulos-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Nikolopoulos/A_Case_for_User-Level_Dynamic_Page_Migration_2000_Nikolopoulos-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/335231.335243}}
}

@inproceedings{Barham:2003vu,
author = {Barham, P and Dragovic, B and Fraser, K and Hand, S},
title = {{Xen and the art of virtualization}},
booktitle = {Proceedings of the {\ldots}},
year = {2003},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:07:30GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {ABSTRACT Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating sys- tems. Some target 100\% binary compatibility at the expense of ...},
url = {http://portal.acm.org/citation.cfm?id=945462},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/Barham/Xen_and_the_art_of_virtualization_2003_Barham.pdf},
file = {{Xen_and_the_art_of_virtualization_2003_Barham.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/Barham/Xen_and_the_art_of_virtualization_2003_Barham.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/52D95220-31FE-4977-BE88-825908BA682D}}
}

@article{Larowe1991,
author = {Larowe, Richard P. and Schlatter Ellis, Carla},
title = {{Experimental comparison of memory management policies for NUMA multiprocessors}},
journal = {ACM Transactions on Computer Systems},
year = {1991},
volume = {9},
number = {4},
pages = {319--363},
keywords = {P2CM-TPDS, To Read},
doi = {10.1145/118544.118546},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:22GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://portal.acm.org/citation.cfm?doid=118544.118546},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1991/Larowe/Experimental_comparison_of_memory_management_policies_for_NUMA_multiprocessors_1991_Larowe.pdf},
file = {{Experimental_comparison_of_memory_management_policies_for_NUMA_multiprocessors_1991_Larowe.pdf:/Users/njustn/Dropbox/Papers2/Articles/1991/Larowe/Experimental_comparison_of_memory_management_policies_for_NUMA_multiprocessors_1991_Larowe.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/118544.118546}}
}

@book{Anonymous:F-laue_A,
title = {{ACM SIGPLAN Notices}},
publisher = {ACM},
issn = {0362-1340},
rating = {0},
date-added = {2014-02-02T23:26:27GMT},
date-modified = {2014-04-10T14:34:48GMT},
uri = {\url{papers2://publication/uuid/17E95AB9-EFC0-439B-A123-06E8AE874620}}
}

@article{Chandra1994,
author = {Chandra, Rohit and Devine, Scott and Verghese, Ben and Gupta, Anoop and Rosenblum, Mendel},
title = {{Scheduling and page migration for multiprocessor compute servers}},
journal = {ACM SIGOPS Operating Systems Review},
year = {1994},
volume = {28},
number = {5},
pages = {12--24},
keywords = {P2CM-TPDS, To Read},
doi = {10.1145/381792.195485},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:23GMT},
date-modified = {2014-07-05T18:30:16GMT},
url = {http://portal.acm.org/citation.cfm?doid=381792.195485},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1994/Chandra/Scheduling_and_page_migration_for_multiprocessor_compute_servers_1994_Chandra.pdf},
file = {{Scheduling_and_page_migration_for_multiprocessor_compute_servers_1994_Chandra.pdf:/Users/njustn/Dropbox/Papers2/Articles/1994/Chandra/Scheduling_and_page_migration_for_multiprocessor_compute_servers_1994_Chandra.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/381792.195485}}
}

@inproceedings{burns-ss1994,
author = {Burns, Greg and Daoud, Raja and Vaigl, James},
title = {{LAM:} An Open Cluster Environment for MPI},
booktitle = {Proceedings of Supercomputing Symposium},
year = {1994},
pages = {379--386},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:49GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://www.lam-mpi.org/download/files/lam-papers.tar.gz},
uri = {\url{papers2://publication/uuid/29E609BE-86C5-49CC-B9DB-FBC07FC7CBC9}}
}

@inproceedings{Bueno:2013jd,
author = {Bueno, Javier and Martorell, Xavier and Badia, Rosa M and Ayguad{\'e}, Eduard and Labarta, Jes{\'u}s},
title = {{Implementing OmpSs Support for Regions of Data in Architectures with Multiple Address Spaces}},
booktitle = {ACM International Conference on Supercomputing},
year = {2013},
publisher = {ACM},
month = jun,
doi = {10.1145/2464996.2465017},
read = {Yes},
rating = {0},
date-added = {2014-02-21T23:58:31GMT},
date-modified = {2014-07-05T20:44:19GMT},
abstract = {The need for features for managing complex data accesses in modern programming models has increased due to the emerging hardware architectures. HPC hardware has moved towards clusters of accelerators and/or multicores, architectures with a complex memory},
url = {http://portal.acm.org/citation.cfm?id=2464996.2465017&coll=DL&dl=ACM&CFID=499699216&CFTOKEN=36254942},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Bueno/Implementing_OmpSs_Support_for_Regions_of_Data_in_Architectures_with_Multiple_Address_Spaces_2013_Bueno-1.pdf},
file = {{Implementing_OmpSs_Support_for_Regions_of_Data_in_Architectures_with_Multiple_Address_Spaces_2013_Bueno-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Bueno/Implementing_OmpSs_Support_for_Regions_of_Data_in_Architectures_with_Multiple_Address_Spaces_2013_Bueno-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2464996.2465017}}
}

@inproceedings{baker-aipl1977,
author = {Henry C Baker, Jr. and Hewitt, Carl},
title = {{The incremental garbage collection of processes}},
booktitle = {Proceedings of the 1977 symposium on Artificial intelligence and programming languages},
year = {1977},
pages = {55--59},
publisher = {ACM},
address = {New York, NY, USA},
doi = {http://doi.acm.org/10.1145/800228.806932},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:49GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/800228.806932}}
}

@book{agha-1986,
author = {Agha, Gul},
title = {{Actors: a model of concurrent computation in distributed systems}},
publisher = {MIT Press},
year = {1986},
address = {Cambridge, MA, USA},
isbn = {0-262-01092-5},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:49GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/AB15702A-0FA3-4142-ABAB-887391675544}}
}

@inproceedings{scogland:55QGKc51,
author = {Scogland, Thomas R W and Feng, Wu{-chun}},
title = {{A Robust, High-Throughput Concurrent FIFO Queue for Many-Core Architectures}},
booktitle = {ACM Symposium on Parallelism in Algorithms and Architectures},
keywords = {In submission},
rating = {0},
date-added = {2014-03-14T16:10:09GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/E7940629-CE75-42F4-A757-79D46002D4E9}}
}

@article{Kerr2010,
author = {Kerr, Andrew and Diamos, Gregory Frederick and Yalamanchili, Sudhakar},
title = {{Modeling GPU-CPU Workloads and Systems}},
journal = {Computer Engineering},
year = {2010},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T18:32:04GMT},
url = {http://gdiamos.net/papers/performance.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Kerr/Modeling_GPU-CPU_Workloads_and_Systems_2010_Kerr.pdf},
file = {{Modeling_GPU-CPU_Workloads_and_Systems_2010_Kerr.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Kerr/Modeling_GPU-CPU_Workloads_and_Systems_2010_Kerr.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C3DD2070-79BE-4A28-BBEC-5CB787D41750}}
}

@book{Anonymous:BNLFTTWx,
title = {{ACM SIGCOMM Computer Communication Review}},
publisher = {ACM},
issn = {0146-4833},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:35:27GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/04D2C54D-35B1-479D-866F-C1B7B3525FD6}}
}

@article{friedrichs2009accelerating,
author = {Friedrichs, M S and Eastman, P and Vaidyanathan, V and Houston, M and Legrand, S and Beberg, A L and Ensign, D L and Bruns, C M and Pande, V S},
title = {{Accelerating molecular dynamic simulation on graphics processing units}},
journal = {Journal of Computational Chemistry},
year = {2009},
volume = {30},
number = {6},
pages = {864--872},
publisher = {Wiley Subscription Services, Inc., A Wiley Company Hoboken},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:15GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Friedrichs/Accelerating_molecular_dynamic_simulation_on_graphics_processing_units_2009_Friedrichs.pdf},
file = {{Accelerating_molecular_dynamic_simulation_on_graphics_processing_units_2009_Friedrichs.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Friedrichs/Accelerating_molecular_dynamic_simulation_on_graphics_processing_units_2009_Friedrichs.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/D9A6B3C6-F595-4357-BBEA-28064876F1AB}}
}

@article{Gelado:2008vy,
author = {Gelado, I and Kelm, J.H. and Ryoo, S and Lumetta, S.S. and Navarro, N. and Hwu, W W},
title = {{CUBA: an architecture for efficient CPU/co-processor data communication}},
journal = {Proceedings of the 22nd annual international conference on Supercomputing},
year = {2008},
pages = {299--308},
publisher = {ACM},
isbn = {1605581585},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:41:13GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://dl.acm.org/citation.cfm?id=1375571},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Gelado/CUBA_an_architecture_for_efficient_CPUco-processor_data_communication_2008_Gelado.pdf},
file = {{CUBA_an_architecture_for_efficient_CPUco-processor_data_communication_2008_Gelado.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Gelado/CUBA_an_architecture_for_efficient_CPUco-processor_data_communication_2008_Gelado.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2395E238-9826-4DEC-84C7-22EAC025EB3D}}
}

@article{Eddy:2005ts,
author = {Eddy, Sean R},
title = {{``Antedisciplinary'' Science}},
journal = {PLoS Computational Biology},
year = {2005},
volume = {1},
number = {1},
pages = {e6},
language = {English},
rating = {5},
date-added = {2009-02-06T15:44:38GMT},
date-modified = {2014-04-10T14:34:48GMT},
url = {http://dx.plos.org/10.1371/journal.pcbi.0010006},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/Eddy/%E2%80%9CAntedisciplinary%E2%80%9D_Science_2005_Eddy.pdf},
file = {{Antedisciplinary_Science_2005_Eddy.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Eddy/Antedisciplinary_Science_2005_Eddy.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E482D9F9-0394-4CB3-B0C2-16BBEE722313}}
}

@inproceedings{ryoo2008optimization,
author = {Ryoo, S and Rodrigues, C I and Baghsorkhi, Sara S and Stone, S S and Kirk, D B and Hwu, W W},
title = {{Optimization principles and application performance evaluation of a multithreaded GPU using CUDA}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2008},
pages = {73--82},
organization = {ACM},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:36:15GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Ryoo/Optimization_principles_and_application_performance_evaluation_of_a_multithreaded_GPU_using_CUDA_2008_Ryoo.pdf},
file = {{Optimization_principles_and_application_performance_evaluation_of_a_multithreaded_GPU_using_CUDA_2008_Ryoo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Ryoo/Optimization_principles_and_application_performance_evaluation_of_a_multithreaded_GPU_using_CUDA_2008_Ryoo.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1BCF1E66-4209-4AC7-8EE3-B60D68A80116}}
}

@article{Walbot:2009ek,
author = {Walbot, Virginia},
title = {{Are we training pit bulls to review our manuscripts?}},
journal = {Journal of Biology},
year = {2009},
volume = {8},
number = {3},
pages = {24},
doi = {10.1186/jbiol125},
language = {English},
rating = {0},
date-added = {2010-03-28T13:47:59GMT},
date-modified = {2014-04-10T14:34:48GMT},
url = {http://jbiol.com/content/8/3/24},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Walbot/Are_we_training_pit_bulls_to_review_our_manuscripts_2009_Walbot.pdf},
file = {{Are_we_training_pit_bulls_to_review_our_manuscripts_2009_Walbot.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Walbot/Are_we_training_pit_bulls_to_review_our_manuscripts_2009_Walbot.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1186/jbiol125}}
}

@inproceedings{prehofer-ecoop1997,
author = {Prehofer, Christian},
title = {{Feature-Oriented Programming: A Fresh Look at Objects}},
booktitle = {ECOOP},
year = {1997},
pages = {419--443},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/59E3B4F1-FA79-4082-A914-2F393FAB14F4}}
}

@techreport{fortress,
author = {Allen, Eric and Chase, David and Hallett, Joe and Luchango, Victor and Massen, Jan-Willem and Ryu, Sukyoung and Steele, Guy and Tobin-Hochstadt, Sam},
title = {{The \F\ortress Language Specifications, v1.0}},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/BC401323-722C-49FC-8982-988E0DD63B91}}
}

@inproceedings{shelepov2008scheduling,
author = {Shelepov, D and Fedorova, A},
title = {{Scheduling on heterogeneous multicore processors using architectural signatures}},
booktitle = {Proceedings of the Workshop on the Interaction between Operating Systems and Computer Architecture, in conjunction with ISCA},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/B2B73FA9-3521-4A2B-B952-62E88E1B26B8}}
}

@misc{nvidia2007cuda,
title = {{CUDA} Programming Guide},
howpublished = {\url{http://docs.nvidia.com/cuda/cuda-c-programming-guide/}},
year = {2007},
publisher = {NVIDIA Corporation, Santa Clara, California},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-04T05:28:30GMT},
uri = {\url{papers2://publication/uuid/C8747E41-106B-4625-944F-134442DEA64D}}
}

@article{narayanaswamy2008ins,
author = {Narayanaswamy, Ganesh and Balaji, Pavan and Feng, Wu{-chun}},
title = {{Impact of Network Sharing in Multi-core Architectures}},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:55:51GMT},
url = {http://eprints.cs.vt.edu/archive/00001021/},
uri = {\url{papers2://publication/uuid/FF6C0D06-FD71-48F5-954C-8020BF8AFE4C}}
}

@inproceedings{bailey2008pat-jop,
author = {Bailey, D H and Chame, J and Chen, C and Dongarra, Jack and Hall, M and Hollingsworth, J K and Hovland, P and Moore, S and Seymour, K and Shin, J and {Others}},
title = {{PERI Auto-Tuning}},
booktitle = {Journal of Physics: Conference Series},
year = {2008},
pages = {12089},
organization = {Institute of Physics Publishing},
affiliation = {Institute of Physics Publishing},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://www.iop.org/EJ/article/1742-6596/125/1/012089/jpconf8\_125\_012089.pdf},
uri = {\url{papers2://publication/uuid/1B533309-937B-436A-8CFD-0CDE10864E7B}}
}

@article{aji2008ads,
author = {Aji, Ashwin M and Feng, Wu{-chun}},
title = {{Accelerating Data-Serial Applications on Data-Parallel GPGPUs: A Systems Approach}},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:55:51GMT},
url = {http://eprints.cs.vt.edu/archive/00001052/},
uri = {\url{papers2://publication/uuid/E79A684D-FCC5-4510-BFA2-616D082F8EA8}}
}

@article{Yamagiwa2008,
author = {Yamagiwa, Shinichi and Wada, Koichi and Sousa, Leonel},
title = {{Heuristic Optimization Methods for Improving Performance of Recursive General Purpose Applications on GPUs}},
journal = {2008 International Symposium on Parallel and Distributed Computing},
year = {2008},
pages = {325--332},
publisher = {Ieee},
affiliation = {IEEE Computer Society Washington, DC, USA},
doi = {10.1109/ISPDC.2008.53},
isbn = {978-0-7695-3472-5},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-08T19:22:10GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4724263},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Yamagiwa/Heuristic_Optimization_Methods_for_Improving_Performance_of_Recursive_General_Purpose_Applications_on_GPUs_2008_Yamagiwa.pdf},
file = {{Heuristic_Optimization_Methods_for_Improving_Performance_of_Recursive_General_Purpose_Applications_on_GPUs_2008_Yamagiwa.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Yamagiwa/Heuristic_Optimization_Methods_for_Improving_Performance_of_Recursive_General_Purpose_Applications_on_GPUs_2008_Yamagiwa.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ISPDC.2008.53}}
}

@inproceedings{Bhadauria2010,
author = {Bhadauria, Major and McKee, Sally a.},
title = {{An Approach To Resource-Aware Co-Scheduling for CMPs}},
booktitle = {ACM International Conference on Supercomputing},
year = {2010},
pages = {189},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/1810085.1810113},
isbn = {9781450300186},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T20:23:36GMT},
url = {http://portal.acm.org/citation.cfm?doid=1810085.1810113},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Bhadauria/An_Approach_To_Resource-Aware_Co-Scheduling_for_CMPs_2010_Bhadauria-1.pdf},
file = {{An_Approach_To_Resource-Aware_Co-Scheduling_for_CMPs_2010_Bhadauria-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Bhadauria/An_Approach_To_Resource-Aware_Co-Scheduling_for_CMPs_2010_Bhadauria-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1810085.1810113}}
}

@inproceedings{Krohn:2007wf,
author = {Krohn, M and Yip, A and Brodsky, M and Cliffer, N},
title = {{Information flow control for standard OS abstractions}},
booktitle = {Proceedings of twenty {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:47:38GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Decentralized Information Flow Control (DIFC) [24] is an ap- proach to security that allows application writers to control how data flows between the pieces of an application and the outside world. As applied to privacy, DIFC allows untrusted software to compute with private data while ...},
url = {http://portal.acm.org/citation.cfm?id=1294293},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Krohn/Information_flow_control_for_standard_OS_abstractions_2007_Krohn.pdf},
file = {{Information_flow_control_for_standard_OS_abstractions_2007_Krohn.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Krohn/Information_flow_control_for_standard_OS_abstractions_2007_Krohn.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/9E21A6BB-D9A6-4902-B478-EAC0649D192E}}
}

@article{odersky2004osp,
author = {Odersky, M and Altherr, P and Cremet, V and Emir, B and Maneth, S and Micheloud, S and Mihaylov, N and Schinz, M and Stenman, E and Zenger, M},
title = {{An overview of the Scala programming language}},
journal = {LAMP-EPFL},
year = {2004},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/099CBA77-EE9F-4192-9EE9-5925E51FBA36}}
}

@inproceedings{Jimenez:2009ws,
author = {Jim{\'e}nez, V{\'\i}ctor J and Vilanova, Llu{\'\i}s and Gelado, Isaac and Gil, Marisa and Fursin, Grigori and Navarro, Nacho},
title = {{Predictive Runtime Code Scheduling for Heterogeneous Architectures}},
booktitle = {International Conference on High Performance Embedded Architectures and Compilers},
year = {2008},
publisher = { Springer-Verlag},
month = dec,
keywords = {ipdps11-omp-co},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:45:39GMT},
date-modified = {2014-07-05T20:35:15GMT},
abstract = {Heterogeneous architectures are currently widespread. With the advent of easy-to-program general purpose GPUs, virtually every recent desktop computer is a heterogeneous system. Combining the CPU and the GPU brings great amounts of processing power},
url = {http://portal.acm.org/citation.cfm?id=1505816.1505822&coll=DL&dl=GUIDE&CFID=503099589&CFTOKEN=58868388},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Jim%C3%A9nez/Predictive_Runtime_Code_Scheduling_for_Heterogeneous_Architectures_2008_Jim%C3%A9nez.pdf},
file = {{Predictive_Runtime_Code_Scheduling_for_Heterogeneous_Architectures_2008_Jimnez.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Jimnez/Predictive_Runtime_Code_Scheduling_for_Heterogeneous_Architectures_2008_Jimnez.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1F7ECB50-407D-489F-AE5C-43EBE330D551}}
}

@inproceedings{bertrand-ipdps2005,
author = {Bertrand, Felipe and Bramley, Randall and Damevski, Kostadin B and Kohl, James A and Bernholdt, David E and Larson, Jay W and Sussman, Alan},
title = {{Data Redistribution and Remote Method Invocation in Parallel Component Architectures}},
crossref = {ipdps},
year = {2005},
annote = {to appear; Best Paper Award},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:43:45GMT},
uri = {\url{papers2://publication/uuid/FEA336FF-55C6-47E5-A7AD-0BE84354D73A}}
}

@book{Jia:2012hs,
author = {Jia, Haipeng and Zhang, Yunquan and Long, Guoping and Xu, Jianliang and Yan, Shengen and Li, Yan},
editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Mattern, Friedemann and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y and Weikum, Gerhard and Kaklamanis, Christos and Papatheodorou, Theodore and Spirakis, Paul G},
title = {{GPURoofline: A Model for Guiding Performance Optimizations on GPUs
}},
publisher = {Springer Berlin Heidelberg},
year = {2012},
volume = {7484},
series = {Lecture Notes in Computer Science},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-32820-6_90},
isbn = {978-3-642-32819-0},
read = {Yes},
rating = {0},
date-added = {2012-09-05T14:22:09GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Performance optimization on GPUs requires deep technical knowledge of the underlying hardware. Modern GPU architectures are becoming more and more diversified, which further exacerbates the already difficult problem. This paper presents GPURoofline , an ... 
},
url = {http://www.springerlink.com/index/10.1007/978-3-642-32820-6_90},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2012/Jia/GPURoofline_A_Model_for_Guiding_Performance_Optimizations_on_GPUs_2012_Jia.pdf},
file = {{GPURoofline_A_Model_for_Guiding_Performance_Optimizations_on_GPUs_2012_Jia.pdf:/Users/njustn/Dropbox/Papers2/Books/2012/Jia/GPURoofline_A_Model_for_Guiding_Performance_Optimizations_on_GPUs_2012_Jia.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-32820-6_90}}
}

@article{Spafford:2011wj,
author = {Spafford, K.L. and Meredith, J.S. and Vetter, J.S.},
title = {{Quartile and Outlier Detection on Heterogeneous Clusters using Distributed Radix Sort}},
journal = {Cluster Computing (CLUSTER), 2011 IEEE International Conference on},
year = {2011},
pages = {412--419},
publisher = {IEEE},
isbn = {1457713551},
read = {Yes},
rating = {0},
date-added = {2012-03-27T20:21:10GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6061072},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Spafford/Quartile_and_Outlier_Detection_on_Heterogeneous_Clusters_using_Distributed_Radix_Sort_2011_Spafford.pdf},
file = {{Quartile_and_Outlier_Detection_on_Heterogeneous_Clusters_using_Distributed_Radix_Sort_2011_Spafford.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Spafford/Quartile_and_Outlier_Detection_on_Heterogeneous_Clusters_using_Distributed_Radix_Sort_2011_Spafford.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/3583CDFF-28A0-4C34-98E9-4D5B900FB8F2}}
}

@article{Thiel-software2002,
author = {Thiel, Steffen and Hein, Andreas},
title = {{Modeling and Using Product Line Variability in Automotive Systems}},
journal = {IEEE Software},
year = {2002},
volume = {19},
number = {4},
pages = {66--72},
address = {Los Alamitos, CA, USA},
publisher = {IEEE Computer Society},
doi = {http://doi.ieeecomputersociety.org/10.1109/MS.2002.1020289},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-04-17T19:10:21GMT},
uri = {\url{papers2://publication/doi/http://doi.ieeecomputersociety.org/10.1109/MS.2002.1020289}}
}

@article{Williams:2009cx,
author = {Williams, Samuel and Waterman, Andrew and Patterson, David},
title = {{Roofline: an insightful visual performance model for multicore architectures}},
journal = {Communications of the ACM},
year = {2009},
volume = {52},
number = {4},
month = apr,
publisher = {ACM},
doi = {10.1145/1498765.1498785},
read = {Yes},
rating = {0},
date-added = {2012-09-03T14:22:48GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {The Roofline model offers insight on how to improve the performance of software and hardware},
url = {http://portal.acm.org/citation.cfm?id=1498765.1498785&coll=DL&dl=ACM&CFID=110913148&CFTOKEN=47668929},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Williams/Roofline_an_insightful_visual_performance_model_for_multicore_architectures_2009_Williams.pdf},
file = {{Roofline_an_insightful_visual_performance_model_for_multicore_architectures_2009_Williams.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Williams/Roofline_an_insightful_visual_performance_model_for_multicore_architectures_2009_Williams.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1498765.1498785}}
}

@article{cardelli-acm1985,
author = {Cardelli, Luca and Wegner, Peter},
title = {{On understanding types, data abstraction, and polymorphism}},
journal = {ACM Comput. Surv.},
year = {1985},
volume = {17},
number = {4},
pages = {471--523},
address = {New York, NY, USA},
publisher = {ACM},
doi = {http://doi.acm.org/10.1145/6041.6042},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/6041.6042}}
}

@techreport{nvidia2009opencl,
title = {{NVIDIA OpenCL Best Practices Guide}},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/CD4FF94C-89F3-45EE-AC28-F8642AE77883}}
}

@inproceedings{rofouei2008energy,
author = {Rofouei, M and Stathopoulos, T and Ryffel, S and Kaiser, W and Sarrafzadeh, M},
title = {{Energy-Aware High Performance Computing with Graphic Processing Units}},
booktitle = {Workshop on Power Aware Computing and System},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:16GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Rofouei/Energy-Aware_High_Performance_Computing_with_Graphic_Processing_Units_2008_Rofouei.pdf},
file = {{Energy-Aware_High_Performance_Computing_with_Graphic_Processing_Units_2008_Rofouei.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Rofouei/Energy-Aware_High_Performance_Computing_with_Graphic_Processing_Units_2008_Rofouei.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F8D0A71B-89F1-40B0-A421-5511592B2CBD}}
}

@article{Gebhart:2011kd,
author = {Gebhart, Mark and Johnson, Daniel R and Tarjan, David and Keckler, Stephen W and Dally, William J and Lindholm, Erik and Skadron, Kevin},
title = {{Energy-efficient mechanisms for managing thread context in throughput processors}},
journal = {ISCA '11: Proceeding of the 38th annual international symposium on Computer architecture},
year = {2011},
month = jun,
publisher = {ACM},
doi = {10.1145/2000064.2000093},
rating = {0},
date-added = {2012-03-27T20:21:57GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Modern graphics processing units (GPUs) use a large number of hardware threads to hide both function unit and memory access latency. Extreme multithreading requires a complicated thread scheduler as well as a large register file, which is expensive to},
url = {http://portal.acm.org/citation.cfm?id=2000064.2000093&coll=DL&dl=GUIDE&CFID=74371648&CFTOKEN=64091836},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Gebhart/Energy-efficient_mechanisms_for_managing_thread_context_in_throughput_processors_2011_Gebhart.pdf},
file = {{Energy-efficient_mechanisms_for_managing_thread_context_in_throughput_processors_2011_Gebhart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Gebhart/Energy-efficient_mechanisms_for_managing_thread_context_in_throughput_processors_2011_Gebhart.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2000064.2000093}}
}

@article{Pakin2009,
author = {Pakin, S and Lang, M and Kerbyson, D J},
title = {{The reverse-acceleration model for programming petascale hybrid systems}},
journal = {International Business},
year = {2009},
volume = {53},
number = {5},
pages = {1--15},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:16GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Pakin/The_reverse-acceleration_model_for_programming_petascale_hybrid_systems_2009_Pakin.pdf},
file = {{The_reverse-acceleration_model_for_programming_petascale_hybrid_systems_2009_Pakin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Pakin/The_reverse-acceleration_model_for_programming_petascale_hybrid_systems_2009_Pakin.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6AFC251B-54E6-4CFC-9248-084EC8DD642C}}
}

@article{apel2008afm,
author = {Apel, S and Leich, T and Saake, G},
title = {{Aspectual Feature Modules}},
journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
year = {2008},
pages = {162--180},
publisher = {IEEE Computer Society},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://doi.ieeecomputersociety.org/10.1109/TSE.2007.70770},
uri = {\url{papers2://publication/uuid/D183F1F0-669F-414F-BE3B-0067E517BE53}}
}

@inproceedings{lin-sc08-bgp,
author = {Lin, Heshan and Balaji, Pavan and Poole, Ruth and Sosa, Carlos and Ma, Xiaosong and Feng, Wu{-chun}},
title = {{Massively Parallel Genomic Sequence Search on the Blue Gene/P Architecture}},
crossref = {supercomputing},
year = {2008},
address = {Austin, Texas},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/06716DFC-C6D3-4B47-9A7A-361300D53CFA}}
}

@book{Brinkmann:2007ve,
author = {Brinkmann, M},
title = {{A Critique of the GNU Hurd Multi-Server Operating System}},
publisher = {ACM SIGOPS Operating Systems Review},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:09:22GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://scholar.google.com/scholar?q=related:O03FPrAO60wJ:scholar.google.com/&hl=en&num=30&as_sdt=0,5},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2007/Brinkmann/A_Critique_of_the_GNU_Hurd_Multi-Server_Operating_System_2007_Brinkmann.pdf},
file = {{A_Critique_of_the_GNU_Hurd_Multi-Server_Operating_System_2007_Brinkmann.pdf:/Users/njustn/Dropbox/Papers2/Books/2007/Brinkmann/A_Critique_of_the_GNU_Hurd_Multi-Server_Operating_System_2007_Brinkmann.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DCA690B9-4D10-4E24-AD5C-C1BC10CF3270}}
}

@article{gallmeister-rtss1991,
author = {Gallmeister, Bill O and Lanier, Chris},
title = {{Early experience with POSIX 1003.4 and POSIX 1003.4 A}},
journal = {Proceedings of the 12th Real-Time Systems Symposium},
year = {1991},
pages = {190----198 (of ix + 307)},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/1CBC5391-5BA9-40E9-8A8C-7A0C5532C9F6}}
}

@inproceedings{hewitt-ijcai1973,
author = {Hewitt, Carl and Bishop, P and Steiger, R},
title = {{A Universal Modular ACTOR Formalism for Artificial Intelligence}},
booktitle = {Proceedings 3rd International Joint Conference on Artificial Intelligence},
year = {1973},
pages = {235--245},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/088E665E-00D3-4A1D-92F5-E87A0A144595}}
}

@article{Bronstein:2007ty,
author = {Bronstein, AM and Bronstein, MM and Devir, YS},
title = {{Parallel algorithms for approximation of distance maps on parametric surfaces}},
journal = {Proc ACM {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:26:57GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Abstract We present an efficient O(n) numerical algorithm for first-order approximation of geodesic distances on parametric surfaces , where n is the number of points on the surface. The structure of our algorithm allows efficient implementation on par- allel architectures. Two ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.128.57&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Bronstein/Parallel_algorithms_for_approximation_of_distance_maps_on_parametric_surfaces_2007_Bronstein.pdf},
file = {{Parallel_algorithms_for_approximation_of_distance_maps_on_parametric_surfaces_2007_Bronstein.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Bronstein/Parallel_algorithms_for_approximation_of_distance_maps_on_parametric_surfaces_2007_Bronstein.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/B770B2E8-8332-4F6C-B1D5-DB5DD282AD01}}
}

@article{hillesland2003nonlinear,
author = {Hillesland, K E and Molinov, S and Grzeszczuk, R},
title = {{Nonlinear optimization framework for image-based modeling on programmable graphics hardware}},
journal = {ACM Transactions on Graphics},
year = {2003},
volume = {22},
number = {3},
pages = {934},
publisher = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T18:30:53GMT},
uri = {\url{papers2://publication/uuid/89610282-445B-4BA0-BF85-562E5ECBBC91}}
}

@book{Yan:2011cx,
author = {Yan, Yonghong and Chatterjee, Sanjay and Orozco, Daniel A and Garcia, Elkin and Budimli{\'c}, Zoran and Shirako, Jun and Pavel, Robert S and Gao, Guang R and Sarkar, Vivek},
editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Mattern, Friedemann and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y and Weikum, Gerhard and Jeannot, Emmanuel and Namyst, Raymond and Roman, Jean},
title = {{Hardware and Software Tradeoffs for Task Synchronization on Manycore Architectures}},
publisher = {Springer Berlin Heidelberg},
year = {2011},
volume = {6853},
series = {Euro-Par / Lecture Notes in Computer Science},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-23397-5_12},
isbn = {978-3-642-23396-8},
rating = {0},
date-added = {2012-09-06T14:07:27GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Manycore architectures --hundreds to thousands of cores per processor--are seen by many as a natural evolution of multicore processors. To take advantage of this massive parallelism in practice requires a productive parallel programming model, and an efficient runtime for ... 
},
url = {http://www.springerlink.com/index/10.1007/978-3-642-23397-5_12},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2011/Yan/Hardware_and_Software_Tradeoffs_for_Task_Synchronization_on_Manycore_Architectures_2011_Yan.pdf},
file = {{Hardware_and_Software_Tradeoffs_for_Task_Synchronization_on_Manycore_Architectures_2011_Yan.pdf:/Users/njustn/Dropbox/Papers2/Books/2011/Yan/Hardware_and_Software_Tradeoffs_for_Task_Synchronization_on_Manycore_Architectures_2011_Yan.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-23397-5_12}}
}

@article{Tipparaju:2012dw,
author = {Tipparaju, Vinod and Apra, Edoardo and Yu, Weikuan and Que, Xinyu and Vetter, Jeffrey S},
title = {{Runtime Techniques to Enable a Highly-Scalable Global Address Space Model for Petascale Computing}},
journal = {International Journal of Parallel Programming},
year = {2012},
month = sep,
doi = {10.1007/s10766-012-0214-9},
language = {English},
read = {Yes},
rating = {0},
date-added = {2012-09-08T02:36:09GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Abstract Over the past decade, the trajectory to the petascale has been built on increased complexity and scale of the underlying parallel architectures. Meanwhile, software developers have struggled to provide tools that maintain the productivity of computational ... 
},
url = {http://www.springerlink.com/index/10.1007/s10766-012-0214-9},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Tipparaju/Runtime_Techniques_to_Enable_a_Highly-Scalable_Global_Address_Space_Model_for_Petascale_Computing_2012_Tipparaju.pdf},
file = {{Runtime_Techniques_to_Enable_a_Highly-Scalable_Global_Address_Space_Model_for_Petascale_Computing_2012_Tipparaju.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Tipparaju/Runtime_Techniques_to_Enable_a_Highly-Scalable_Global_Address_Space_Model_for_Petascale_Computing_2012_Tipparaju.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/s10766-012-0214-9}}
}

@article{gropp-pc1996,
author = {Gropp, William and Lusk, Ewing and Doss, Nathan and Skjellum, Anthony},
title = {{A high-performance, portable implementation of the \MPI\ message passing interface standard}},
journal = {Parallel Computing},
year = {1996},
volume = {22},
number = {6},
pages = {789--828},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/C9CFAAD3-D756-4010-B556-11A21C37FEE6}}
}

@inproceedings{archuleta-embc2007-pluggable,
author = {Archuleta, Jeremy S and Feng, Wu{-chun} and Tilevich, Eli},
title = {{A Pluggable Framework for Parallel Pairwise Sequence Search}},
booktitle = {International Conference of the IEEE Engineering in Medicine and Biology Society},
year = {2007},
address = {Lyon, France},
month = aug,
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/104F8B47-78FC-42ED-846D-5AE1D8EC7A46}}
}

@article{Stuart:2011uh,
author = {Stuart, Jeff A and Owens, John D},
title = {{Efficient Synchronization Primitives for GPUs}},
journal = {arXiv.org},
year = {2011},
eprint = {1110.4623v1},
eprinttype = {arxiv},
eprintclass = {cs.OS},
month = oct,
annote = {13 pages with appendix, several figures, plans to submit to CompSci
  conference in early 2012},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:43:20GMT},
date-modified = {2014-04-30T19:47:15GMT},
abstract = {In this paper, we revisit the design of synchronization primitives---specifically barriers, mutexes, and semaphores---and how they apply to the GPU. Previous implementations are insufficient due to the discrepancies in hardware and programming model of the GPU and CPU. We create new implementations in CUDA and analyze the performance of spinning on the GPU, as well as a method of sleeping on the GPU, by running a set of memory-system benchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class GPUs from NVIDIA. From our results we define higher-level principles that are valid for generic many-core processors, the most important of which is to limit the number of atomic accesses required for a synchronization operation because atomic accesses are slower than regular memory accesses. We use the results of the benchmarks to critique existing synchronization algorithms and guide our new implementations, and then define an abstraction of GPUs to classify any GPU based on the behavior of the memory system. We use this abstraction to create suitable implementations of the primitives specifically targeting the GPU, and analyze the performance of these algorithms on Tesla and Fermi. We then predict performance on future GPUs based on characteristics of the abstraction. We also examine the roles of spin waiting and sleep waiting in each primitive and how their performance varies based on the machine abstraction, then give a set of guidelines for when each strategy is useful based on the characteristics of the GPU and expected contention.},
url = {http://arxiv.org/abs/1110.4623v1},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Stuart/Efficient_Synchronization_Primitives_for_GPUs_2011_Stuart.pdf},
file = {{Efficient_Synchronization_Primitives_for_GPUs_2011_Stuart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Stuart/Efficient_Synchronization_Primitives_for_GPUs_2011_Stuart.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/517F756B-E6E2-48A4-81D4-7DF8F75B2076}}
}

@book{Anonymous:RYv95cvi,
title = {{IEEE INFOCOM}},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:36:40GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/458BFDE5-CBE2-4B80-8942-1B71CA858B69}}
}

@inproceedings{apel-icse2006,
author = {Apel, S and Leich, T and Saake, G},
title = {{Aspectual Mixin Layers: Aspects and Features in Concert}},
booktitle = {International Conference on Software Engineering (ICSE)},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {citeseer.ist.psu.edu/apel06aspectual.html},
uri = {\url{papers2://publication/uuid/05EE0E77-BE26-4016-B68F-B4A00C36A28D}}
}

@article{bailey2008pat,
author = {Bailey, D H and Williams, S and Datta, Kaushik and Carter, J and Oliker, L and Shalf, J and Yelick, K},
title = {{PERI-Auto-tuning Memory Intensive Kernels for Multicore}},
year = {2008},
publisher = {LBNL-845E, Ernest Orlando Lawrence Berkeley National Laboratory, Berkeley, CA (US)},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://www.osti.gov/bridge/product.biblio.jsp?osti\_id=936521},
uri = {\url{papers2://publication/uuid/D543B0F7-146A-4B94-991C-69D01BD99780}}
}

@inproceedings{lee2009openmp,
author = {Lee, S and Min, S J},
title = {{OpenMP to GPGPU: a Compiler Framework for Automatic Translation and Optimization}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2009},
pages = {101--110},
organization = {ACM New York, NY, USA},
publisher = {ACM},
affiliation = {ACM New York, NY, USA},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T20:53:32GMT},
url = {http://portal.acm.org/citation.cfm?id=1594835.1504194},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Lee/OpenMP_to_GPGPU_a_Compiler_Framework_for_Automatic_Translation_and_Optimization_2009_Lee-1.pdf},
file = {{OpenMP_to_GPGPU_a_Compiler_Framework_for_Automatic_Translation_and_Optimization_2009_Lee-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Lee/OpenMP_to_GPGPU_a_Compiler_Framework_for_Automatic_Translation_and_Optimization_2009_Lee-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6CF4DA9C-3F0A-4EBE-9466-94F53CA1FA45}}
}

@book{bosch-2000,
author = {Bosch, Jan},
title = {{Design and use of software architectures: adopting and evolving a product-line approach}},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
year = {2000},
address = {New York, NY, USA},
isbn = {0-201-67494-7},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/6AE34FE9-3875-4401-9AF7-04833EAB0EC3}}
}

@inproceedings{Wang:2013fp,
author = {Wang, Zhenning and Zheng, Long and Chen, Quan and Guo, Minyi},
title = {{CAP: co-scheduling based on asymptotic profiling in CPU+GPU hybrid systems}},
booktitle = {the 2013 International Workshop},
year = {2013},
pages = {107--114},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/2442992.2443004},
isbn = {9781450319089},
read = {Yes},
rating = {0},
date-added = {2013-03-02T16:52:40GMT},
date-modified = {2014-04-06T17:22:50GMT},
url = {http://dl.acm.org/citation.cfm?doid=2442992.2443004},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Wang/CAP_co-scheduling_based_on_asymptotic_profiling_in_CPU+GPU_hybrid_systems_2013_Wang.pdf},
file = {{CAP_co-scheduling_based_on_asymptotic_profiling_in_CPU+GPU_hybrid_systems_2013_Wang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Wang/CAP_co-scheduling_based_on_asymptotic_profiling_in_CPU+GPU_hybrid_systems_2013_Wang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2442992.2443004}}
}

@article{stream,
author = {McCalpin, John D},
title = {{Memory Bandwidth and Machine Balance in Current High Performance Computers}},
journal = {IEEE Computer Society Technical Committee on Computer Architecture (TCCA) Newsletter},
year = {1995},
pages = {19--25},
rating = {0},
date-added = {2014-07-05T21:27:57GMT},
date-modified = {2014-07-05T21:28:11GMT},
abstract = {The ratio of cpu speed to memory speed in current high-performance computers is growing rapidly, with significant implications for the design and implementation of algorithms in scientific computing. I present the results of a broad survey of memory bandwidth and machine balance for a large variety of current computers, including uniprocessors, vector processors, shared-memory systems, and districuted-memory systems. The results are analyzed in terms of the sustainable data transfer rates for uncached unit-stride vector operation for each machine, and for each class.},
uri = {\url{papers2://publication/uuid/DACFEB29-70F7-49B4-94D6-9E82320D8D69}}
}

@inproceedings{liu-icse2006,
author = {Liu, Jia and Batory, Don and Lengauer, Christian},
title = {{Feature oriented refactoring of legacy applications}},
booktitle = {ICSE '06: Proceedings of the 28th international conference on Software engineering},
year = {2006},
pages = {112--121},
publisher = {ACM},
address = {New York, NY, USA},
doi = {http://doi.acm.org/10.1145/1134285.1134303},
isbn = {1-59593-375-1},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/1134285.1134303}}
}

@inproceedings{Lee:2010gd,
author = {Lee, Jinpil and Sato, M},
title = {{Implementation and Performance Evaluation of XcalableMP: A Parallel Programming Language for Distributed Memory Systems}},
booktitle = { International Conference on Parallel Processing, Workshops (ICPPW)},
year = {2010},
pages = {413--420},
doi = {10.1109/ICPPW.2010.62},
rating = {0},
date-added = {2014-07-06T21:13:14GMT},
date-modified = {2014-07-06T21:14:19GMT},
abstract = {Although MPI is a de-facto standard for parallel programming on distributed memory systems, writing MPI programs is often a time-consuming and complicated process. XcalableMP is a language extension of C and Fortran for parallel programming on distributed memory systems that helps users to reduce those programming efforts. XcalableMP provides two programming models. The first one is the global view model, which supports typical parallelization based on the data and task parallel paradigm, and enables parallelizing the original sequential code using minimal modification with simple, OpenMP-like directives. The other one is the local view model, which allows using CAF-like expressions to describe inter-node communication. Users can even use MPI and OpenMP explicitly in our language to optimize performance explicitly. In this paper, we introduce XcalableMP, the implementation of the compiler, and the performance evaluation result. For the performance evaluation, we parallelized HPCC Benchmark in XcalableMP. It shows that users can describe the parallelization for distributed memory system with a small modification to the original sequential code. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5599100&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28xcalablemp%29},
uri = {\url{papers2://publication/doi/10.1109/ICPPW.2010.62}}
}

@inproceedings{cederman2008dynamic,
author = {Cederman, D and Tsigas, P},
title = {{On dynamic load balancing on graphics processors}},
booktitle = {Proceedings of the 23rd ACM SIGGRAPH/EUROGRAPHICS symposium on Graphics hardware},
year = {2008},
pages = {57--64},
organization = {Eurographics Association Aire-la-Ville, Switzerland, Switzerland},
affiliation = {Eurographics Association Aire-la-Ville, Switzerland, Switzerland},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:15GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Cederman/On_dynamic_load_balancing_on_graphics_processors_2008_Cederman.pdf},
file = {{On_dynamic_load_balancing_on_graphics_processors_2008_Cederman.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Cederman/On_dynamic_load_balancing_on_graphics_processors_2008_Cederman.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/03A66F5C-00D8-479B-A1F1-8A26BB083C14}}
}

@article{Nomizu:2012ds,
author = {Nomizu, T and Takahashi, D and Lee, Jinpil and Boku, T and Sato, M},
title = {{Implementation of XcalableMP Device Acceleration Extention with OpenCL}},
journal = {International Parallel and Distributed Processing Symposium, Workshops and Phd Forum},
year = {2012},
pages = {2394--2403},
doi = {10.1109/IPDPSW.2012.296},
rating = {0},
date-added = {2014-07-06T21:13:44GMT},
date-modified = {2014-07-06T21:14:19GMT},
abstract = {Due to their outstanding computational performance, many acceleration devices, such as GPUs, the Cell Broadband Engine (Cell/B.E.), and multi-core computing are attracting a lot of attention in the field of high-performance computing. Although there are many programming models and languages de-signed for programming accelerators, such as CUDA, AMD Accelerated Parallel Processing (AMD APP), and OpenCL, these models remain difficult and complex. Furthermore, when programming for accelerator-enhanced clusters, we have to use an inter-node programming interface, such as MPI to coordinate the nodes. In order to address these problems and reduce complexity, an extension to XcalableMP (XMP), a PGAS language, for use on accelerator-enhanced clusters, called XcalableMP Device Acceleration Extension (XMP-dev), is proposed. In XMP-dev, a global distributed data is mapped onto distributed memory of each accelerator, and a fragment of codes can be of-floaded to execute in a set of accelerators. It eliminates the complex programming between nodes and accelerators and between nodes. In this paper, we present an implementation of the XMP-dev runtime library with the OpenCL APIs, while the previous implementation targets CUDA-only. Since OpenCL is a standardized interface supported for various kinds of accelerators, it improves the portability of XMP-dev and reduces the cost of development. In the result of performance evaluation, we show that the OpenCL implementation of XMP-dev can generate portable programs that can run on not only NVIDIA GPU-enhanced clusters but also various accelerator-enhanced clusters. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6270611&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28xcalablemp%29},
uri = {\url{papers2://publication/doi/10.1109/IPDPSW.2012.296}}
}

@inproceedings{Baghsorkhi2010ppopp,
author = {Baghsorkhi, Sara S and Delahaye, M and Patel, S and Gropp, W. and Hwu, W},
title = {{An adaptive performance monitoring tool for GPU architectures}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2010},
organization = {ACM},
publisher = {Conference},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:36:15GMT},
uri = {\url{papers2://publication/uuid/057B51EF-AB0D-4781-BB2A-3FA04A03E485}}
}

@article{flynn-computing1972,
author = {Flynn, Michael},
title = {{Some Computer Organizations and Their Effectiveness}},
journal = {IEEE Transactions on Computing},
year = {1972},
volume = {21},
number = {9},
pages = {948--960},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/9DE0A349-F178-480C-9B26-DD770EB5E2D6}}
}

@article{ati2009brook,
author = {ATI, B},
title = {{ATI Stream Computing User Guide}},
journal = {ATI, March},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/6EFF0D64-02CF-4F86-8A39-3D59E049C1FF}}
}

@inproceedings{Hamano:2009dq,
author = {Hamano, T and Endo, T and Matsuoka, S},
title = {{Power-aware dynamic task scheduling for heterogeneous accelerated clusters}},
crossref = {ipdps},
year = {2009},
pages = {1--8},
doi = {10.1109/IPDPS.2009.5160977},
rating = {0},
date-added = {2011-11-12T21:59:25GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {Recent accelerators such as GPUs achieve better cost-performance and watt-performance ratio, while the range of their application is more limited than general CPUs. Thus heterogeneous clusters and supercomputers equipped both with accelerators and general CPUs are becoming popular, such as LANL's Roadrunner and our own TSUBAME supercomputer. Under the assumption that many applications will run both on CPUs and accelerators but with varying speed and power consumption characteristics, we propose a task scheduling scheme that optimize overall energy consumption of the system. We model task scheduling in terms of the scheduling makespan and energy to be consumed for each scheduling decision. We define acceleration factor to normalize the effect of acceleration per each task. The proposed scheme attempts to improve energy efficiency by effectively adjusting the schedule based on the acceleration factor. Although in the paper we adopted the popular EDP (Energy-Delay Product) as the optimization metric, our scheme is agnostic on the optimization function. Simulation studies on various sets of tasks with mixed acceleration factors, the overall makespan closely matched the theoretical optimal, while the energy consumption was reduced up to 13.8\%.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5160977&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28power+aware+dynamic+task+scheduling+for+heterogeneous+accelerated+clusters%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Hamano/Power-aware_dynamic_task_scheduling_for_heterogeneous_accelerated_clusters_2009_Hamano.pdf},
file = {{Power-aware_dynamic_task_scheduling_for_heterogeneous_accelerated_clusters_2009_Hamano.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Hamano/Power-aware_dynamic_task_scheduling_for_heterogeneous_accelerated_clusters_2009_Hamano.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5160977}}
}

@inproceedings{Lee:2010hw,
author = {Lee, Victor W and Kim, Changkyu and Chhugani, Jatin and Deisher, Michael and Kim, Daehyun and Nguyen, Anthony D and Satish, Nadathur and Smelyanskiy, Mikhail and Chennupaty, Srinivas and Hammarlund, Per and Singhal, Ronak and Dubey, Pradeep},
title = {{Debunking the 100X GPU vs. CPU Myth: an Evaluation of Throughput Computing on CPU and GPU}},
booktitle = {ISCA '10: Proceedings of the 37th annual international symposium on Computer architecture},
year = {2010},
publisher = {ACM},
month = jun,
doi = {10.1145/1815961.1816021},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:59:54GMT},
date-modified = {2014-07-05T20:54:25GMT},
abstract = {Recent advances in computing have led to an explosion in the amount of data being generated. Processing the ever-growing data in a timely manner has made throughput computing an important aspect for emerging applications. Our analysis of a set of important},
url = {http://portal.acm.org/citation.cfm?id=1815961.1816021&coll=DL&dl=GUIDE&CFID=53317199&CFTOKEN=95945713},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Lee/Debunking_the_100X_GPU_vs._CPU_Myth_an_Evaluation_of_Throughput_Computing_on_CPU_and_GPU_2010_Lee-1.pdf},
file = {{Debunking_the_100X_GPU_vs._CPU_Myth_an_Evaluation_of_Throughput_Computing_on_CPU_and_GPU_2010_Lee-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Lee/Debunking_the_100X_GPU_vs._CPU_Myth_an_Evaluation_of_Throughput_Computing_on_CPU_and_GPU_2010_Lee-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1815961.1816021}}
}

@misc{top500,
title = {{TOP500 Supercomputer Sites}},
howpublished = {http://top500.org},
publisher = {http://top500.org},
rating = {0},
date-added = {2014-07-06T21:28:51GMT},
date-modified = {2014-07-06T21:29:26GMT},
uri = {\url{papers2://publication/uuid/CB069ADB-51AF-4D58-8565-FB934C99C8DB}}
}

@article{aji2008rsv,
author = {Aji, Ashwin M and Feng, Wu{-chun}},
title = {{Revisiting the Speed-versus-Sensitivity Tradeoff in Pairwise Sequence Search}},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:55:51GMT},
url = {http://eprints.cs.vt.edu/archive/00001023/},
uri = {\url{papers2://publication/uuid/7F053A35-8F64-4E9B-A2DF-EEA6CA71DB61}}
}

@inproceedings{armstrong-hpdc1999,
author = {Armstrong, Rob and Gannon, Dennis and Geist, Al and Keahey, Katarzyna and Kohn, Scott and McInnes, Lois and Parker, Steve and Smolinski, Brent},
title = {{Toward a Common Component Architecture for High-Performance Scientific Computing}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {1999},
pages = {13},
publisher = {IEEE Computer Society},
address = {Washington, DC, USA},
isbn = {0-7695-0287-3},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T17:42:14GMT},
uri = {\url{papers2://publication/uuid/01394D79-B24F-46CB-A908-15B3FADBFC35}}
}

@article{Aguilera:2007wz,
author = {Aguilera, MK and Merchant, A and Shah, M},
title = {{Sinfonia: a new paradigm for building scalable distributed systems}},
journal = {{\ldots} on Operating systems {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:48:35GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {ABSTRACT We propose a new paradigm for building scalable distributed sys- tems. Our approach does not require dealing with message-passing protocols---a major complication in existing distributed systems . Instead, developers just design and manipulate data structures within our ...},
url = {http://portal.acm.org/citation.cfm?id=1294278},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Aguilera/Sinfonia_a_new_paradigm_for_building_scalable_distributed_systems_2007_Aguilera.pdf},
file = {{Sinfonia_a_new_paradigm_for_building_scalable_distributed_systems_2007_Aguilera.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Aguilera/Sinfonia_a_new_paradigm_for_building_scalable_distributed_systems_2007_Aguilera.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/868A0516-5EF6-4A86-88C9-F977F932421F}}
}

@inproceedings{charles-oopsla2005,
author = {Charles, Philippe and Grothoff, Christian and Saraswat, Vijay and Donawa, Christopher and Kielstra, Allan and Ebcioglu, Kemal and von Praun, Christoph and Sarkar, Vivek},
title = {{X10: an object-oriented approach to non-uniform cluster computing}},
booktitle = {ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages, and Applications},
year = {2005},
pages = {519--538},
publisher = {ACM},
address = {New York, NY, USA},
doi = {http://doi.acm.org/10.1145/1094811.1094852},
isbn = {1-59593-031-0},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-07-05T20:36:25GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/1094811.1094852}}
}

@article{Karlin:2011:PMP:1964218.1964226,
author = {Karlin, Ian and Jessup, Elizabeth and Belter, Geoffrey and Siek, Jeremy G.},
title = {{Parallel memory prediction for fused linear algebra kernels}},
journal = {SIGMETRICS Perform. Eval. Rev.},
year = {2011},
volume = {38},
pages = {43--49},
month = mar,
address = {New York, NY, USA},
publisher = {ACM},
doi = {http://doi.acm.org/10.1145/1964218.1964226},
read = {Yes},
rating = {0},
date-added = {2011-11-13T03:24:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://doi.acm.org/10.1145/1964218.1964226},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Karlin/Parallel_memory_prediction_for_fused_linear_algebra_kernels_2011_Karlin.pdf},
file = {{Parallel_memory_prediction_for_fused_linear_algebra_kernels_2011_Karlin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Karlin/Parallel_memory_prediction_for_fused_linear_algebra_kernels_2011_Karlin.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/1964218.1964226}}
}

@article{Manavski2008,
author = {Manavski, Svetlin a and Valle, Giorgio},
title = {{CUDA compatible GPU cards as efficient hardware accelerators for Smith-Waterman sequence alignment.}},
journal = {BMC bioinformatics},
year = {2008},
volume = {9 Suppl 2},
number = {November},
pages = {S10},
doi = {10.1186/1471-2105-9-S2-S10},
pmid = {18387198},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:50GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {BACKGROUND: Searching for similarities in protein and DNA databases has become a routine procedure in Molecular Biology. The Smith-Waterman algorithm has been available for more than 25 years. It is based on a dynamic programming approach that explores all the possible alignments between two sequences; as a result it returns the optimal local alignment. Unfortunately, the computational cost is very high, requiring a number of operations proportional to the product of the length of two sequences. Furthermore, the exponential growth of protein and DNA databases makes the Smith-Waterman algorithm unrealistic for searching similarities in large sets of sequences. For these reasons heuristic approaches such as those implemented in FASTA and BLAST tend to be preferred, allowing faster execution times at the cost of reduced sensitivity. The main motivation of our work is to exploit the huge computational power of commonly available graphic cards, to develop high performance solutions for sequence alignment. RESULTS: In this paper we present what we believe is the fastest solution of the exact Smith-Waterman algorithm running on commodity hardware. It is implemented in the recently released CUDA programming environment by NVidia. CUDA allows direct access to the hardware primitives of the last-generation Graphics Processing Units (GPU) G80. Speeds of more than 3.5 GCUPS (Giga Cell Updates Per Second) are achieved on a workstation running two GeForce 8800 GTX. Exhaustive tests have been done to compare our implementation to SSEARCH and BLAST, running on a 3 GHz Intel Pentium IV processor. Our solution was also compared to a recently published GPU implementation and to a Single Instruction Multiple Data (SIMD) solution. These tests show that our implementation performs from 2 to 30 times faster than any other previous attempt available on commodity hardware. CONCLUSIONS: The results show that graphic cards are now sufficiently advanced to be used as efficient hardware accelerators for sequence alignment. Their performance is better than any alternative available on commodity hardware platforms. The solution presented in this paper allows large scale alignments to be performed at low cost, using the exact Smith-Waterman algorithm instead of the largely adopted heuristic approaches.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18387198},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Manavski/CUDA_compatible_GPU_cards_as_efficient_hardware_accelerators_for_Smith-Waterman_sequence_alignment._2008_Manavski.pdf},
file = {{CUDA_compatible_GPU_cards_as_efficient_hardware_accelerators_for_Smith-Waterman_sequence_alignment._2008_Manavski.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Manavski/CUDA_compatible_GPU_cards_as_efficient_hardware_accelerators_for_Smith-Waterman_sequence_alignment._2008_Manavski.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1186/1471-2105-9-S2-S10}}
}

@article{Che:2010if,
author = {Che, Shuai and Sheaffer, J W and Boyer, Michael and Szafaryn, L.G and Wang, Liang and Skadron, K},
title = {{A characterization of the Rodinia benchmark suite with comparison to contemporary CMP workloads}},
journal = {Workload Characterization (IISWC), 2010 IEEE International Symposium on},
year = {2010},
pages = {1--11},
doi = {10.1109/IISWC.2010.5650274},
read = {Yes},
rating = {0},
date-added = {2011-11-23T03:57:14GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {The recently released Rodinia benchmark suite enables users to evaluate heterogeneous systems including both accelerators, such as GPUs, and multicore CPUs. As Rodinia sees higher levels of acceptance, it becomes important that researchers understand this new set of benchmarks, especially in how they differ from previous work. In this paper, we present recent extensions to Rodinia and conduct a detailed characterization of the Rodinia benchmarks (including performance results on an NVIDIA GeForce GTX480, the first product released based on the Fermi architecture). We also compare and contrast Rodinia with Parsec to gain insights into the similarities and differences of the two benchmark collections; we apply principal component analysis to analyze the application space coverage of the two suites. Our analysis shows that many of the workloads in Rodinia and Parsec are complementary, capturing different aspects of certain performance metrics.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5650274&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28rodinia%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Che/A_characterization_of_the_Rodinia_benchmark_suite_with_comparison_to_contemporary_CMP_workloads_2010_Che.pdf},
file = {{A_characterization_of_the_Rodinia_benchmark_suite_with_comparison_to_contemporary_CMP_workloads_2010_Che.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Che/A_characterization_of_the_Rodinia_benchmark_suite_with_comparison_to_contemporary_CMP_workloads_2010_Che.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IISWC.2010.5650274}}
}

@inproceedings{curtis-maury-qest2005,
author = {Curtis-Maury, M and Wang, T and Antonopoulos, C and Nikolopoulos, D},
title = {{Integrating Multiple Forms of Multithreaded Execution on SMT Processors: A Quantitative Study with Scientific Workloads}},
booktitle = {Proc.$\backslash$ of the Second International Conference on the Quantitative Evaluation of Systems (QEST'2005)},
year = {2005},
pages = {199--208},
address = {Torino, Italy},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:14GMT},
uri = {\url{papers2://publication/uuid/1E482FCE-2BB9-48F1-89A8-9DE90FB76C62}}
}

@article{Che:2009bc,
author = {Che, Shuai and Boyer, Michael and Meng, Jiayuan and Tarjan, D and Sheaffer, J W and Lee, Sang-Ha and Skadron, K},
title = {{Rodinia: A benchmark suite for heterogeneous computing}},
journal = {Workload Characterization, 2009. IISWC 2009. IEEE International Symposium on},
year = {2009},
pages = {44--54},
doi = {10.1109/IISWC.2009.5306797},
read = {Yes},
rating = {0},
date-added = {2011-11-23T03:57:05GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {This paper presents and characterizes Rodinia, a benchmark suite for heterogeneous computing. To help architects study emerging platforms such as GPUs (Graphics Processing Units), Rodinia includes applications and kernels which target multi-core CPU and GPU platforms. The choice of applications is inspired by Berkeley's dwarf taxonomy. Our characterization shows that the Rodinia benchmarks cover a wide range of parallel communication patterns, synchronization techniques and power consumption, and has led to some important architectural insight, such as the growing importance of memory-bandwidth limitations and the consequent importance of data layout.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5306797&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28rodinia%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Che/Rodinia_A_benchmark_suite_for_heterogeneous_computing_2009_Che.pdf},
file = {{Rodinia_A_benchmark_suite_for_heterogeneous_computing_2009_Che.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Che/Rodinia_A_benchmark_suite_for_heterogeneous_computing_2009_Che.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IISWC.2009.5306797}}
}

@inproceedings{amdahl-afips1967,
author = {Amdahl, Gene M},
title = {{The Validity of the Single Processor Approach to Achieving Large-scale Computing Capabilities}},
booktitle = {AFIPS Conference Proceedings},
year = {1967},
pages = {483--485},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1967/Amdahl/The_Validity_of_the_Single_Processor_Approach_to_Achieving_Large-scale_Computing_Capabilities_1967_Amdahl.pdf},
file = {{The_Validity_of_the_Single_Processor_Approach_to_Achieving_Large-scale_Computing_Capabilities_1967_Amdahl.pdf:/Users/njustn/Dropbox/Papers2/Articles/1967/Amdahl/The_Validity_of_the_Single_Processor_Approach_to_Achieving_Large-scale_Computing_Capabilities_1967_Amdahl.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C35D78D1-BA73-4E83-9C5A-F29336846B72}}
}

@book{Davidson:2012dh,
author = {Davidson, Andrew and Owens, John},
editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M and Mattern, Friedemann and Mitchell, John C and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y and Weikum, Gerhard and J{\'o}nasson, Kristj{\'a}n},
title = {{Lecture Notes in Computer Science}},
publisher = {Springer Berlin Heidelberg},
year = {2012},
volume = {7134},
series = {DavidHutchisonTakeoKanadeJosefKittlerJon M.KleinbergFriedemannMatternJohn C.MitchellMoniNaorOscarNierstraszC.Pandu RanganBernhardSteffenMadhuSudanDemetriTerzopoulosDougTygarMoshe Y.VardiGerhardWeikumLecture Notes in Computer Science0302-97431611-3349},
address = {Berlin, Heidelberg},
edition = {Springer Berlin Heidelberg},
doi = {10.1007/978-3-642-28145-7_11},
isbn = {978-3-642-28144-0},
rating = {0},
date-added = {2012-03-27T20:30:12GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {We introduce a variety of techniques toward autotuning data-parallel algorithms on the GPU . Our techniques tune these algorithms independent of hardware architecture, and attempt to select near-optimum parameters. We work towards a general framework for creating auto - ... 
},
url = {http://www.springerlink.com/index/10.1007/978-3-642-28145-7_11},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2012/Davidson/Lecture_Notes_in_Computer_Science_2012_Davidson.pdf},
file = {{Lecture_Notes_in_Computer_Science_2012_Davidson.pdf:/Users/njustn/Dropbox/Papers2/Books/2012/Davidson/Lecture_Notes_in_Computer_Science_2012_Davidson.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-28145-7_11}}
}

@article{halstead1985,
author = {Halstead, R H},
title = {{MULTILISP: a language for concurrent symbolic computation}},
journal = {ACM Transactions on Programming Languages and Systems},
year = {1985},
volume = {7},
number = {4},
pages = {501--538},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/9C8BA31D-F9F8-4BB7-AB9C-BF8A6D1976E0}}
}

@inproceedings{Pienaar:2011kp,
author = {Pienaar, Jacques A and Raghunathan, Anand and Chakradhar, Srimat},
title = {{MDR: performance model driven runtime for heterogeneous parallel platforms}},
booktitle = {ACM International Conference on Supercomputing},
year = {2011},
publisher = {ACM},
month = may,
doi = {10.1145/1995896.1995933},
read = {Yes},
rating = {0},
date-added = {2012-09-08T10:50:46GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {We present a runtime framework for the execution of work-loads represented as parallel-operator directed acyclic graphs (PO-DAGs) on heterogeneous multi-core platforms. PO-DAGs combine coarse-grained parallelism at the graph level with fine-grained parallelism},
url = {http://portal.acm.org/citation.cfm?id=1995896.1995933&coll=DL&dl=GUIDE&CFID=153870936&CFTOKEN=46265051},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Pienaar/MDR_performance_model_driven_runtime_for_heterogeneous_parallel_platforms_2011_Pienaar.pdf},
file = {{MDR_performance_model_driven_runtime_for_heterogeneous_parallel_platforms_2011_Pienaar.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Pienaar/MDR_performance_model_driven_runtime_for_heterogeneous_parallel_platforms_2011_Pienaar.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1995896.1995933}}
}

@inproceedings{Fang:2007dg,
author = {Fang, Rui and He, Bingsheng and Lu, Mian and Yang, Ke and Govindaraju, Naga K and Luo, Qiong and Sander, Pedro V},
title = {{GPUQP: query co-processing using graphics processors}},
booktitle = {SIGMOD '07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data},
year = {2007},
publisher = {ACM},
month = jun,
doi = {10.1145/1247480.1247606},
rating = {0},
date-added = {2011-11-12T22:02:50GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {We present GPUQP, a relational query engine that employs both CPUs and GPUs (Graphics Processing Units) for in-memory query co-processing. GPUs are commodity processors traditionally designed for graphics applications. Recent research has shown that},
url = {http://portal.acm.org/citation.cfm?id=1247606},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Fang/GPUQP_query_co-processing_using_graphics_processors_2007_Fang.pdf},
file = {{GPUQP_query_co-processing_using_graphics_processors_2007_Fang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Fang/GPUQP_query_co-processing_using_graphics_processors_2007_Fang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1247480.1247606}}
}

@book{fowler-1999,
author = {Fowler, Martin},
title = {{Refactoring: Improving the Design of Existing Code}},
publisher = {Addison-Wesley},
year = {1999},
address = {Boston, MA, USA},
isbn = {0-201-48567-2},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/uuid/2AD3AFA6-8806-4E2E-9A2D-CD873B92AEBC}}
}

@inproceedings{barrett2007mas,
author = {Barrett, C L and Bisset, K and Eubank, S and Marathe, M V and Kumar, V S A and Mortveit, H S},
title = {{Modeling and simulation of large biological, information and socio-technical systems: An interaction-based approach}},
booktitle = {PROCEEDINGS OF SYMPOSIA IN APPLIED MATHEMATICS},
year = {2007},
pages = {101},
organization = {Springer},
affiliation = {Springer},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://www.springerlink.com/index/v103u4185k703457.pdf},
uri = {\url{papers2://publication/uuid/25E1B85B-97EA-4687-A5E2-1FDCDB175EFD}}
}

@article{Timm:2010vd,
author = {Timm, C and Gelenberg, A and Weichert, F},
title = {{Reducing the Energy Consumption of Embedded Systems by Integrating General Purpose GPUs}},
year = {2010},
rating = {0},
date-added = {2011-11-12T22:02:50GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Technische Universit{\"a}t Dortmund --- Fakult{\"a}t f{\"u}r Informatik Otto-Hahn-Str. 16, 44227 Dortmund ... Constantin Timm, Andrej Gelenberg, Peter Marwedel,Frank Weichert: Reducing the Energy Consumption of Embedded Systems by Integrating General Purpose GPUs , Technical ...},
url = {http://ls12-www.cs.tu-dortmund.de/publications/papers/2010-timmTR829.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Timm/Reducing_the_Energy_Consumption_of_Embedded_Systems_by_Integrating_General_Purpose_GPUs_2010_Timm.pdf},
file = {{Reducing_the_Energy_Consumption_of_Embedded_Systems_by_Integrating_General_Purpose_GPUs_2010_Timm.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Timm/Reducing_the_Energy_Consumption_of_Embedded_Systems_by_Integrating_General_Purpose_GPUs_2010_Timm.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/D4EBC8FE-1B01-4E61-B57E-80515B0C50FE}}
}

@article{Altschul97,
author = {Altschul, S and Madden, T.\~{}L. and Schaffer, A.\~{}A. and Zhang, J and Zhang, Z and Miller, W and Lipman, D.\~{}J.},
title = {{Gapped BLAST and PSIBLAST: A New Generation of Protein Database Search Programs}},
journal = {Nucleic Acids Research},
year = {1997},
volume = {25},
pages = {3389--3402},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/uuid/0E7ED632-5F6A-459D-8DFC-2F83E603E5FB}}
}

@inproceedings{Bozdag:2009js,
author = {Bozda{\u g}, Doruk and Barbacioru, C.C and Catalyurek, U.V},
title = {{Parallel short sequence mapping for high throughput genome sequencing}},
crossref = {ipdps},
year = {2009},
pages = {1--10},
doi = {10.1109/IPDPS.2009.5161075},
read = {Yes},
rating = {0},
date-added = {2011-11-12T22:02:50GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {With the advent of next-generation high throughput sequencing instruments, large volumes of short sequence data are generated at an unprecedented rate. Processing and analyzing these massive data requires overcoming several challenges including mapping of generated short sequences to a reference genome. This computationally intensive process takes time on the order of days using existing sequential techniques on large scale datasets. In this work, we propose six parallelization methods to speedup short sequence mapping and to reduce the execution time under just a few hours for such large datasets. We comparatively present these methods and give theoretical cost models for each method. Experimental results on real datasets demonstrate the effectiveness of the parallel methods and indicate that the cost models help accurate estimation of parallel execution time. Based on these cost models we implemented a selection function to predict the best method for a given scenario. To the best of our knowledge this is the first study on parallelization of short sequence mapping problem.},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/IPDPS.2009.5161075},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Bozda%C4%9F/Parallel_short_sequence_mapping_for_high_throughput_genome_sequencing_2009_Bozda%C4%9F.pdf},
file = {{Parallel_short_sequence_mapping_for_high_throughput_genome_sequencing_2009_Bozda.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Bozda/Parallel_short_sequence_mapping_for_high_throughput_genome_sequencing_2009_Bozda.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5161075}}
}

@inproceedings{bolz2003sparse,
author = {Bolz, J and Farmer, I and Grinspun, E and Schr backslash backslash ooder, P},
title = {{Sparse matrix solvers on the GPU: conjugate gradients and multigrid}},
booktitle = {ACM SIGGRAPH 2003 Papers},
year = {2003},
pages = {924},
organization = {ACM},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/1D36AE1D-765E-4F52-8024-B7841C0A0899}}
}

@article{Liu:2006tv,
author = {Liu, Y and Huang, W and Johnson, J},
title = {{Gpu accelerated smith-waterman}},
journal = {Computational Science--ICCS {\ldots}},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:10:03GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Sequence comparison [1] is a fundamental tool for genome scientists to infer biological relationships from large databases of related DNA and proteins se- quences. This task cannot be adequately solved by traditional string matching methods because genomic sequences that share the ...},
url = {http://www.springerlink.com/index/W3727H42513362XN.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Liu/Gpu_accelerated_smith-waterman_2006_Liu.pdf},
file = {{Gpu_accelerated_smith-waterman_2006_Liu.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Liu/Gpu_accelerated_smith-waterman_2006_Liu.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/21C99406-D422-41C9-914F-D10451AE92AE}}
}

@article{lefohn2006glift,
author = {Lefohn, A E and Sengupta, S and Kniss, J and Strzodka, R and Owens, J D},
title = {{Glift: Generic, efficient, random-access GPU data structures}},
journal = {ACM Transactions on Graphics},
year = {2006},
volume = {25},
number = {1},
pages = {60--99},
publisher = {ACM New York, NY, USA},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T18:30:53GMT},
uri = {\url{papers2://publication/uuid/3F19A4D8-9DD6-40D7-ABD7-EA59EB3795E7}}
}

@inproceedings{Nordstrom:2012wq,
author = {Nordstr{\"o}m, Erik and Shue, David and Gopalan, Prem and Kiefer, Robert and Arye, Matvey and Ko, Steven Y and Rexford, Jennifer and Freedman, Michael J},
title = {{Serval: an end-host stack for service-centric networking}},
booktitle = {NSDI'12: Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation},
year = {2012},
publisher = { USENIX Association},
month = apr,
read = {Yes},
rating = {0},
date-added = {2012-09-16T04:55:40GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Internet services run on multiple servers in different locations, serving clients that are often mobile and multihomed. This does not match well with today's network stack, designed for communication between fixed hosts with topology-dependent addresses},
url = {http://portal.acm.org/citation.cfm?id=2228298.2228308&coll=DL&dl=GUIDE&CFID=115675960&CFTOKEN=34189237},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Nordstr%C3%B6m/Serval_an_end-host_stack_for_service-centric_networking_2012_Nordstr%C3%B6m.pdf},
file = {{Serval_an_end-host_stack_for_service-centric_networking_2012_Nordstrm.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Nordstrm/Serval_an_end-host_stack_for_service-centric_networking_2012_Nordstrm.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E135364D-265D-4F44-939E-BBD0EF06A178}}
}

@article{petit2007hybrid,
author = {Petit, E and Bodin, F and Dolbeau, R},
title = {{An Hybrid Data Transfer Optimization Technique for GPGPU}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/23F49DA8-0AAF-491F-9556-8E26E00816B5}}
}

@article{Spinczyk-kbs2007,
author = {Spinczyk, Olaf and Lohmann, Daniel},
title = {{The design and implementation of AspectC++}},
journal = {Knowledge-Based Systems},
year = {2007},
volume = {20},
number = {7},
pages = {636--651},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/D4610EB1-A253-4447-BA1D-0C84EC292D8B}}
}

@article{Weber:2011bt,
author = {Weber, R and Gothandaraman, A and Hinde, R.J and Peterson, G.D},
title = {{Comparing Hardware Accelerators in Scientific Applications: A Case Study}},
journal = {Parallel and Distributed Systems, IEEE Transactions on},
year = {2011},
volume = {22},
number = {1},
pages = {58--68},
doi = {10.1109/TPDS.2010.125},
rating = {0},
date-added = {2011-11-28T21:16:40GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {Multicore processors and a variety of accelerators have allowed scientific applications to scale to larger problem sizes. We present a performance, design methodology, platform, and architectural comparison of several application accelerators executing a Quantum Monte Carlo application. We compare the application's performance and programmability on a variety of platforms including CUDA with Nvidia GPUs, Brook+ with ATI graphics accelerators, OpenCL running on both multicore and graphics processors, C++ running on multicore processors, and a VHDL implementation running on a Xilinx FPGA. We show that OpenCL provides application portability between multicore processors and GPUs, but may incur a performance cost. Furthermore, we illustrate that graphics accelerators can make simulations involving large numbers of particles feasible.},
url = {http://ieeexplore.ieee.org/search/freesrchabstract.jsp?tp=&arnumber=5482576},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Weber/Comparing_Hardware_Accelerators_in_Scientific_Applications_A_Case_Study_2011_Weber.pdf},
file = {{Comparing_Hardware_Accelerators_in_Scientific_Applications_A_Case_Study_2011_Weber.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Weber/Comparing_Hardware_Accelerators_in_Scientific_Applications_A_Case_Study_2011_Weber.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/TPDS.2010.125}}
}

@inproceedings{huang-ccgrid09-energy,
author = {Huang, Song and Feng, Wu{-chun}},
title = {{Energy-Efficient Cluster Computing via Accurate Workload Characterization}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2009},
pages = {68--75},
publisher = {IEEE Computer Society},
address = {Shanghai, China},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T20:14:14GMT},
url = {http://portal.acm.org/citation.cfm?id=1577849.1577887},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Huang/Energy-Efficient_Cluster_Computing_via_Accurate_Workload_Characterization_2009_Huang.pdf},
file = {{Energy-Efficient_Cluster_Computing_via_Accurate_Workload_Characterization_2009_Huang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Huang/Energy-Efficient_Cluster_Computing_via_Accurate_Workload_Characterization_2009_Huang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/9FB863EB-CE07-48A6-BC50-F5F146E074B6}}
}

@inproceedings{Bauer:2011fl,
author = {Bauer, Michael and Cook, Henry and Khailany, Brucek},
title = {{CudaDMA: optimizing GPU memory bandwidth via warp specialization}},
crossref = {supercomputing},
year = {2011},
publisher = {ACM},
month = nov,
doi = {10.1145/2063384.2063400},
rating = {0},
date-added = {2011-12-09T21:11:33GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {As the computational power of GPUs continues to scale with Moore's Law, an increasing number of applications are becoming limited by memory bandwidth. We propose an approach for programming GPUs with tightly-coupled specialized DMA warps for performing},
url = {http://portal.acm.org/citation.cfm?id=2063384.2063400&coll=DL&dl=GUIDE&CFID=72572659&CFTOKEN=38207039},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Bauer/CudaDMA_optimizing_GPU_memory_bandwidth_via_warp_specialization_2011_Bauer.pdf},
file = {{CudaDMA_optimizing_GPU_memory_bandwidth_via_warp_specialization_2011_Bauer.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Bauer/CudaDMA_optimizing_GPU_memory_bandwidth_via_warp_specialization_2011_Bauer.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2063384.2063400}}
}

@inproceedings{hochstein-sc2005,
author = {Hochstein, L and Carver, J and Shull, F and Asgari, S and Basili, Victor R and Hollingsworth, J K and Zelkowitz, M},
title = {{\HPC\ Programmer Productivity: A Case Study of Novice \HPC\ Programmers}},
crossref = {supercomputing},
year = {2005},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/617FB855-8914-4D8D-94EE-D85294505089}}
}

@inproceedings{Zheng:2011jd,
author = {Zheng, Mai and Ravi, Vignesh T and Qin, Feng and Agrawal, Gagan},
title = {{GRace: a low-overhead mechanism for detecting data races in GPU programs}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2011},
publisher = {ACM},
month = feb,
doi = {10.1145/1941553.1941574},
read = {Yes},
rating = {0},
date-added = {2014-03-21T12:08:59GMT},
date-modified = {2014-07-05T17:36:15GMT},
abstract = {In recent years, GPUs have emerged as an extremely cost-effective means for achieving high performance. Many application developers, including those with no prior parallel programming experience, are now trying to scale their applications using GPUs},
url = {http://portal.acm.org/citation.cfm?id=1941553.1941574&coll=DL&dl=GUIDE&CFID=425101185&CFTOKEN=11238371},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Zheng/GRace_a_low-overhead_mechanism_for_detecting_data_races_in_GPU_programs_2011_Zheng.pdf},
file = {{GRace_a_low-overhead_mechanism_for_detecting_data_races_in_GPU_programs_2011_Zheng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Zheng/GRace_a_low-overhead_mechanism_for_detecting_data_races_in_GPU_programs_2011_Zheng.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1941553.1941574}}
}

@article{che2008performance,
author = {Che, S and Boyer, Michael and Meng, J and Tarjan, D and Sheaffer, J W and Skadron, K},
title = {{A performance study of general-purpose applications on graphics processors using CUDA}},
journal = {Journal of parallel and Distributed Computing},
year = {2008},
volume = {68},
number = {10},
pages = {1370--1380},
publisher = {Elsevier},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-04-23T18:03:57GMT},
uri = {\url{papers2://publication/uuid/201EB068-E9CF-45A8-8B12-18DC3B09B482}}
}

@article{Weber:2012kl,
author = {Weber, R and Peterson, G.D},
title = {{A Trip to Tahiti: Approaching a 5 TFlop SGEMM Using 3 AMD GPUs}},
journal = {Application Accelerators in High Performance Computing (SAAHPC), 2012 Symposium on},
year = {2012},
pages = {19--25},
publisher = { IEEE Computer Society},
keywords = {To Read},
doi = {10.1109/SAAHPC.2012.19},
read = {Yes},
rating = {0},
date-added = {2014-04-05T18:14:36GMT},
date-modified = {2014-04-10T14:34:49GMT},
abstract = {Using GPUs as computational accelerators has been a growing area of research in the past several years. One particular area amenable to exploiting video card hardware is dense linear algebra. We continue this trend by generalizing the MAGMA xGEMM kernels, porting them to OpenCL and tuning them to run on the AMD 7970. Achieving up to 1.7 TFlops in SGEMM and 650 GFlops in DGEMM, we extend this performance to multiple GPUs using a parallel-for algorithm designed to run on multiple heterogeneous devices. Using 3 Radeon 7970s, our large GEMM algorithm obtains 4.37TFlops in single precision and 1.64 TFlops/s in double. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6319187&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22A+Trip+to+Tahiti%3A+Approaching+a+5+TFlop+SGEMM+Using+3+AMD+GPUs%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Weber/A_Trip_to_Tahiti_Approaching_a_5_TFlop_SGEMM_Using_3_AMD_GPUs_2012_Weber.pdf},
file = {{A_Trip_to_Tahiti_Approaching_a_5_TFlop_SGEMM_Using_3_AMD_GPUs_2012_Weber.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Weber/A_Trip_to_Tahiti_Approaching_a_5_TFlop_SGEMM_Using_3_AMD_GPUs_2012_Weber.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SAAHPC.2012.19}}
}

@article{chamberlain-hpca2007,
author = {Chamberlain, B L and Callahan, D and Zima, H P},
title = {{Parallel Programmability and the Chapel Language}},
journal = {International Journal of High Performance Computing Applications},
year = {2007},
volume = {21},
number = {3},
pages = {291--312},
address = {Thousand Oaks, CA, USA},
publisher = {Sage Publications, Inc.},
doi = {http://dx.doi.org/10.1177/1094342007078442},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-04-17T19:16:38GMT},
uri = {\url{papers2://publication/doi/http://dx.doi.org/10.1177/1094342007078442}}
}

@inproceedings{Taylor:2010gy,
author = {Taylor, R and Li, Xiaoming},
title = {{A Micro-benchmark Suite for AMD GPUs}},
booktitle = { International Conference on Parallel Processing, Workshops (ICPPW)},
year = {2010},
pages = {387--396},
doi = {10.1109/ICPPW.2010.59},
read = {Yes},
rating = {0},
date-added = {2012-10-02T14:18:14GMT},
date-modified = {2014-07-05T17:46:40GMT},
abstract = {Optimizing programs for Graphic Processing Unit (GPU) requires thorough knowledge about the values of architectural features for the new computing platform. However, this knowledge is frequently unavailable, e.g., due to insufficient documentation, which is probably a result of the infancy of general purpose computing on the GPU. What makes the modeling of program performance on GPU even more difficult is that the exact value of some ``architectural'' parameters on the GPU depends on how a GPU program interacts with those features. For example, AMD GPUs show different memory latencies when the memory is accessed with address sequences that have different patterns. Current micro-benchmark suites such as X-Ray are powerless for characterizing the GPU. Clearly, a preliminary for efficient code optimization and automatic tuning on the GPU is a systematic method to measure the architectural features and identify the most basic program characteristics that determine the performance of a program on the new GPU architectures. In this paper, we present a micro-benchmark suite for AMD GPUs that supports the AMD StreamSDK. Our model identifies and measures a series of architectural features and basic program characteristics that are most important and most predictive for program performance on the platform. The features and characteristics include vectorization, burst write latency, texture fetch latency, global read and write latency, ALU/Fetch operation ratio, domain size and register usage for both AMD's pixel shader and compute shader modes. Our performance model not only generates correct values for those parameters, but also provides a clear picture of program performance on the GPU. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5599097&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22micro+benchmark+suite%22+AND+amd%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Taylor/A_Micro-benchmark_Suite_for_AMD_GPUs_2010_Taylor.pdf},
file = {{A_Micro-benchmark_Suite_for_AMD_GPUs_2010_Taylor.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Taylor/A_Micro-benchmark_Suite_for_AMD_GPUs_2010_Taylor.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPPW.2010.59}}
}

@article{Lieberman-Aiden2009,
author = {Lieberman-Aiden, Erez and van Berkum, Nynke L and Williams, Louise and Imakaev, Maxim and Ragoczy, Tobias and Telling, Agnes and Amit, Ido and Lajoie, Bryan R and Sabo, Peter J and Dorschner, Michael O and Sandstrom, Richard and Bernstein, Bradley and Bender, M a and Groudine, Mark and Gnirke, Andreas and Stamatoyannopoulos, John and Mirny, Leonid a and Lander, Eric S and Dekker, Job},
title = {{Comprehensive mapping of long-range interactions reveals folding principles of the human genome.}},
journal = {Science (New York, N.Y.)},
year = {2009},
volume = {326},
number = {5950},
pages = {289--293},
doi = {10.1126/science.1181369},
pmid = {19815776},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {We describe Hi-C, a method that probes the three-dimensional architecture of whole genomes by coupling proximity-based ligation with massively parallel sequencing. We constructed spatial proximity maps of the human genome with Hi-C at a resolution of 1 megabase. These maps confirm the presence of chromosome territories and the spatial proximity of small, gene-rich chromosomes. We identified an additional level of genome organization that is characterized by the spatial segregation of open and closed chromatin to form two genome-wide compartments. At the megabase scale, the chromatin conformation is consistent with a fractal globule, a knot-free, polymer conformation that enables maximally dense packing while preserving the ability to easily fold and unfold any genomic locus. The fractal globule is distinct from the more commonly used globular equilibrium model. Our results demonstrate the power of Hi-C to map the dynamic conformations of whole genomes.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19815776},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Lieberman-Aiden/Comprehensive_mapping_of_long-range_interactions_reveals_folding_principles_of_the_human_genome._2009_Lieberman-Aiden.pdf},
file = {{Comprehensive_mapping_of_long-range_interactions_reveals_folding_principles_of_the_human_genome._2009_Lieberman-Aiden.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Lieberman-Aiden/Comprehensive_mapping_of_long-range_interactions_reveals_folding_principles_of_the_human_genome._2009_Lieberman-Aiden.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1126/science.1181369}}
}

@inproceedings{fc-queue,
author = {Hendler, Danny and Incze, Itai and Shavit, Nir and Tzafrir, Moran},
title = {{Flat combining and the synchronization-parallelism tradeoff}},
booktitle = {ACM Symposium on Parallelism in Algorithms and Architectures},
year = {2010},
publisher = {ACM},
month = jun,
annote = {similar to my blocking queue, but still using CAS{\ldots} no idea why},
keywords = {Important},
doi = {10.1145/1810479.1810540},
read = {Yes},
rating = {0},
date-added = {2013-07-21T17:51:20GMT},
date-modified = {2014-07-05T17:45:25GMT},
abstract = {Traditional data structure designs, whether lock-based or lock-free, provide parallelism via fine grained synchronization among threads. We introduce a new synchronization paradigm based on coarse locking, which we call flat combining. The cost},
url = {http://portal.acm.org/citation.cfm?id=1810479.1810540&coll=DL&dl=ACM&CFID=235641177&CFTOKEN=70799411},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Hendler/Flat_combining_and_the_synchronization-parallelism_tradeoff_2010_Hendler.pdf},
file = {{Flat_combining_and_the_synchronization-parallelism_tradeoff_2010_Hendler.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Hendler/Flat_combining_and_the_synchronization-parallelism_tradeoff_2010_Hendler.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1810479.1810540}}
}

@inproceedings{adaptive-udp,
author = {Eckart, B and He, Xubin and Wu, Qishi},
title = {{Performance adaptive UDP for high-speed bulk data transfer over dedicated links}},
crossref = {ipdps},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:43:45GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Eckart/Performance_adaptive_UDP_for_high-speed_bulk_data_transfer_over_dedicated_links_2008_Eckart.pdf},
file = {{Performance_adaptive_UDP_for_high-speed_bulk_data_transfer_over_dedicated_links_2008_Eckart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Eckart/Performance_adaptive_UDP_for_high-speed_bulk_data_transfer_over_dedicated_links_2008_Eckart.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CD92BFDD-E512-44AD-A31B-619E4B55F8A2}}
}

@inproceedings{kirsch-k-fifo,
author = {Kirsch, Christoph M and Lippautz, Michael and Payer, Hannes},
title = {{Fast and Scalable, Lock-free k-FIFO Queues}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
read = {Yes},
rating = {0},
date-added = {2013-07-21T18:20:02GMT},
date-modified = {2014-07-05T17:37:18GMT},
url = {http://cs.uni-salzburg.at/~hpayer/publications/pact13.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Kirsch/Fast_and_Scalable_Lock-free_k-FIFO_Queues__Kirsch.pdf},
file = {{Fast_and_Scalable_Lock-free_k-FIFO_Queues__Kirsch.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Kirsch/Fast_and_Scalable_Lock-free_k-FIFO_Queues__Kirsch.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E5D27D5F-7008-48C5-961A-6F7E55DA194B}}
}

@article{parnas-tse1976,
author = {Parnas, D L},
title = {{On the Design and Development of Program Families}},
journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
year = {1976},
volume = {2},
number = {1},
pages = {1--9},
address = {Piscataway, NJ, USA},
publisher = {IEEE Press},
doi = {http://dx.doi.org/10.1109/TSE.1976.233797},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/doi/http://dx.doi.org/10.1109/TSE.1976.233797}}
}

@inproceedings{darling-cwce2002-mpiblast,
author = {Darling, Aaron E and Carey, Lucas and Feng, Wu{-chun}},
title = {{The Design, Implementation, and Evaluation of mpiBLAST}},
booktitle = {International Conference on Linux Clusters: The HPC Revolution 2003},
year = {2003},
address = {San Jose, California},
month = jun,
annote = {Best Paper: Applications Track},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/E281FD39-153E-4A8A-8AA5-924A3AC6DC48}}
}

@article{Stuart:2011ux,
author = {Stuart, J and Cox, M},
title = {{GPU-to-CPU callbacks}},
journal = {Euro-Par 2010 Parallel Processing Workshops},
year = {2011},
rating = {0},
date-added = {2012-03-27T20:31:31GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {We present GPU -to- CPU callbacks , a new mechanism and abstraction for GPUs that offers them more independence in a heterogeneous computing environment. Specifically, we provide a method for GPUs to issue callback requests to the CPU . These requests serve ... 
},
url = {http://www.springerlink.com/index/12087WQH75135184.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Stuart/GPU-to-CPU_callbacks_2011_Stuart.pdf},
file = {{GPU-to-CPU_callbacks_2011_Stuart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Stuart/GPU-to-CPU_callbacks_2011_Stuart.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E6ECE8E2-8ADF-4778-98E7-101B56D946ED}}
}

@inproceedings{silberstein2008efficient,
author = {Silberstein, M and Schuster, A and Geiger, D and Patney, A and Owens, J D},
title = {{Efficient computation of sum-products on GPUs through software-managed cache}},
booktitle = {ACM International Conference on Supercomputing},
year = {2008},
pages = {309--318},
organization = {ACM},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:44:21GMT},
uri = {\url{papers2://publication/uuid/4F0B847D-13CF-493B-BF55-505C8291CD5D}}
}

@article{Donfack:wj,
author = {Donfack, Simplice and Tomov, Stanimire and Dongarra, Jack},
title = {{Dynamically balanced synchronization-avoiding LU factorization with multicore and GPUs}},
keywords = {To Read},
read = {Yes},
rating = {0},
date-added = {2014-04-05T18:28:00GMT},
date-modified = {2014-04-10T14:34:49GMT},
url = {ftp://160.36.56.208/pub/TechReports/2013/ut-cs-13-713.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Donfack/Dynamically_balanced_synchronization-avoiding_LU_factorization_with_multicore_and_GPUs__Donfack.pdf},
file = {{Dynamically_balanced_synchronization-avoiding_LU_factorization_with_multicore_and_GPUs__Donfack.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Donfack/Dynamically_balanced_synchronization-avoiding_LU_factorization_with_multicore_and_GPUs__Donfack.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/FCA05502-4A9F-4665-8262-51558553207A}}
}

@inproceedings{anguoma2009performance,
author = {AnguoMa, J C and YuCheng, X N},
title = {{Performance Optimization Strategies of High Performance Computing on GPU}},
booktitle = {Advanced Parallel Processing Technologies: 8th International Symposium, Appt 2009, Rapperswil, Switzerland, August 24-25, 2009 Proceedings},
year = {2009},
pages = {150},
organization = {Springer-Verlag New York Inc},
affiliation = {Springer-Verlag New York Inc},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/003FF7D9-C86A-4EF1-98B7-D31CA734B320}}
}

@techreport{massingill-plop1999,
author = {Massingill, B and Mattson, T and Sanders, B},
title = {{Patterns for parallel application programs}},
year = {1999},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {citeseer.ist.psu.edu/massingill99patterns.html},
uri = {\url{papers2://publication/uuid/BF8D3F00-CF2D-42DA-9335-1CA08B4D6D84}}
}

@article{trapnell2009optimizing,
author = {Trapnell, C and Schatz, M C},
title = {{Optimizing data intensive GPGPU computations for DNA sequence alignment}},
journal = {Parallel Computing},
year = {2009},
volume = {35},
number = {8-9},
pages = {429--440},
publisher = {Elsevier},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:14GMT},
uri = {\url{papers2://publication/uuid/F7F38297-49DD-4979-958E-3D1F3EDBEC04}}
}

@inproceedings{manikandan2008compiler,
author = {Manikandan, M and Bondhugula, U and Krishnamoorthy, S and Ramanujam, J and Rountev, A and Sadayappan, P},
title = {{A Compiler Framework for Optimization of Affine Loop Nests for GPGPUs}},
booktitle = {ACM International Conference on Supercomputing},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:44:21GMT},
uri = {\url{papers2://publication/uuid/E1411DB0-40FB-4629-BCA8-1920508C3478}}
}

@article{Bhandarkar1997,
author = {Bhandarkar, Dileep and Ding, Jason},
title = {{Performance Characterization of the Pentium? Pro Processor}},
journal = {hpca},
year = {1997},
pages = {1--10},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/HPCA.1997.569689},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1997/Bhandarkar/Performance_Characterization_of_the_Pentium?_Pro_Processor_1997_Bhandarkar.pdf},
file = {{Performance_Characterization_of_the_Pentium?_Pro_Processor_1997_Bhandarkar.pdf:/Users/njustn/Dropbox/Papers2/Articles/1997/Bhandarkar/Performance_Characterization_of_the_Pentium?_Pro_Processor_1997_Bhandarkar.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/BCAF828E-EF2C-4E02-8EC0-806C2521DDC4}}
}

@article{Schaa2009,
author = {Schaa, Dana and Kaeli, David},
title = {{Exploring the multiple-GPU design space}},
journal = {Parallel Computing},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/IPDPS.2009.5161068},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Schaa/Exploring_the_multiple-GPU_design_space_2009_Schaa.pdf},
file = {{Exploring_the_multiple-GPU_design_space_2009_Schaa.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Schaa/Exploring_the_multiple-GPU_design_space_2009_Schaa.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/4961F954-51DD-4DC9-8D44-CC6F6C5F2CF3}}
}

@book{grubb-2003,
author = {Grubb, Penny and Takang, Armstrong A},
title = {{Software Maintenance: Concepts and Practice}},
publisher = {World Scientific},
year = {2003},
edition = {2nd},
isbn = {981-238-426-X},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/A7FB11FA-B8E6-4032-85DC-B16C1CF451A9}}
}

@inproceedings{huang-ecoop2007,
author = {Huang, Shan Shan and Zook, David and Smaragdakis, Yannis},
title = {{Morphing: Safely Shaping a Class in the Image of Others}},
booktitle = {Proceedings of the European Conference on Object-Oriented Programming (\ECOOP\)},
year = {2007},
pages = {399--424},
publisher = {Springer-Verlag},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/F26A7BEF-D40B-4A75-9EF2-EBACA4C55BBA}}
}

@article{Korthikanti2010,
author = {Korthikanti, VA and Agha, G},
title = {{Towards Optimizing Energy Costs of Algorithms for Shared Memory Architectures}},
journal = {Memory},
year = {2010},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T18:32:04GMT},
url = {http://osl.cs.uiuc.edu/docs/spaa/spaa094-korthikanti.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Korthikanti/Towards_Optimizing_Energy_Costs_of_Algorithms_for_Shared_Memory_Architectures_2010_Korthikanti.pdf},
file = {{Towards_Optimizing_Energy_Costs_of_Algorithms_for_Shared_Memory_Architectures_2010_Korthikanti.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Korthikanti/Towards_Optimizing_Energy_Costs_of_Algorithms_for_Shared_Memory_Architectures_2010_Korthikanti.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/B58C080C-13E4-45C6-8240-D86487B6D931}}
}

@inproceedings{Phansalkar:2007fa,
author = {Phansalkar, Aashish and Joshi, Ajay and John, Lizy K},
title = {{Analysis of redundancy and application balance in the SPEC CPU2006 benchmark suite}},
booktitle = {ISCA '07: Proceedings of the 34th annual international symposium on Computer architecture},
year = {2007},
publisher = {ACM},
month = jun,
doi = {10.1145/1250662.1250713},
rating = {0},
date-added = {2012-10-03T14:15:03GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {The recently released SPEC CPU2006 benchmark suite is expected to be used by computer designers and computer architecture researchers for pre-silicon early design analysis. Partial use of benchmark suites by researchers, due to simulation time constraints},
url = {http://portal.acm.org/citation.cfm?id=1250662.1250713&coll=DL&dl=ACM&CFID=167902430&CFTOKEN=87848002},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Phansalkar/Analysis_of_redundancy_and_application_balance_in_the_SPEC_CPU2006_benchmark_suite_2007_Phansalkar.pdf},
file = {{Analysis_of_redundancy_and_application_balance_in_the_SPEC_CPU2006_benchmark_suite_2007_Phansalkar.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Phansalkar/Analysis_of_redundancy_and_application_balance_in_the_SPEC_CPU2006_benchmark_suite_2007_Phansalkar.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1250662.1250713}}
}

@inproceedings{aji-bibe08-ps3,
author = {Aji, Ashwin M and Feng, Wu{-chun}},
title = {{Optimizing Performance, Cost, and Sensitivity in Pairwise Sequence Search on a Cluster of PlayStations}},
booktitle = {BioInformatics and BioEngineering, 2008. BIBE 2008. 8th IEEE International Conference on},
year = {2008},
pages = {1--6},
address = {Athens, Greece},
month = oct,
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:55:51GMT},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4696723},
uri = {\url{papers2://publication/uuid/D2B53811-8B4C-4424-A7B1-EBAF88AA8DEE}}
}

@inproceedings{sengupta2007scan,
author = {Sengupta, S and Harris, M and Zhang, Y and Owens, J D},
title = {{Scan primitives for GPU computing}},
booktitle = {Proceedings of the 22nd ACM SIGGRAPH/EUROGRAPHICS symposium on Graphics hardware},
year = {2007},
pages = {106},
organization = {Eurographics Association},
affiliation = {Eurographics Association},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/5B1373CC-614F-4182-80D3-0FADB0D0BAE7}}
}

@article{Altschul90,
author = {Altschul, S and Gish, W and Miller, W and Myers, E and Lipman, D},
title = {{Basic Local Alignment Search Tool}},
journal = {Journal of Molecular Biology},
year = {1990},
volume = {215},
pages = {403--410},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/E1E1A622-9AF2-4F64-8A77-5374FFCFC7C0}}
}

@article{Vuduc:2010tr,
author = {Vuduc, R and Chandramowlishwaran, A and Choi, J and Guney, M and Shringarpure, A},
title = {{On the limits of GPU acceleration}},
journal = {Proceedings of the 2nd USENIX conference on Hot topics in parallelism},
year = {2010},
pages = {13--13},
publisher = {USENIX Association},
read = {Yes},
rating = {0},
date-added = {2012-10-03T15:11:03GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://static.usenix.org/event/hotpar10/tech/full_papers/main.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Vuduc/On_the_limits_of_GPU_acceleration_2010_Vuduc.pdf},
file = {{On_the_limits_of_GPU_acceleration_2010_Vuduc.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Vuduc/On_the_limits_of_GPU_acceleration_2010_Vuduc.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CFC6F085-7807-469B-B883-A54BD36281FC}}
}

@inproceedings{sheaffer2004flexible,
author = {Sheaffer, J W and Luebke, D and Skadron, K},
title = {{A flexible simulation framework for graphics architectures}},
booktitle = {Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware},
year = {2004},
pages = {94},
organization = {ACM},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/8CBCC7B6-0E3A-4967-836A-F02C7C3FAEFE}}
}

@inproceedings{bracha-oopsla1990,
author = {Bracha, G and Cook, W},
title = {{Mixin-Based Inheritance}},
booktitle = {ECOOP/OOPSLA},
year = {1990},
pages = {303--311},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/EC877617-347A-4A18-8E2C-2267D9EAA2ED}}
}

@inproceedings{archuleta-icsm2007-mpiblast,
author = {Archuleta, Jeremy S and Tilevich, Eli and Feng, Wu{-chun}},
title = {{A Maintainable Software Architecture for Fast and Modular Bioinformatics Sequence Search}},
booktitle = {23rd IEEE International Conference on Software Maintenance},
year = {2007},
pages = {144--153},
address = {Paris, France},
month = oct,
doi = {10.1109/ICSM.2007.4362627},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {Bioinformaticists use the Basic Local Alignment Search Tool (BLAST) to characterize an unknown sequence by comparing it against a database of known sequences, thus detecting evolutionary relationships and biological properties. mpiBLAST is a widely-used, high-performance, open-source parallelization of BLAST that runs on a computer cluster delivering super-linear speedups. However, the Achilles heel of mpiBLAST is its lack of modularity, thus adversely affecting maintainability and extensibility. Alleviating this shortcoming requires an architectural refactoring to improve maintenance and extensibility while preserving high performance. Toward that end, this paper evaluates five different software architectures and details how each satisfies our design objectives. In addition, we introduce a novel approach to using mixin layers to enable mixing-and-matching of modules in constructing sequence-search applications for a variety of high-performance computing systems. Our design, which we call "mixin layers with refined roles", utilizes mixin layers to separate functionality into complementary modules and the refined roles in each layer improve the inherently modular design by precipitating flexible and structured parallel development, a necessity for an open-source application. We believe that this new software architecture for mpiBLAST-2.0 will benefit both the users and developers of the package and that our evaluation of different software architectures will be of value to other software engineers faced with the challenges of creating maintainable and extensible, high-performance, bioinformatics software. View full abstract},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4362627},
uri = {\url{papers2://publication/doi/10.1109/ICSM.2007.4362627}}
}

@inproceedings{smaragdakis-icsr2002,
author = {Smaragdakis, Yannis},
title = {{Layered Development with (Unix) Dynamic Libraries}},
booktitle = {ICSR-7: Proceedings of the 7th International Conference on Software Reuse},
year = {2002},
pages = {33--45},
publisher = {Springer-Verlag},
address = {London, UK},
isbn = {3-540-43483-6},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/9683B398-BB99-4AAF-9136-BFC1AF0B9D85}}
}

@inproceedings{aji-cf08-cellswat,
author = {Aji, Ashwin M and Feng, Wu{-chun} and Blagojevic, Filip and Nikolopoulos, Dimitrios S.},
title = {{Cell-SWat: Modeling and Scheduling Wavefront Computations on the Cell Broadband Engine}},
booktitle = {ACM International Conference on Computing Frontiers},
year = {2008},
pages = {13--22},
address = {Ischia, Italy},
month = may,
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {... Our scheduling scheme achieves perfectly balanced SPE work assignment, while at the same time enables ... Results and evaluation of our model are discussed in Section 5. ... The implementation and optimization details that are specific to Cell - SWat are discussed in this section. ...},
url = {http://www.google.com/search?client=safari&rls=10_7_4&q=Cell+SWat+Modeling+and+Scheduling+Wavefront+Computations+on+the+Cell+Broadband+Engine&ie=UTF-8&oe=UTF-8},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Aji/Cell-SWat_Modeling_and_Scheduling_Wavefront_Computations_on_the_Cell_Broadband_Engine_2008_Aji.pdf},
file = {{Cell-SWat_Modeling_and_Scheduling_Wavefront_Computations_on_the_Cell_Broadband_Engine_2008_Aji.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Aji/Cell-SWat_Modeling_and_Scheduling_Wavefront_Computations_on_the_Cell_Broadband_Engine_2008_Aji.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/719D5818-017F-449E-9D2A-C97CF5817D5D}}
}

@article{Stuart:2011kg,
author = {Stuart, J.A and Owens, J D},
title = {{Multi-GPU MapReduce on GPU Clusters}},
year = {2011},
pages = {1068--1079},
publisher = {IEEE},
doi = {10.1109/IPDPS.2011.102},
isbn = {978-1-61284-372-8},
issn = {1530-2075},
language = {English},
read = {Yes},
rating = {0},
date-added = {2012-03-27T20:32:13GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {... The GPU is a many-core machine with multiple SIMD multiprocessors (SM) that can run thousands of ... Like Mars, MapCG only offers limited scalability as it uses but one GPU . CellMR [13] is a single-node implementation of MapReduce on the Cell Engine that alleviates the in ... 
},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012914},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Stuart/Multi-GPU_MapReduce_on_GPU_Clusters_2011_Stuart.pdf},
file = {{Multi-GPU_MapReduce_on_GPU_Clusters_2011_Stuart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Stuart/Multi-GPU_MapReduce_on_GPU_Clusters_2011_Stuart.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2011.102}}
}

@inproceedings{Kang:2011kl,
author = {Kang, Pilsung and Tilevich, Eli and Varadarajan, Srinidhi and Ramakrishnan, Naren},
title = {{Maintainable and reusable scientific software adaptation: democratizing scientific software adaptation}},
booktitle = {AOSD '11: Proceedings of the tenth international conference on Aspect-oriented software development},
year = {2011},
publisher = {ACM},
month = mar,
doi = {10.1145/1960275.1960296},
read = {Yes},
rating = {0},
date-added = {2011-04-24T14:26:20GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Scientific software must be adapted for different execution environments, problem sets, and available resources to ensure its efficiency and reliability. Although adaptation patterns can be found in a sizable percentage of recent scientific applications},
url = {http://portal.acm.org/citation.cfm?id=1960275.1960296&coll=DL&dl=ACM&CFID=83783308&CFTOKEN=85656368},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Kang/Maintainable_and_reusable_scientific_software_adaptation_democratizing_scientific_software_adaptation_2011_Kang.pdf},
file = {{Maintainable_and_reusable_scientific_software_adaptation_democratizing_scientific_software_adaptation_2011_Kang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Kang/Maintainable_and_reusable_scientific_software_adaptation_democratizing_scientific_software_adaptation_2011_Kang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1960275.1960296}}
}

@article{dagum-cse1998,
author = {Dagum, Leonardo and Menon, Ramesh},
title = {{OpenMP: An Industry-Standard API for Shared-Memory Programming}},
journal = {IEEE Computational Science and Engineering},
year = {1998},
volume = {05},
number = {1},
pages = {46--55},
address = {Los Alamitos, CA, USA},
publisher = {IEEE Computer Society},
keywords = {ipdps11-omp-co},
doi = {http://doi.ieeecomputersociety.org/10.1109/99.660313},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:14GMT},
uri = {\url{papers2://publication/doi/http://doi.ieeecomputersociety.org/10.1109/99.660313}}
}

@inproceedings{Stone:1990gn,
author = {Stone, Janice M},
title = {{A simple and correct shared-queue algorithm using compare-and-swap}},
crossref = {supercomputing},
year = {1990},
pages = {495--504},
doi = {10.1109/SUPERC.1990.130060},
read = {Yes},
rating = {0},
date-added = {2013-07-23T17:03:38GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {A compare-and-swap shared-queue algorithm is presented that permits concurrent access. This algorithm is nondelaying in that no processor need wait for an action by another processor. A verification method that analyzes the states of the shared data structure is given. By drawing a graph that incorporates in a simple way the effects of multiprocessor interleaving, one can quickly find errors in an algorithm or produce a proof of correctness. Since enqueue and dequeue operations may begin at any time, concurrent queue operations are represented by providing, in each state of the shared data structure, one transition that initiates an enqueue operation and another transition for a dequeue operation. The method is a practical one that is applicable to a variety of algorithms that use shared data structures View full abstract},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=130060},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1990/Stone/A_simple_and_correct_shared-queue_algorithm_using_compare-and-swap_1990_Stone.pdf},
file = {{A_simple_and_correct_shared-queue_algorithm_using_compare-and-swap_1990_Stone.pdf:/Users/njustn/Dropbox/Papers2/Articles/1990/Stone/A_simple_and_correct_shared-queue_algorithm_using_compare-and-swap_1990_Stone.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SUPERC.1990.130060}}
}

@book{vliet-2000,
author = {van Vliet, Hans},
title = {{Software engineering (2nd ed.): principles and practice}},
publisher = {John Wiley \{\&} Sons, Inc.},
year = {2000},
address = {New York, NY, USA},
isbn = {0-471-97508-7},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/1D618BCE-E6B6-4FC9-90AB-4A296B32AB5D}}
}

@article{diamos2009translating,
author = {Diamos, Gregory Frederick and Kerr, A and Kesavan, M},
title = {{Translating GPU binaries to tiered SIMD architectures with Ocelot}},
year = {2009},
publisher = {Georgia Institute of Technology},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/3E8656A6-8591-4A05-BDCB-B619C45F22BB}}
}

@article{keene-rms1993,
author = {Keene, S J and Keene, K C},
title = {{Reducing the life cycle cost of software through concurrent engineering}},
journal = {Reliability and Maintainability Symposium, 1993. Proceedings., Annual},
pages = {305--310},
doi = {10.1109/RAMS.1993.296838},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/doi/10.1109/RAMS.1993.296838}}
}

@article{lavender-pplp1995,
author = {Lavender, RG},
title = {{Active Object: An Object Behavioral Pattern for Concurrent Programming}},
journal = {Proc.Pattern Languages of Programs,},
year = {1995},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:10:47GMT},
date-modified = {2014-07-05T20:27:46GMT},
abstract = {This paper describes the Active Object pattern, which decouples method execution from method invocation in order to simplify synchronized access to a shared resource by methods invoked in different threads of control. The Active Object pattern allows one or more independent ...},
url = {citeseer.ist.psu.edu/lavender96active.html},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1995/Lavender/Active_Object_An_Object_Behavioral_Pattern_for_Concurrent_Programming_1995_Lavender-1.pdf},
file = {{Active_Object_An_Object_Behavioral_Pattern_for_Concurrent_Programming_1995_Lavender-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/1995/Lavender/Active_Object_An_Object_Behavioral_Pattern_for_Concurrent_Programming_1995_Lavender-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1C62DD38-DAD9-4F14-AEAB-D4DABD3F70ED}}
}

@inproceedings{Diamos:2010dc,
author = {Diamos, Gregory Frederick and Kerr, Andrew Robert and Yalamanchili, Sudhakar and Clark, Nathan},
title = {{Ocelot: a dynamic optimization framework for bulk-synchronous applications in heterogeneous systems}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2010},
publisher = {ACM},
month = sep,
doi = {10.1145/1854273.1854318},
rating = {0},
date-added = {2011-11-12T20:47:55GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {Ocelot is a dynamic compilation framework designed to map the explicitly data parallel execution model used by NVIDIA CUDA applications onto diverse multithreaded platforms. Ocelot includes a dynamic binary translator from Parallel Thread eXecution ISA},
url = {http://portal.acm.org/citation.cfm?id=1854273.1854318},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Diamos/Ocelot_a_dynamic_optimization_framework_for_bulk-synchronous_applications_in_heterogeneous_systems_2010_Diamos.pdf},
file = {{Ocelot_a_dynamic_optimization_framework_for_bulk-synchronous_applications_in_heterogeneous_systems_2010_Diamos.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Diamos/Ocelot_a_dynamic_optimization_framework_for_bulk-synchronous_applications_in_heterogeneous_systems_2010_Diamos.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1854273.1854318}}
}

@inproceedings{Paul:2013jv,
author = {Paul, Indrani and Ravi, Vignesh and Manne, Srilatha and Arora, Manish and Yalamanchili, Sudhakar},
title = {{Coordinated energy management in heterogeneous processors}},
crossref = {supercomputing},
year = {2013},
pages = {1--12},
publisher = {ACM Press},
address = {New York, New York, USA},
annote = {this is the Juggling Joules paper renamed into its final form},
doi = {10.1145/2503210.2503227},
isbn = {9781450323789},
read = {Yes},
rating = {0},
date-added = {2014-04-05T20:00:43GMT},
date-modified = {2014-07-05T20:58:04GMT},
url = {http://dl.acm.org/citation.cfm?doid=2503210.2503227},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Paul/Coordinated_energy_management_in_heterogeneous_processors_2013_Paul.pdf},
file = {{Coordinated_energy_management_in_heterogeneous_processors_2013_Paul.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Paul/Coordinated_energy_management_in_heterogeneous_processors_2013_Paul.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2503210.2503227}}
}

@inproceedings{gedik-vldb2007,
author = {Gedik, Bu$\backslash$vgra and Bordawekar, Rajesh R and Yu, Philip S},
title = {{CellSort: high performance sorting on the cell processor}},
booktitle = {VLDB '07: Proceedings of the 33rd international conference on Very large data bases},
year = {2007},
pages = {1286--1297},
publisher = {VLDB Endowment},
isbn = {978-1-59593-649-3},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://www.worldcat.org/title/33rd-international-conference-on-very-large-data-bases-university-of-vienna-austria-september-23-27-2007-conference-proceedings/oclc/650168232},
uri = {\url{papers2://publication/uuid/9C969A60-7F98-4BDE-A64B-B18AF125E852}}
}

@inproceedings{Tan:2007wv,
author = {Tan, L and Yuan, D and Krishna, G},
title = {{/* icomment: Bugs or Bad Comments? */}},
booktitle = {ACM SIGOPS Symposium on Operating Systems Principles},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:49:31GMT},
date-modified = {2014-07-05T17:38:47GMT},
abstract = {ABSTRACT Commenting source code has long been a common practice in soft- ware development. Compared to source code, comments are more direct, descriptive and easy-to-understand. Comments and source code provide relatively redundant and ...},
url = {http://portal.acm.org/citation.cfm?id=1294276},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Tan/icomment_Bugs_or_Bad_Comments__2007_Tan.pdf},
file = {{icomment_Bugs_or_Bad_Comments__2007_Tan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Tan/icomment_Bugs_or_Bad_Comments__2007_Tan.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/8543C431-FB31-40BF-A14B-6FB13BF4989A}}
}

@article{basili-software2008,
author = {Basili, Victor R and Carver, Jeffrey and Cruzes, Daniela and Hochstein, Lorin and Hollingsworth, Jeffrey K and Shull, Forrest and Zelkowitz, Marvin V},
title = {{Understanding the High Performance Computing Community: A Software Engineer's Perspective}},
journal = {IEEE Software},
year = {2008},
volume = {25},
number = {4},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/BDB96354-AE11-4E78-B878-BE8A607EA6F1}}
}

@article{Sanjay2010,
author = {Sanjay, S.S.B.M.D. and Gropp, J.P.W.D. and Wen-mei, W.H.},
title = {{An Adaptive Performance Modeling Tool for GPU Architectures}},
journal = {Urbana},
year = {2010},
volume = {51},
pages = {61801},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:14GMT},
url = {http://impact.crhc.illinois.edu/ftp/conference/sara.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Sanjay/An_Adaptive_Performance_Modeling_Tool_for_GPU_Architectures_2010_Sanjay.pdf},
file = {{An_Adaptive_Performance_Modeling_Tool_for_GPU_Architectures_2010_Sanjay.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Sanjay/An_Adaptive_Performance_Modeling_Tool_for_GPU_Architectures_2010_Sanjay.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/77935212-4459-4F80-9BAF-14AD6A8E8D8B}}
}

@inproceedings{Li:2010wp,
author = {Li, Min and Vazhkudai, Sudharshan S and Butt, Ali R and Meng, Fei and Ma, Xiaosong and Kim, Youngjae and Engelmann, Christian and Shipman, Galen},
title = {{Functional Partitioning to Optimize End-to-End Performance on Many-core Architectures}},
crossref = {supercomputing},
year = {2010},
publisher = { IEEE Computer Society},
month = nov,
read = {Yes},
rating = {0},
date-added = {2011-04-24T14:33:42GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Scaling computations on emerging massive-core supercomputers is a daunting task, which coupled with the significantly lagging system I/O capabilities exacerbates applications' end-to-end performance. The I/O bottleneck often negates potential performance},
url = {http://portal.acm.org/citation.cfm?id=1884643.1884686&coll=DL&dl=GUIDE&CFID=17718134&CFTOKEN=56718728},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Li/Functional_Partitioning_to_Optimize_End-to-End_Performance_on_Many-core_Architectures_2010_Li.pdf},
file = {{Functional_Partitioning_to_Optimize_End-to-End_Performance_on_Many-core_Architectures_2010_Li.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Li/Functional_Partitioning_to_Optimize_End-to-End_Performance_on_Many-core_Architectures_2010_Li.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/74654219-877F-4E91-9361-8B3AEF208AB3}}
}

@article{eubank2004mdo,
author = {Eubank, S and Guclu, H and Kumar, V S A and Marathe, M V and Srinivasan, A and Toroczkai, Z and Wang, N},
title = {{Modelling disease outbreaks in realistic urban social networks}},
journal = {Nature},
year = {2004},
volume = {429},
number = {6988},
pages = {180--184},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://www.mcc.uiuc.edu/nsfitr04Rev/presentations/0113049\_Modelling\_disease.pdf},
uri = {\url{papers2://publication/uuid/EC3241B8-67B0-4B31-8C77-8B5C3E56017F}}
}

@inproceedings{hwloc,
author = {Broquedis, F and Clet-Ortega, J and Moreaud, S and Furmento, N and Goglin, B and Mercier, G and Thibault, S and Namyst, R},
title = {{hwloc: A Generic Framework for Managing Hardware Affinities in HPC Applications}},
booktitle = {International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
year = {2010},
pages = {180--186},
publisher = { IEEE Computer Society},
doi = {10.1109/PDP.2010.67},
rating = {0},
date-added = {2014-04-17T02:51:01GMT},
date-modified = {2014-07-05T20:10:02GMT},
abstract = {The increasing numbers of cores, shared caches and memory nodes within machines introduces a complex hardware topology. High-performance computing applications now have to carefully adapt their placement and behavior according to the underlying hierarchy of hardware resources and their software affinities. We introduce the Hardware Locality (hwloc) software which gathers hardware information about processors, caches, memory nodes and more, and exposes it to applications and runtime systems in a abstracted and portable hierarchical manner. hwloc may significantly help performance by having runtime systems place their tasks or adapt their communication strategies depending on hardware affinities. We show that hwloc can already be used by popular high-performance OpenMP or MPI software. Indeed, scheduling OpenMP threads according to their affinities or placing MPI processes according to their communication patterns shows interesting performance improvement thanks to hwloc. An optimized MPI communication strategy may also be dynamically chosen according to the location of the communicating processes in the machine and its hardware characteristics. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5452445&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28hwloc%29},
uri = {\url{papers2://publication/doi/10.1109/PDP.2010.67}}
}

@techreport{upc,
author = {El-Ghazawi, Tarek and Carlson, William and Draper, Jesse},
title = {{\UPC\ Language Specifications, v1.1.1}},
year = {2003},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/47E40F1B-BF8E-48E9-9B72-DD1D68B440DF}}
}

@inproceedings{apel-gpce2005,
author = {Apel, Sven and Leich, Thomas and Rosenm u ller, Marko and Saake, Gunter},
title = {{\FeatureC++\: On the Symbiosis of Feature-Oriented and Aspect-Oriented Programming}},
booktitle = {GPCE},
year = {2005},
pages = {125--140},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/450E7FE2-C67F-433D-B845-B676EDC0C319}}
}

@inproceedings{he2007efficient,
author = {He, B and Govindaraju, N K and Luo, Q and Smith, B},
title = {{Efficient gather and scatter operations on graphics processors}},
crossref = {supercomputing},
year = {2007},
organization = {ACM New York, NY, USA},
affiliation = {ACM New York, NY, USA},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/DB1614E7-7A21-4374-A784-776ADF4D16E2}}
}

@techreport{mpi,
author = {Forum, Message Passing Interface},
title = {{\MPI\: \A\ Message-Passing Interface Standard}},
year = {1994},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {citeseer.ist.psu.edu/article/forum94mpi.html},
uri = {\url{papers2://publication/uuid/408BA92E-ED91-43FE-91F8-A1286ADCA365}}
}

@inproceedings{carrillo2009control,
author = {Carrillo, S and Siegel, J and Li, X},
title = {{A control-structure splitting optimization for GPGPU}},
booktitle = {ACM International Conference on Computing Frontiers},
year = {2009},
pages = {147--150},
organization = {ACM New York, NY, USA},
affiliation = {ACM New York, NY, USA},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/81A8D716-2B19-4369-8312-025AF19BE42E}}
}

@inproceedings{Rafique:2010vb,
author = {Rafique, M Mustafa and Butt, Ali R and Nikolopoulos, Dimitrios S.},
title = {{Designing Accelerator-Based Distributed Systems for High Performance}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2010},
publisher = { IEEE Computer Society},
month = may,
read = {Yes},
rating = {0},
date-added = {2011-04-24T14:33:37GMT},
date-modified = {2014-07-05T20:14:14GMT},
abstract = {Multi-core processors with accelerators are becoming commodity components for high-performance computing at scale. While accelerator-based processors have been studied in some detail, the design and management of clusters based on these processors have},
url = {http://portal.acm.org/citation.cfm?id=1844765.1845111&coll=DL&dl=GUIDE&CFID=17718134&CFTOKEN=56718728},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Rafique/Designing_Accelerator-Based_Distributed_Systems_for_High_Performance_2010_Rafique.pdf},
file = {{Designing_Accelerator-Based_Distributed_Systems_for_High_Performance_2010_Rafique.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Rafique/Designing_Accelerator-Based_Distributed_Systems_for_High_Performance_2010_Rafique.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2DA1D271-95F2-42D8-B23F-690F52AAF44B}}
}

@inproceedings{catanzaro2008map,
author = {Catanzaro, B and Sundaram, N and Keutzer, K},
title = {{A map reduce framework for programming graphics processors}},
booktitle = {Workshop on Software Tools for MultiCore Systems},
year = {2008},
organization = {Citeseer},
affiliation = {Citeseer},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/F8A98812-155D-4746-AFEA-C594EC7994E2}}
}

@article{Sachdeva2008,
author = {Sachdeva, Vipin and Kistler, Michael and Speight, Evan and Tzeng, T.H.K.},
title = {{Exploring the viability of the Cell Broadband Engine for bioinformatics applications}},
journal = {Parallel Computing},
year = {2008},
volume = {34},
number = {11},
pages = {616--626},
publisher = {Elsevier},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167819108000501},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Sachdeva/Exploring_the_viability_of_the_Cell_Broadband_Engine_for_bioinformatics_applications_2008_Sachdeva.pdf},
file = {{Exploring_the_viability_of_the_Cell_Broadband_Engine_for_bioinformatics_applications_2008_Sachdeva.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Sachdeva/Exploring_the_viability_of_the_Cell_Broadband_Engine_for_bioinformatics_applications_2008_Sachdeva.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/55674E65-F8D3-4C40-9457-FE6C31BF6D1D}}
}

@article{batory-tosem2002,
author = {Batory, Don and Johnson, Clay and MacDonald, Bob and von Heeder, Dale},
title = {{Achieving extensibility through product-lines and domain-specific languages: a case study}},
journal = {ACM Transactions on Software Engineering and Methodology},
year = {2002},
volume = {11},
number = {2},
pages = {191--214},
address = {New York, NY, USA},
publisher = {ACM},
doi = {http://doi.acm.org/10.1145/505145.505147},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/505145.505147}}
}

@inproceedings{Pyla:2011eo,
author = {Pyla, Hari K},
title = {{Composing locks by decomposing deadlocks}},
booktitle = {SPLASH '11: Proceedings of the ACM international conference companion on Object oriented programming systems languages and applications companion},
year = {2011},
publisher = {ACM},
month = oct,
doi = {10.1145/2048147.2048176},
rating = {0},
date-added = {2011-11-05T21:55:33GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {The evolution of processor architectures from multi-core to many-core requires programmers to use concurrency to achieve performance. Unfortunately, shared memory parallel programs are difficult to implement correctly, and so is detecting concurrency},
url = {http://portal.acm.org/citation.cfm?id=2048147.2048176&coll=DL&dl=GUIDE&CFID=67286147&CFTOKEN=46934297},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Pyla/Composing_locks_by_decomposing_deadlocks_2011_Pyla.pdf},
file = {{Composing_locks_by_decomposing_deadlocks_2011_Pyla.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Pyla/Composing_locks_by_decomposing_deadlocks_2011_Pyla.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2048147.2048176}}
}

@article{Stone2007,
author = {Stone, JE and Phillips, JC and Freddolino, PL and {DJ}},
title = {{Accelerating molecular modeling applications with graphics processors}},
journal = {Journal of},
year = {2007},
doi = {10.1002/jcc},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://sips.inesc-id.pt/\~fcpp/molecular\_quantum\_mechanics/acce\_molecular\_model\_app\_w\_GPU.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Stone/Accelerating_molecular_modeling_applications_with_graphics_processors_2007_Stone.pdf},
file = {{Accelerating_molecular_modeling_applications_with_graphics_processors_2007_Stone.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Stone/Accelerating_molecular_modeling_applications_with_graphics_processors_2007_Stone.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1002/jcc}}
}

@inproceedings{Pyla:2011gh,
author = {Pyla, Hari K and Ribbens, Calvin and Varadarajan, Srinidhi},
title = {{Exploiting Coarse-Grain Speculative Parallelism}},
booktitle = {ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages, and Applications},
year = {2011},
publisher = {ACM},
month = oct,
doi = {10.1145/2048066.2048110},
read = {Yes},
rating = {0},
date-added = {2011-11-05T21:55:13GMT},
date-modified = {2014-07-05T21:05:18GMT},
abstract = {Speculative execution at coarse granularities (e.g., code-blocks, methods, algorithms) offers a promising programming model for exploiting parallelism on modern architectures. In this paper we present Anumita, a framework that includes programming constructs},
url = {http://portal.acm.org/citation.cfm?id=2048066.2048110&coll=DL&dl=GUIDE&CFID=67286147&CFTOKEN=46934297},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Pyla/Exploiting_Coarse-Grain_Speculative_Parallelism_2011_Pyla-1.pdf},
file = {{Exploiting_Coarse-Grain_Speculative_Parallelism_2011_Pyla-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Pyla/Exploiting_Coarse-Grain_Speculative_Parallelism_2011_Pyla-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2048066.2048110}}
}

@article{Pyla:2010uz,
author = {Pyla, Hari and Varadarajan, Srinidhi},
title = {{Avoiding deadlock avoidance}},
journal = {PACT '10: Proceedings of the 19th international conference on Parallel architectures and compilation techniques},
year = {2010},
read = {Yes},
rating = {0},
date-added = {2011-11-05T21:55:47GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://portal.acm.org/ft_gateway.cfm?id=1854288&type=pdf&coll=DL&dl=GUIDE&CFID=67182534&CFTOKEN=49932139},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Pyla/Avoiding_deadlock_avoidance_2010_Pyla.pdf},
file = {{Avoiding_deadlock_avoidance_2010_Pyla.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Pyla/Avoiding_deadlock_avoidance_2010_Pyla.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/535FF439-A313-4977-A1E3-14A1FCDC307B}}
}

@inproceedings{Pyla:2011fj,
author = {Pyla, Hari K},
title = {{Coarse-grain speculation for emerging processors}},
booktitle = {SPLASH '11: Proceedings of the ACM international conference companion on Object oriented programming systems languages and applications companion},
year = {2011},
publisher = {ACM},
month = oct,
doi = {10.1145/2048147.2048215},
read = {Yes},
rating = {0},
date-added = {2011-11-05T21:56:00GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {The impending multi/many-core processor revolution requires that programmers leverage explicit concurrency to improve performance. Unfortunately, a large body of applications/algorithms are inherently hard to parallelize due to execution order constraints},
url = {http://portal.acm.org/citation.cfm?id=2048147.2048215&coll=DL&dl=GUIDE&CFID=67286147&CFTOKEN=46934297},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Pyla/Coarse-grain_speculation_for_emerging_processors_2011_Pyla.pdf},
file = {{Coarse-grain_speculation_for_emerging_processors_2011_Pyla.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Pyla/Coarse-grain_speculation_for_emerging_processors_2011_Pyla.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2048147.2048215}}
}

@inproceedings{jang2009architecture,
author = {Jang, B and Do, S and Pien, H and Kaeli, D},
title = {{Architecture-aware optimization targeting multithreaded stream computing}},
booktitle = {Annual Workshop on General Purpose Processing with Graphics Processing Units},
year = {2009},
pages = {62--70},
organization = {ACM New York, NY, USA},
affiliation = {ACM New York, NY, USA},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-05T17:33:36GMT},
uri = {\url{papers2://publication/uuid/C1102921-CA3E-4AF8-8F5D-59D6F74B9748}}
}

@article{Gummaraju:2010up,
author = {Gummaraju, Jayanth and Morichetti, Laurent and Houston, Michael and Ben Sander and Gaster, Benedict and Zheng, Bixia},
title = {{Twin peaks: a software platform for heterogeneous computing on general-purpose and graphics processors}},
journal = {PACT '10: Proceedings of the 19th international conference on Parallel architectures and compilation techniques},
year = {2010},
read = {Yes},
rating = {0},
date-added = {2011-11-05T21:59:21GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://portal.acm.org/ft_gateway.cfm?id=1854302&type=pdf&coll=DL&dl=GUIDE&CFID=67182534&CFTOKEN=49932139},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Gummaraju/Twin_peaks_a_software_platform_for_heterogeneous_computing_on_general-purpose_and_graphics_processors_2010_Gummaraju.pdf},
file = {{Twin_peaks_a_software_platform_for_heterogeneous_computing_on_general-purpose_and_graphics_processors_2010_Gummaraju.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Gummaraju/Twin_peaks_a_software_platform_for_heterogeneous_computing_on_general-purpose_and_graphics_processors_2010_Gummaraju.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/7117166C-0EDC-4E7D-B8A1-163BC93FF898}}
}

@inproceedings{Sun:2012in,
author = {Sun, Enqiang and Schaa, Dana and Bagley, Richard and Rubin, Norman and Kaeli, David},
title = {{Enabling task-level scheduling on heterogeneous platforms}},
booktitle = {Annual Workshop on General Purpose Processing with Graphics Processing Units},
year = {2012},
pages = {84--93},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/2159430.2159440},
isbn = {9781450312332},
rating = {0},
date-added = {2013-03-06T01:54:32GMT},
date-modified = {2014-07-05T17:33:36GMT},
url = {http://dl.acm.org/citation.cfm?doid=2159430.2159440},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Sun/Enabling_task-level_scheduling_on_heterogeneous_platforms_2012_Sun.pdf},
file = {{Enabling_task-level_scheduling_on_heterogeneous_platforms_2012_Sun.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Sun/Enabling_task-level_scheduling_on_heterogeneous_platforms_2012_Sun.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2159430.2159440}}
}

@article{Feng,
author = {Feng, Xizhou and Ge, Rong and Cameron, KW},
title = {{Power and energy profiling of scientific applications on distributed systems}},
journal = {Power},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Power+and+Energy+Profiling+of+Scientific+Applications+on+Distributed+Systems\#0},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Feng/Power_and_energy_profiling_of_scientific_applications_on_distributed_systems__Feng.pdf},
file = {{Power_and_energy_profiling_of_scientific_applications_on_distributed_systems__Feng.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Feng/Power_and_energy_profiling_of_scientific_applications_on_distributed_systems__Feng.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/08444E30-341B-47FF-AA06-06B470C74B7C}}
}

@article{Loveman:1993cg,
author = {Loveman, D B},
title = {{High Performance Fortran}},
journal = {Parallel {\&} Distributed Technology: Systems {\&} Applications, IEEE},
year = {1993},
volume = {1},
number = {1},
pages = {25--42},
doi = {10.1109/88.219857},
rating = {0},
date-added = {2014-04-17T03:24:16GMT},
date-modified = {2014-07-05T20:56:32GMT},
abstract = {Fortran-90, its basis in Fortran-77, its implications for parallel machines, and the extensions developed for it by the High Performance Fortran Forum (HPFF), a coalition of computer vendors, government laboratories, and academic groups founded in 1992 to improve the performance and usability of Fortran-90 for computationally intensive applications on a wide variety of machines, including massively parallel single-instruction multiple-data (SIMD) and multiple-instruction multiple-data (MIMD) systems and vector processors, are discussed. SIMD and MIMD systems, previous attempts to develop languages for them, the genesis of the HPFF, how the group actually worked, and the HPF programming model are described.<<ETX>> View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=219857&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22high+performance+fortran%22%29},
uri = {\url{papers2://publication/doi/10.1109/88.219857}}
}

@webpage{Anonymous:BHctX_5K,
title = {{Parallax - A New Operating System for Scalable, Distributed and Parallel Computing | Intel{\textregistered} Developer Zone}},
url = {http://software.intel.com/en-us/articles/parallax-a-new-operating-system-for-scalable-distributed-and-parallel-computing},
read = {Yes},
rating = {0},
date-added = {2013-03-06T02:08:25GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/04772D5F-FE4A-468B-A4FC-4F543AF24561}}
}

@inproceedings{Misra:bo,
author = {Misra, Prabhakar and Chaudhuri, Mainak},
title = {{Performance Evaluation of Concurrent Lock-free Data Structures on GPUs}},
booktitle = {International Conference on Parallel and Distributed Systems},
pages = {53--60},
publisher = {IEEE},
doi = {10.1109/ICPADS.2012.18},
isbn = {978-0-7695-4903-3},
rating = {0},
date-added = {2013-07-24T00:51:52GMT},
date-modified = {2014-07-05T17:43:02GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6413551},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Misra/Performance_Evaluation_of_Concurrent_Lock-free_Data_Structures_on_GPUs__Misra.pdf},
file = {{Performance_Evaluation_of_Concurrent_Lock-free_Data_Structures_on_GPUs__Misra.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Misra/Performance_Evaluation_of_Concurrent_Lock-free_Data_Structures_on_GPUs__Misra.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPADS.2012.18}}
}

@misc{thrust,
title = {{Thrust}},
howpublished = {http://code.google.com/p/thrust/},
year = {2009},
publisher = {http://code.google.com/p/thrust/},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-06T21:20:37GMT},
url = {http://code.google.com/p/thrust/},
uri = {\url{papers2://publication/uuid/21B6CAFB-F76E-49B8-9670-BB2F1FC8950A}}
}

@article{hoare-acm1978,
author = {Hoare, C A R},
title = {{Communicating sequential processes}},
journal = {Commun. ACM},
year = {1978},
volume = {21},
number = {8},
pages = {666--677},
address = {New York, NY, USA},
publisher = {ACM},
doi = {http://doi.acm.org/10.1145/359576.359585},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/359576.359585}}
}

@techreport{devices-inc,
author = {Devices, A M},
title = {{Inc. AMD Brook+}},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/uuid/DD5FB8D3-31ED-4ED4-A202-6DECAAFE2194}}
}

@book{weiss-1999,
author = {Weiss, David M and Lai, Chi Tau Robert},
title = {{Software product-line engineering: a family-based software development process}},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
year = {1999},
address = {Boston, MA, USA},
isbn = {0-201-69438-7},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/F38D7398-17F6-45AD-922F-6239EA33D845}}
}

@inproceedings{gabriel-pvmmpi2004,
author = {Gabriel, Edgar and Fagg, Graham E and Bosilca, George and Angskun, Thara and Dongarra, Jack and Squyres, Jeffrey M and Sahay, Vishal and Kambadur, Prabhanjan and Barrett, Brian and Lumsdaine, Andrew and Castain, Ralph H and Daniel, David J and Graham, Richard L and Woodall, Timothy S},
title = {{Open \MPI\: Goals, Concept, and Design of a Next Generation \MPI\ Implementation}},
booktitle = {Proceedings, 11th European PVM/MPI Users' Group Meeting},
year = {2004},
pages = {97--104},
address = {Budapest, Hungary},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/69550E11-A44A-472B-9EF1-3EEA0294C8A8}}
}

@article{Datta:2009tl,
author = {Datta, Kaushik and Williams, S and Volkov, V and Carter, J and Oliker, L},
title = {{Auto-tuning the 27-point stencil for multicore}},
journal = {iWAPT2009},
year = {2009},
rating = {0},
date-added = {2011-12-14T06:41:51GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Abstract. This study focuses on the key numerical technique of stencil computations, used in many different scientific disciplines, and illustrates how auto- tuning can be used to produce very efficient implementations across a diverse set of current multicore architectures.},
url = {http://crd.lbl.gov/~oliker/papers/iwapt09.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Datta/Auto-tuning_the_27-point_stencil_for_multicore_2009_Datta.pdf},
file = {{Auto-tuning_the_27-point_stencil_for_multicore_2009_Datta.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Datta/Auto-tuning_the_27-point_stencil_for_multicore_2009_Datta.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/7DD3CBF0-67A5-47EB-ABA8-71848F9DA84F}}
}

@techreport{llnl,
title = {{Tutorial: Introduction to Parallel Computing}},
year = {2007},
annote = {https://computing.llnl.gov/tutorials/parallel\_comp/},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/61301ABE-E494-4798-90DA-0DE3099B12EF}}
}

@article{kepner-ijhpca2004,
author = {Kepner, Jeremy},
title = {{\HPC\ Productivity: An Overarching View}},
journal = {International Journal of High Performance Computing Applications},
year = {2004},
volume = {18},
number = {4},
pages = {393--397},
address = {Thousand Oaks, CA, USA},
publisher = {Sage Publications, Inc.},
doi = {http://dx.doi.org/10.1177/1094342004048533},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/doi/http://dx.doi.org/10.1177/1094342004048533}}
}

@inproceedings{sheaffer2005fine,
author = {Sheaffer, J W and Skadron, K and Luebke, D P},
title = {{Fine-grained graphics architectural simulation with Qsilver}},
booktitle = {ACM SIGGRAPH 2005 Posters},
year = {2005},
pages = {118},
organization = {ACM},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/uuid/D6288B32-47E0-499C-9CF9-AADF180A196A}}
}

@techreport{Henzinger:2013wx,
author = {Henzinger, Thomas A and Payer, Hannes and Sezgin, Ali},
title = {{Replacing Competition with Cooperation to Achieve Scalable Lock-Free FIFO Queues}},
year = {2013},
number = {IST-2013-124-v1+1},
month = jun,
publisher = {IST Austria},
read = {Yes},
rating = {0},
date-added = {2013-07-24T01:10:30GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {In order to guarantee that each method of a data structure updates the logical state exactly once, almost all non-blocking implementations employ Compare-And-Swap (CAS) based synchronization. For FIFO queue implementations this translates into concurrent enqueue or dequeue methods competing among themselves to update the same variable, the tail or the head, respectively, leading to high contention and poor scalability. Recent non-blocking queue implementations try to alleviate high contention by increasing the number of contention points, all the while using CAS-based synchronization. Furthermore, obtaining a wait-free implementation with competition is achieved by additional synchronization which leas to further degradation of performance.
In this paper we formalize the notion of competitiveness of a synchronizing statement which can be used as a measure for the scalability of concurrent implementations. We present a new queue implementation, the Speculative Pairing (SP) queue, which, as we show, decreases competitiveness by using Fetch-And-Increment (FAI) instead of CAS. We prove that the SP queue is linearizable and lock-free. We also show that replacing CAS with FAI leads to wait-freedom for dequeue methods without an adverse effect on performance. In fact, our experiments suggest that the SP queue can perform and scale better than the state-of-the-art queue implementations.},
url = {https://repository.ist.ac.at/124/},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Reports/2013/Henzinger/Replacing_Competition_with_Cooperation_to_Achieve_Scalable_Lock-Free_FIFO_Queues_2013_Henzinger.pdf},
file = {{Replacing_Competition_with_Cooperation_to_Achieve_Scalable_Lock-Free_FIFO_Queues_2013_Henzinger.pdf:/Users/njustn/Dropbox/Papers2/Reports/2013/Henzinger/Replacing_Competition_with_Cooperation_to_Achieve_Scalable_Lock-Free_FIFO_Queues_2013_Henzinger.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/B6013BDE-6355-4D16-8CCA-8E3080D3CF08}}
}

@inproceedings{ryoo2007program,
author = {Ryoo, S and Rodrigues, C I and Stone, S S and Baghsorkhi, Sara S and Ueng, S Z and Hwu, W W},
title = {{Program optimization study on a 128-core GPU}},
booktitle = {The First Workshop on General Purpose Processing on Graphics Processing Units},
year = {2007},
organization = {Citeseer},
affiliation = {Citeseer},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/3404C3A8-D9D6-4C89-8B09-77107116D09A}}
}

@article{numrich-sigplan1998,
author = {Numrich, Robert W and Reid, John},
title = {{Co-Array Fortran for Parallel Programming}},
journal = {SIGPLAN Fortran Forum},
year = {1998},
volume = {17},
number = {2},
pages = {1--31},
address = {New York, NY, USA},
publisher = {ACM},
doi = {http://doi.acm.org/10.1145/289918.289920},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-05T20:56:51GMT},
uri = {\url{papers2://publication/doi/http://doi.acm.org/10.1145/289918.289920}}
}

@inproceedings{smargadakis-ecoop1998,
author = {Smaragdakis, Yannis and Batory, Don},
title = {{Implementing Layered Designs with Mixin Layers}},
booktitle = {European Conference on Object-Oriented Programming (ECOOP)},
year = {1998},
publisher = {Springer-Verlag LNCS 1445},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/DA6E5071-3DD9-4C69-BC04-05E0B2950AA8}}
}

@techreport{gccxml,
title = {{\GCC-XML\, the \XML\ output extension to \GCC\}},
year = {2007},
annote = {http://www.gccxml.org/},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
uri = {\url{papers2://publication/uuid/4EA50C1B-F2E7-4BF8-A17D-D2B56F98A5FC}}
}

@article{Pakin2008,
author = {Pakin, Scott},
title = {{Receiver-initiated message passing over RDMA networks}},
journal = {IEEE International Symposium on Parallel and},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Receiver-initiated+Message+Passing+over+RDMA+Networks\#0},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Pakin/Receiver-initiated_message_passing_over_RDMA_networks_2008_Pakin.pdf},
file = {{Receiver-initiated_message_passing_over_RDMA_networks_2008_Pakin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Pakin/Receiver-initiated_message_passing_over_RDMA_networks_2008_Pakin.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/FBA00215-0F7B-4A81-8985-B22071407A44}}
}

@article{Manferdelli-ctwatch2007,
author = {Manferdelli, John L},
title = {{The Many-Core Inflection Point for Mass Market Computer Systems}},
journal = {CTWatch Quarterly},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://www.ctwatch.org/quarterly/articles/2007/02/the-many-core-inflection-point-for-mass-market-computer-systems/},
uri = {\url{papers2://publication/uuid/E79A6325-116B-472D-ACAF-3AEA57EEA20E}}
}

@inproceedings{kastner-ecoop2007,
author = {K a stner, Christian and Kuhlemann, Martin and Batory, Don},
title = {{Automating Feature-Oriented Refactoring of Legacy Applications}},
booktitle = {Poster presented at Europ.$\backslash$ Conf.$\backslash$ Object-Oriented Programming (ECOOP)},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:20GMT},
uri = {\url{papers2://publication/uuid/C4AFE6EE-9428-4A58-9CAB-B3FC2EAED57E}}
}

@inproceedings{ha2008wait,
author = {Ha, P H and Tsigas, P and Anshus, O J},
title = {{Wait-free programming for general purpose computations on graphics processors}},
booktitle = {ACM Symposium on Principles of Distributed Computing},
year = {2008},
pages = {452},
organization = {ACM},
affiliation = {ACM},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-05T17:39:37GMT},
uri = {\url{papers2://publication/uuid/A5A3BB9E-8B8D-47EF-AD94-57B4AB8510B1}}
}

@book{Czarnecki-2000,
author = {Czarnecki, Krzysztof and Eisenecker, Ulrich W},
title = {{Generative programming: methods, tools, and applications}},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
year = {2000},
address = {New York, NY, USA},
isbn = {0-201-30977-7},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/15B400EE-6498-4BC5-90CA-16532A3D49FD}}
}

@inproceedings{openarc,
author = {Lee, Seyong and Vetter, Jeffrey S},
title = {{OpenARC: open accelerator research compiler for directive-based, efficient heterogeneous computing}},
booktitle = {HPDC '14: Proceedings of the 23rd international symposium on High-performance parallel and distributed computing},
year = {2014},
publisher = {ACM},
month = jun,
doi = {10.1145/2600212.2600704},
rating = {0},
date-added = {2014-07-06T21:57:41GMT},
date-modified = {2014-07-06T21:58:10GMT},
abstract = {This paper presents Open Accelerator Research Compiler (OpenARC): an open-source framework that supports the full feature set of OpenACC V1.0 and performs source-to-source transformations, targeting heterogeneous devices, such as NVIDIA GPUs. Combined},
url = {http://portal.acm.org/citation.cfm?id=2600212.2600704&coll=DL&dl=GUIDE&CFID=505612272&CFTOKEN=49831496},
uri = {\url{papers2://publication/doi/10.1145/2600212.2600704}}
}

@inproceedings{cole-sci2003,
author = {Cole, M and Parker, S},
title = {{Dynamic Compilation of C++ Template Code}},
booktitle = {Scientific Programming},
year = {2003},
pages = {321--327},
publisher = {IOS Press},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://www.sci.utah.edu/publications/mcole01/dyn.pdf},
uri = {\url{papers2://publication/uuid/1354153C-F942-43AF-8DD5-D134362BD9B9}}
}

@techreport{nvidia2008cublas,
author = {NVIDIA, C},
title = {{CUBLAS Library}},
year = {2008},
publisher = {NVIDIA Corporation, Santa Clara, California},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/92F09F28-A12F-41D8-85B3-E06C8A3BCAB1}}
}

@inproceedings{manavski2007cuda,
author = {Manavski, S A},
title = {{CUDA compatible GPU as an efficient hardware accelerator for AES cryptography}},
booktitle = {Proc. IEEE International Conference on Signal Processing and Communication},
year = {2007},
pages = {65--68},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/495B1FD9-315A-4277-B123-7E38F047A59A}}
}

@inproceedings{ryoo2008program,
author = {Ryoo, S and Rodrigues, C I and Stone, S S and Baghsorkhi, Sara S and Ueng, S Z and Stratton, J A and Wen-mei, W.H.},
title = {{Program optimization space pruning for a multithreaded gpu}},
booktitle = {Proceedings of the sixth annual IEEE/ACM international symposium on Code generation and optimization},
year = {2008},
pages = {195--204},
organization = {ACM New York, NY, USA},
affiliation = {ACM New York, NY, USA},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:17GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Ryoo/Program_optimization_space_pruning_for_a_multithreaded_gpu_2008_Ryoo.pdf},
file = {{Program_optimization_space_pruning_for_a_multithreaded_gpu_2008_Ryoo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Ryoo/Program_optimization_space_pruning_for_a_multithreaded_gpu_2008_Ryoo.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/935AD439-63FC-4941-8669-6E2247BF60C7}}
}

@inproceedings{fatahalian-sc2006,
author = {Fatahalian, Kayvon and Knight, Timothy J and Houston, Mike and Erez, Mattan and Horn, Daniel Reiter and Leem, Larkhoon and Park, Ji Young and Ren, Manman and Aiken, Alex and Dally, William J and Hanrahan, Pat},
title = {{Sequoia: Programming the Memory Hierarchy}},
crossref = {supercomputing},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/65D91E0D-9773-4A3B-8EE4-5F9DE0B6A14C}}
}

@book{Esmaeilzadeh:2012eu,
author = {Esmaeilzadeh, Hadi and Sampson, Adrian and Ceze, Luis and Burger, Doug and Esmaeilzadeh, Hadi and Sampson, Adrian and Ceze, Luis and Burger, Doug},
title = {{Architecture support for disciplined approximate programming}},
publisher = {ACM},
year = {2012},
volume = {40},
address = {New York, New York, USA},
month = apr,
doi = {10.1145/2189750.2151008},
isbn = {978-1-4503-0759-8},
read = {Yes},
rating = {0},
date-added = {2012-10-18T22:19:14GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Abstract Disciplined approximate programming lets programmers declare which parts of a program can be computed approximately and consequently at a lower energy cost. The compiler proves statically that all approximate computation is properly isolated from ... 
},
url = {http://dl.acm.org/citation.cfm?doid=2150976.2151008},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2012/Esmaeilzadeh/Architecture_support_for_disciplined_approximate_programming_2012_Esmaeilzadeh.pdf},
file = {{Architecture_support_for_disciplined_approximate_programming_2012_Esmaeilzadeh.pdf:/Users/njustn/Dropbox/Papers2/Books/2012/Esmaeilzadeh/Architecture_support_for_disciplined_approximate_programming_2012_Esmaeilzadeh.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2189750.2151008}}
}

@article{smargadakis-tosem2002,
author = {Smaragdakis, Yannis and Batory, Don},
title = {{Mixin Layers: An Object-Oriented Implementation Technique for Refinements and Collaboration-Based Designs}},
journal = {ACM Transactions on Software Engineering and Methodologies (TOSEM)},
year = {2002},
volume = {11},
number = {2},
pages = {215--255},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/B08B6523-A0B6-4D38-A3F5-F1AA3C8B5FFA}}
}

@article{Jang:2011ct,
author = {Jang, Byunghyun and Schaa, D and Mistry, P and Kaeli, D},
title = {{Exploiting Memory Access Patterns to Improve Memory Performance in Data-Parallel Architectures}},
journal = {Parallel and Distributed Systems, IEEE Transactions on},
year = {2011},
volume = {22},
number = {1},
pages = {105--118},
doi = {10.1109/TPDS.2010.107},
read = {Yes},
rating = {0},
date-added = {2011-12-30T22:00:39GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {The introduction of General-Purpose computation on GPUs (GPGPUs) has changed the landscape for the future of parallel computing. At the core of this phenomenon are massively multithreaded, data-parallel architectures possessing impressive acceleration ratings, offering low-cost supercomputing together with attractive power budgets. Even given the numerous benefits provided by GPGPUs, there remain a number of barriers that delay wider adoption of these architectures. One major issue is the heterogeneous and distributed nature of the memory subsystem commonly found on data-parallel architectures. Application acceleration is highly dependent on being able to utilize the memory subsystem effectively so that all execution units remain busy. In this paper, we present techniques for enhancing the memory efficiency of applications on data-parallel architectures, based on the analysis and characterization of memory access patterns in loop bodies; we target vectorization via data transformation to benefit vector-based architectures (e.g., AMD GPUs) and algorithmic memory selection for scalar-based architectures (e.g., NVIDIA GPUs). We demonstrate the effectiveness of our proposed methods with kernels from a wide range of benchmark suites. For the benchmark kernels studied, we achieve consistent and significant performance improvements (up to 11.4 and 13.5 over baseline GPU implementations on each platform, respectively) by applying our proposed methodology.},
url = {http://ieeexplore.ieee.org/search/freesrchabstract.jsp?tp=&arnumber=5473222},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Jang/Exploiting_Memory_Access_Patterns_to_Improve_Memory_Performance_in_Data-Parallel_Architectures_2011_Jang.pdf},
file = {{Exploiting_Memory_Access_Patterns_to_Improve_Memory_Performance_in_Data-Parallel_Architectures_2011_Jang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Jang/Exploiting_Memory_Access_Patterns_to_Improve_Memory_Performance_in_Data-Parallel_Architectures_2011_Jang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/TPDS.2010.107}}
}

@article{Yelick:1998uk,
author = {Yelick, K and Semenzato, Luigi and Pike, G and Miyamoto, C},
title = {{Titanium: A high-performance Java dialect}},
journal = {Concurrency Practice {\ldots}},
year = {1998},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Titanium is a language and system for high - performance parallel scientific computing. Titanium uses Java as its base, thereby leveraging the advantages of that language and allowing us to focus attention on parallel computing issues. The main additions to Java are immutable ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.6703&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1998/Yelick/Titanium_A_high-performance_Java_dialect_1998_Yelick.pdf},
file = {{Titanium_A_high-performance_Java_dialect_1998_Yelick.pdf:/Users/njustn/Dropbox/Papers2/Articles/1998/Yelick/Titanium_A_high-performance_Java_dialect_1998_Yelick.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/4D015A9F-375E-4E55-8FFF-60EB71D4E131}}
}

@inproceedings{Bueno:2011go,
author = {Bueno, Javier and Duran, Alejandro and Martorell, Xavier and Ayguad{\'e}, Eduard and Badia, Rosa M and Labarta, Jes{\'u}s},
title = {{Poster: Programming Clusters of GPUs with OmpSs}},
crossref = {supercomputing},
year = {2011},
publisher = {ACM},
month = may,
doi = {10.1145/1995896.1995961},
read = {Yes},
rating = {0},
date-added = {2012-01-11T18:57:41GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {OmpSs is a programming model that provides an environment to develop parallel applications for cluster environments with heterogeneous architectures. Based on OpenMP and StarSs, it offers a set of compiler directives that can be used to annotate a sequential},
url = {http://portal.acm.org/citation.cfm?id=1995896.1995961&coll=DL&dl=GUIDE&CFID=61704752&CFTOKEN=92261478},
uri = {\url{papers2://publication/doi/10.1145/1995896.1995961}}
}

@inproceedings{Lin2005,
author = {Lin, H and Ma, X and Chandramohan, P and Geist, A and Samatova, N},
title = {{Efficient Data Access for Parallel BLAST}},
crossref = {ipdps},
year = {2005},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-07-05T17:43:45GMT},
url = {http://www.google.com/search?client=safari&rls=en-us&q=Efficient+Data+Access+for+Parallel+BLAST&ie=UTF-8&oe=UTF-8},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/Lin/Efficient_Data_Access_for_Parallel_BLAST_2005_Lin.pdf},
file = {{Efficient_Data_Access_for_Parallel_BLAST_2005_Lin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Lin/Efficient_Data_Access_for_Parallel_BLAST_2005_Lin.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/210C8E1E-FB2A-49CC-8175-2484146E8424}}
}

@article{Wentzlaff:2009jq,
author = {Wentzlaff, David and Agarwal, Anant},
title = {{Factored operating systems (fos)}},
journal = {ACM SIGOPS Operating Systems Review},
year = {2009},
volume = {43},
number = {2},
pages = {76},
month = apr,
doi = {10.1145/1531793.1531805},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-03-06T02:10:06GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {... to attack this problem and proposes how to build a factored  operating  system ( fos ) which em ... Section 3 describes the design of fos and how its design attacks scalability ... 2. Scalability Problems of Contemporary Operating  Systems This section investigates three main scalability ... 
},
url = {http://portal.acm.org/citation.cfm?doid=1531793.1531805},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Wentzlaff/Factored_operating_systems_(fos)_2009_Wentzlaff.pdf},
file = {{Factored_operating_systems_(fos)_2009_Wentzlaff.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Wentzlaff/Factored_operating_systems_(fos)_2009_Wentzlaff.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1531793.1531805}}
}

@article{Ruscio2006,
author = {Ruscio, Jory Z and Onufriev, Alexey},
title = {{A computational study of nucleosomal DNA flexibility.}},
journal = {Biophysical journal},
year = {2006},
volume = {91},
number = {11},
pages = {4121--4132},
doi = {10.1529/biophysj.106.082099},
pmid = {16891359},
read = {Yes},
rating = {0},
date-added = {2011-03-22T22:03:52GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Molecular dynamics simulations of the nucleosome core particle and its isolated DNA free in solution are reported. The simulations are based on the implicit solvent methodology and provide insights into the nature of large-scale structural fluctuations and flexibility of the nucleosomal DNA. In addition to the kinked regions previously identified in the x-ray structure of the nucleosome, the simulations support the existence of a biochemically identified distorted region of the DNA. Comparison of computed relative free energies shows that formation of the kinks is associated with little, if any, energy cost relative to a smooth, ideal conformation of the DNA superhelix. Isolated nucleosomal DNA is found to be considerably more flexible than expected for a 147 bp stretch of DNA based on its canonical persistence length of 500 A. Notably, the significant bending of the DNA observed in our simulations occurs without breaking of Watson-Crick bonds. The computed relative stability of bent conformations is sensitive to the ionic strength of the solution in the physiological range; the sensitivity suggests possible experiments that might provide further insights into the structural origins of the unusual flexibility of the DNA.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16891359},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Ruscio/A_computational_study_of_nucleosomal_DNA_flexibility._2006_Ruscio.pdf},
file = {{A_computational_study_of_nucleosomal_DNA_flexibility._2006_Ruscio.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Ruscio/A_computational_study_of_nucleosomal_DNA_flexibility._2006_Ruscio.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1529/biophysj.106.082099}}
}

@inproceedings{Chen:2010cy,
author = {Chen, Long and Villa, O and Krishnamoorthy, S and Gao, G.R},
title = {{Dynamic load balancing on single- and multi-GPU systems}},
crossref = {ipdps},
year = {2010},
pages = {1--12},
doi = {10.1109/IPDPS.2010.5470413},
read = {Yes},
rating = {0},
date-added = {2012-01-16T00:29:48GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {The computational power provided by many-core graphics processing units (GPUs) has been exploited in many applications. The programming techniques currently employed on these GPUs are not sufficient to address problems exhibiting irregular, and unbalanced workload. The problem is exacerbated when trying to effectively exploit multiple GPUs concurrently, which are commonly available in many modern systems. In this paper, we propose a task-based dynamic load-balancing solution for single-and multi-GPU systems. The solution allows load balancing at a finer granularity than what is supported in current GPU programming APIs, such as NVIDIA's CUDA. We evaluate our approach using both micro-benchmarks and a molecular dynamics application that exhibits significant load imbalance. Experimental results with a single-GPU configuration show that our fine-grained task solution can utilize the hardware more efficiently than the CUDA scheduler for unbalanced workload. On multi-GPU systems, our solution achieves near-linear speedup, load balance, and significant performance improvement over techniques based on standard CUDA APIs.},
url = {http://ieeexplore.ieee.org/search/freesrchabstract.jsp?tp=&arnumber=5470413},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Chen/Dynamic_load_balancing_on_single-_and_multi-GPU_systems_2010_Chen.pdf},
file = {{Dynamic_load_balancing_on_single-_and_multi-GPU_systems_2010_Chen.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Chen/Dynamic_load_balancing_on_single-_and_multi-GPU_systems_2010_Chen.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2010.5470413}}
}

@article{DURAN:2011uy,
author = {Duran, Alejandro and Ayguad{\'e}, Eduard and Badia, Rosa M and Labarta, J. and Martinell, L and Martorell, Xavier and Planas, J},
title = {{OmpSs: A Proposal for Programming Heterogeneous Multi-Core Architectures}},
journal = {Parallel Processing Letters},
year = {2011},
volume = {21},
number = {2},
pages = {173--193},
read = {Yes},
rating = {0},
date-added = {2012-01-21T18:38:39GMT},
date-modified = {2014-07-04T05:00:12GMT},
url = {http://www.worldscinet.com/abstract?id=pii:S0129626411000151},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Duran/OmpSs_A_Proposal_for_Programming_Heterogeneous_Multi-Core_Architectures_2011_Duran.pdf},
file = {{OmpSs_A_Proposal_for_Programming_Heterogeneous_Multi-Core_Architectures_2011_Duran.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Duran/OmpSs_A_Proposal_for_Programming_Heterogeneous_Multi-Core_Architectures_2011_Duran.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DE4B7681-2BF4-4AE0-88B0-0D2112E1F24A}}
}

@article{Lin:2011du,
author = {Lin, Heshan and Ma, Xiaosong and Feng, Wu{-chun}},
title = {{Reliable MapReduce computing on opportunistic resources}},
journal = {Cluster Computing},
year = {2011},
month = feb,
keywords = {ipdps11-omp-co},
doi = {10.1007/s10586-011-0158-7},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:49:04GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {Abstract MapReduce offers an ease-of-use programming paradigm for processing large data sets, making it an attractive model for opportunistic compute resources . However, unlike dedicated resources , where MapReduce has mostly been deployed, opportunistic  ...},
url = {http://www.springerlink.com/index/10.1007/s10586-011-0158-7},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Lin/Reliable_MapReduce_computing_on_opportunistic_resources_2011_Lin.pdf},
file = {{Reliable_MapReduce_computing_on_opportunistic_resources_2011_Lin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Lin/Reliable_MapReduce_computing_on_opportunistic_resources_2011_Lin.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/s10586-011-0158-7}}
}

@article{Wang:2007vy,
author = {Wang, HJ and Fan, X and Howell, J},
title = {{Protection and communication abstractions for web browsers in MashupOS}},
journal = {ACM SIGOPS Operating Systems Review},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:50:06GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {... ble 1. We give our proposal of the CommRequest abstraction for cross-domain communications and the ... turn an open content into an unauthorized content with our sandbox browser abstraction (described in ... that the origin of a private sandbox is relevant for its protection but not ...},
url = {http://portal.acm.org/citation.cfm?id=1294263},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Wang/Protection_and_communication_abstractions_for_web_browsers_in_MashupOS_2007_Wang.pdf},
file = {{Protection_and_communication_abstractions_for_web_browsers_in_MashupOS_2007_Wang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Wang/Protection_and_communication_abstractions_for_web_browsers_in_MashupOS_2007_Wang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F3502C76-842A-4DA1-9077-9F3519E251F3}}
}

@article{Scogland:2010bz,
author = {Scogland, Thomas R W and Lin, Heshan and Feng, Wu{-chun}},
title = {{A First Look at Integrated GPUs for Green High-performance Computing}},
journal = {Computer Science-Research and Development},
year = {2010},
volume = {25},
number = {3-4},
pages = {125--134},
month = aug,
doi = {10.1007/s00450-010-0128-y},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-04-09T17:12:38GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {Abstract The graphics processing unit (GPU) has evolved from a single-purpose graphics accelerator to a tool that can greatly accelerate the performance of high-performance computing (HPC) applications. Previous studies have shown that discrete GPUs, while energy efficient for ...},
url = {http://www.springerlink.com/index/10.1007/s00450-010-0128-y},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Scogland/A_First_Look_at_Integrated_GPUs_for_Green_High-performance_Computing_2010_Scogland.pdf},
file = {{A_First_Look_at_Integrated_GPUs_for_Green_High-performance_Computing_2010_Scogland.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Scogland/A_First_Look_at_Integrated_GPUs_for_Green_High-performance_Computing_2010_Scogland.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/s00450-010-0128-y}}
}

@article{MellorCrummey:1991jc,
author = {Mellor-Crummey, John M and Scott, Michael L},
title = {{Algorithms for scalable synchronization on shared-memory multiprocessors}},
journal = {ACM Transactions on Computer Systems},
year = {1991},
volume = {9},
number = {1},
pages = {21--65},
month = feb,
doi = {10.1145/103727.103729},
read = {Yes},
rating = {0},
date-added = {2013-03-07T19:46:06GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Abstract Busy-wait techniques are heavily used for mutual exclusion and barrier synchronization in shared - memory parallel programs. Unfortunately, typical implementations of busy-waiting tend to produce large amounts of memory and interconnect contention, ... 
},
url = {http://portal.acm.org/citation.cfm?doid=103727.103729},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1991/Mellor-Crummey/Algorithms_for_scalable_synchronization_on_shared-memory_multiprocessors_1991_Mellor-Crummey.pdf},
file = {{Algorithms_for_scalable_synchronization_on_shared-memory_multiprocessors_1991_Mellor-Crummey.pdf:/Users/njustn/Dropbox/Papers2/Articles/1991/Mellor-Crummey/Algorithms_for_scalable_synchronization_on_shared-memory_multiprocessors_1991_Mellor-Crummey.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/103727.103729}}
}

@article{McCormick:2007ex,
author = {McCormick, P and Inman, J and Ahrens, J and MOHDYUSOF, J and ROTH, G and Cummins, S},
title = {{Scout: a data-parallel programming language for graphics processors}},
journal = {Parallel Computing},
year = {2007},
month = sep,
keywords = {ipdps11-omp-co},
doi = {10.1016/j.parco.2007.09.001},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:49:28GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Commodity graphics hardware has seen incredible growth in terms of performance, programmability, and arithmetic precision. Even though these trends have been primarily driven by the entertainment industry, the price-to-performance ratio of graphics processors ...},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167819107001019},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/McCormick/Scout_a_data-parallel_programming_language_for_graphics_processors_2007_McCormick.pdf},
file = {{Scout_a_data-parallel_programming_language_for_graphics_processors_2007_McCormick.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/McCormick/Scout_a_data-parallel_programming_language_for_graphics_processors_2007_McCormick.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.parco.2007.09.001}}
}

@article{Petsko:2007kg,
author = {Petsko, Gregory A},
title = {{A day in the life of a genome biologist in the not-too-distant future}},
journal = {Genome Biology},
year = {2007},
volume = {8},
number = {3},
pages = {104},
annote = {Indeed not-to-distant future: 
"6:15 pm to 7 pm.packed up to go home. Waited 45 minutes for shuttle bus to parking lot. while waiting, checked latest news on iPhone."},
affiliation = {Rosenstiel Basic Medical Sciences Research Center, Brandeis University, Waltham, MA 02454-9110, USA. petsko@brandeis.edu},
doi = {10.1186/gb-2007-8-3-104},
pmid = {17397521},
read = {Yes},
rating = {4},
date-added = {2009-02-06T15:41:58GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {A look into the future of a biologist: daily activities governed by presidential mandates and acts.},
url = {http://genomebiology.com/2007/8/3/104},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Petsko/A_day_in_the_life_of_a_genome_biologist_in_the_not-too-distant_future_2007_Petsko.pdf},
file = {{A_day_in_the_life_of_a_genome_biologist_in_the_not-too-distant_future_2007_Petsko.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Petsko/A_day_in_the_life_of_a_genome_biologist_in_the_not-too-distant_future_2007_Petsko.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1186/gb-2007-8-3-104}}
}

@inproceedings{Zhuravlev:2010tl,
author = {Zhuravlev, Sergey and Blagodurov, Sergey and Fedorova, Alexandra},
title = {{Addressing shared resource contention in multicore processors via scheduling}},
booktitle = {International Conference on Architectural Support for Programming Languages and Operating Systems},
year = {2010},
publisher = {ACM},
month = mar,
doi = {10.1145/1736020.1736036},
read = {Yes},
rating = {0},
date-added = {2011-03-31T02:21:51GMT},
date-modified = {2014-07-05T20:27:05GMT},
abstract = {Contention for shared resources on multicore processors remains an unsolved problem in existing systems despite significant research efforts dedicated to this problem in the past. Previous solutions focused primarily on hardware techniques and software},
url = {http://portal.acm.org/citation.cfm?id=1736020.1736036&coll=DL&dl=GUIDE&CFID=503059456&CFTOKEN=23607131},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Zhuravlev/Addressing_shared_resource_contention_in_multicore_processors_via_scheduling_2010_Zhuravlev.pdf},
file = {{Addressing_shared_resource_contention_in_multicore_processors_via_scheduling_2010_Zhuravlev.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Zhuravlev/Addressing_shared_resource_contention_in_multicore_processors_via_scheduling_2010_Zhuravlev.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1736020.1736036}}
}

@article{Chu:2007wt,
author = {Chu, CT and Kim, SK and Lin, YA and Yu, YY},
title = {{Map-reduce for machine learning on multicore}},
journal = {Advances in Neural {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:12:45GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Map - Reduce for Machine Learning on Multicore Cheng-Tao Chu Sang Kyun Kim Yi-An Lin chengtao@ stanford. edu skkim38@ stanford. edu ianl@ stanford. edu YuanYuan Yu Gary Bradski Andrew Y. Ng yuanyuan@ stanford. edu garybradski@ gmail ang@ cs. ...},
url = {http://books.google.com/books?hl=en&lr=&id=Tbn1l9P1220C&oi=fnd&pg=PA281&dq=map+reduce+for+machine+learning+on+multicore&ots=V2k8Efjp21&sig=hEyMqcRMfw_eIwZsrOFmJxG_aoY},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Chu/Map-reduce_for_machine_learning_on_multicore_2007_Chu.pdf},
file = {{Map-reduce_for_machine_learning_on_multicore_2007_Chu.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Chu/Map-reduce_for_machine_learning_on_multicore_2007_Chu.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5A0F7D4C-CACD-4DD1-B110-C130B65D980C}}
}

@inproceedings{Tzeng:2010ti,
author = {Tzeng, Stanley and Patney, Anjul and Owens, John D},
title = {{Task management for irregular-parallel workloads on the GPU}},
booktitle = {HPG '10: Proceedings of the Conference on High Performance Graphics},
year = {2010},
publisher = { Eurographics Association},
month = jun,
read = {Yes},
rating = {0},
date-added = {2012-03-27T20:33:54GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {We explore software mechanisms for managing irregular tasks on graphics processing units (GPUs). We demonstrate that dynamic scheduling and efficient memory management are critical problems in achieving high efficiency on irregular workloads. We experiment},
url = {http://portal.acm.org/citation.cfm?id=1921479.1921485&coll=DL&dl=GUIDE&CFID=74371648&CFTOKEN=64091836},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Tzeng/Task_management_for_irregular-parallel_workloads_on_the_GPU_2010_Tzeng.pdf},
file = {{Task_management_for_irregular-parallel_workloads_on_the_GPU_2010_Tzeng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Tzeng/Task_management_for_irregular-parallel_workloads_on_the_GPU_2010_Tzeng.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/4F11365F-5039-4A24-B03D-4172DB87D17A}}
}

@book{Anonymous:mJJpsIRB,
title = {{ACM SIGARCH Computer Architecture News}},
publisher = {ACM},
issn = {0163-5964},
rating = {0},
date-added = {2012-10-18T22:19:24GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/989269B0-8441-4726-BFD5-34FCDA3CE8E9}}
}

@article{Bueno:2012ka,
author = {Bueno, J and Planas, J and Duran, Alejandro and Badia, Rosa M and Martorell, Xavier and Ayguad{\'e}, Eduard and Labarta, J.},
title = {{Productive Programming of GPU Clusters with OmpSs}},
journal = {International Parallel and Distributed Processing Symposium},
year = {2012},
pages = {557--568},
doi = {10.1109/IPDPS.2012.58},
read = {Yes},
rating = {0},
date-added = {2012-10-31T00:36:27GMT},
date-modified = {2014-07-05T17:43:45GMT},
abstract = {Clusters of GPUs are emerging as a new computational scenario. Programming them requires the use of hybrid models that increase the complexity of the applications, reducing the productivity of programmers. We present the implementation of OmpSs for clusters of GPUs, which supports asynchrony and heterogeneity for task parallelism. It is based on annotating a serial application with directives that are translated by the compiler. With it, the same program that runs sequentially in a node with a single GPU can run in parallel in multiple GPUs either local (single node) or remote (cluster of GPUs). Besides performing a task-based parallelization, the runtime system moves the data as needed between the different nodes and GPUs minimizing the impact of communication by using affinity scheduling, caching, and by overlapping communication with the computational task. We show several applications programmed with OmpSs and their performance with multiple GPUs in a local node and in remote nodes. The results show good tradeoff between performance and effort from the programmer. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6267858&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Productive+Programming+of+GPU+Clusters+with+OmpSs%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Bueno/Productive_Programming_of_GPU_Clusters_with_OmpSs_2012_Bueno.pdf},
file = {{Productive_Programming_of_GPU_Clusters_with_OmpSs_2012_Bueno.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Bueno/Productive_Programming_of_GPU_Clusters_with_OmpSs_2012_Bueno.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2012.58}}
}

@inproceedings{Sim:2012ce,
author = {Sim, Jaewoong and Dasgupta, Aniruddha and Kim, Hyesoon and Vuduc, Richard},
title = {{A performance analysis framework for identifying potential benefits in GPGPU applications}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2012},
publisher = {ACM},
month = feb,
doi = {10.1145/2145816.2145819},
read = {Yes},
rating = {0},
date-added = {2012-03-29T02:16:36GMT},
date-modified = {2014-07-05T17:36:15GMT},
abstract = {Tuning code for GPGPU and other emerging many-core platforms is a challenge because few models or tools can precisely pinpoint the root cause of performance bottlenecks. In this paper, we present a performance analysis framework that can help shed light},
url = {http://portal.acm.org/citation.cfm?id=2145816.2145819&coll=DL&dl=GUIDE&CFID=94173570&CFTOKEN=19513318},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Sim/A_performance_analysis_framework_for_identifying_potential_benefits_in_GPGPU_applications_2012_Sim.pdf},
file = {{A_performance_analysis_framework_for_identifying_potential_benefits_in_GPGPU_applications_2012_Sim.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Sim/A_performance_analysis_framework_for_identifying_potential_benefits_in_GPGPU_applications_2012_Sim.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2145816.2145819}}
}

@article{Lowenthal:2010uz,
author = {Lowenthal, Barry Louis Rountree David K},
title = {{Theory and practice of dynamic voltage/frequency scaling in the high performance computing environment}},
journal = {Theory and practice of dynamic voltage/frequency scaling in the high performance computing environment},
year = {2010},
month = jan,
publisher = { University of Arizona},
read = {Yes},
rating = {0},
date-added = {2012-01-23T04:32:37GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://portal.acm.org/citation.cfm?id=1970945&coll=DL&dl=GUIDE&CFID=63255266&CFTOKEN=12559758},
uri = {\url{papers2://publication/uuid/722DCAA1-A9CA-4FAC-B595-6732666FC9B9}}
}

@inproceedings{Rountree:2007bv,
author = {Rountree, Barry and Lowenthal, David K and Funk, Shelby and Freeh, Vincent W and de Supinski, Bronis R and Schulz, Martin},
title = {{Bounding energy consumption in large-scale MPI programs}},
crossref = {supercomputing},
year = {2007},
pages = {1--9},
doi = {10.1145/1362622.1362688},
read = {Yes},
rating = {0},
date-added = {2012-01-23T04:33:57GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Power is now a first-order design constraint in large-scale parallel computing. Used carefully, dynamic voltage scaling can execute parts of a program at a slower CPU speed to achieve energy savings with a relatively small (possibly zero) time delay. However, the problem of when to change frequencies in order to optimize energy savings is NP-complete, which has led to many heuristic energy-saving algorithms. To determine how closely these algorithms approach optimal savings, we developed a system that determines a bound on the energy savings for an application. Our system uses a linear programming solver that takes as inputs the application communication trace and the cluster power characteristics and then outputs a schedule that realizes this bound. We apply our system to three scientific programs, two of which exhibit load imbalance---particle simulation and UMT2K. Results from our bounding technique show particle simulation is more amenable to energy savings than UMT2K.},
url = {http://ieeexplore.ieee.org/search/freesrchabstract.jsp?tp=&arnumber=5348808},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Rountree/Bounding_energy_consumption_in_large-scale_MPI_programs_2007_Rountree.pdf},
file = {{Bounding_energy_consumption_in_large-scale_MPI_programs_2007_Rountree.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Rountree/Bounding_energy_consumption_in_large-scale_MPI_programs_2007_Rountree.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1362622.1362688}}
}

@inproceedings{Kulkarni:2009ix,
author = {Kulkarni, Milind and Burtscher, Martin and Inkulu, Rajeshkar and Pingali, Keshav and Cas{\c c}aval, Calin},
title = {{How much parallelism is there in irregular applications?}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2009},
publisher = {ACM},
month = feb,
doi = {10.1145/1504176.1504181},
read = {Yes},
rating = {0},
date-added = {2012-11-03T12:54:14GMT},
date-modified = {2014-07-05T17:36:15GMT},
abstract = {Irregular programs are programs organized around pointer-based data structures such as trees and graphs. Recent investigations by the Galois project have shown that many irregular programs have a generalized form of data-parallelism called amorphous},
url = {http://portal.acm.org/citation.cfm?id=1504176.1504181&coll=DL&dl=GUIDE&CFID=136447126&CFTOKEN=31048127},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Kulkarni/How_much_parallelism_is_there_in_irregular_applications_2009_Kulkarni.pdf},
file = {{How_much_parallelism_is_there_in_irregular_applications_2009_Kulkarni.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Kulkarni/How_much_parallelism_is_there_in_irregular_applications_2009_Kulkarni.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1504176.1504181}}
}

@inproceedings{Rountree:2009in,
author = {Rountree, Barry and Lownenthal, David K and de Supinski, Bronis R and Schulz, Martin and Freeh, Vincent W and Bletsch, Tyler},
title = {{Adagio: making DVS practical for complex HPC applications}},
booktitle = {ACM International Conference on Supercomputing},
year = {2009},
publisher = {ACM},
month = jun,
doi = {10.1145/1542275.1542340},
read = {Yes},
rating = {0},
date-added = {2012-01-23T04:38:25GMT},
date-modified = {2014-07-05T17:44:21GMT},
abstract = {Power and energy are first-order design constraints in high performance computing. Current research using dynamic voltage scaling (DVS) relies on trading increased execution time for energy savings, which is unacceptable for most high performance computing},
url = {http://portal.acm.org/citation.cfm?id=1542275.1542340&coll=DL&dl=GUIDE&CFID=63255266&CFTOKEN=12559758},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Rountree/Adagio_making_DVS_practical_for_complex_HPC_applications_2009_Rountree.pdf},
file = {{Adagio_making_DVS_practical_for_complex_HPC_applications_2009_Rountree.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Rountree/Adagio_making_DVS_practical_for_complex_HPC_applications_2009_Rountree.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1542275.1542340}}
}

@article{Valiant:1990td,
author = {Valiant, LG},
title = {{A Bridging Model for Parallel Computation}},
journal = {Communications of the ACM},
year = {1990},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-07-05T21:11:35GMT},
abstract = {I na conventional sequential computer, processing is chan- nelled through one physical location. In a pa.rallel machine, processing can occur simulta- neously at many locations and consequently many more computa- tional operations per second should be achievable. ...},
url = {http://portal.acm.org/citation.cfm?id=79173.79181},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1990/Valiant/A_Bridging_Model_for_Parallel_Computation_1990_Valiant-1.pdf},
file = {{A_Bridging_Model_for_Parallel_Computation_1990_Valiant-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/1990/Valiant/A_Bridging_Model_for_Parallel_Computation_1990_Valiant-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/421DB3BD-E539-4083-BDFC-41B6BEAF03B0}}
}

@article{Mueller:2006we,
author = {Mueller, C},
title = {{Runtime synthesis of high-performance code from scripting languages}},
journal = {{\ldots} programming systems},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Scripting languages are ubiquitous in modern software engineering and are often used as the sole language for application development. However, some applications, specifically scientific and multimedia applications, often have small sections of code that require a higher level ...},
url = {http://portal.acm.org/citation.cfm?id=1176617.1176754},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Mueller/Runtime_synthesis_of_high-performance_code_from_scripting_languages_2006_Mueller.pdf},
file = {{Runtime_synthesis_of_high-performance_code_from_scripting_languages_2006_Mueller.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Mueller/Runtime_synthesis_of_high-performance_code_from_scripting_languages_2006_Mueller.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/20D429AE-7FC6-4914-B893-123CDB221A7E}}
}

@inproceedings{Knight:2007ue,
author = {Knight, TJ and Park, JY and Ren, M and Houston, M},
title = {{Compilation for explicitly managed memory hierarchies}},
booktitle = {Proceedings of the {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {1. Introduction The advances in semiconductor technology that have dramatically increased the performance possible on a single chip have also un- dermined the classical random-access model of memory : the idea that a processor can access every memory address in a ...},
url = {http://portal.acm.org/citation.cfm?id=1229477},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Knight/Compilation_for_explicitly_managed_memory_hierarchies_2007_Knight.pdf},
file = {{Compilation_for_explicitly_managed_memory_hierarchies_2007_Knight.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Knight/Compilation_for_explicitly_managed_memory_hierarchies_2007_Knight.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/18688B1D-8AFA-4618-867E-A4833C2D9B43}}
}

@article{Fleming:1986cs,
author = {Fleming, Philip J and Wallace, John J},
title = {{How not to lie with statistics: the correct way to summarize benchmark results}},
journal = {Commun. ACM},
year = {1986},
volume = {29},
number = {3},
pages = {218--221},
month = mar,
doi = {10.1145/5666.5673},
read = {Yes},
rating = {0},
date-added = {2012-11-03T12:54:47GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {In the literature, performance results are frequently summarized using i.he arithmetic mean of performance ratios, leading, in some cases, to wrong conclusions (see Tables 2 and 3 in [Z]) or, at best, inappropriate statistics (see Tables' 12 and 13 in [3]). We hope to elucidate this ... 
},
url = {http://portal.acm.org/citation.cfm?doid=5666.5673},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1986/Fleming/How_not_to_lie_with_statistics_the_correct_way_to_summarize_benchmark_results_1986_Fleming.pdf},
file = {{How_not_to_lie_with_statistics_the_correct_way_to_summarize_benchmark_results_1986_Fleming.pdf:/Users/njustn/Dropbox/Papers2/Articles/1986/Fleming/How_not_to_lie_with_statistics_the_correct_way_to_summarize_benchmark_results_1986_Fleming.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/5666.5673}}
}

@article{Felderman:1995ty,
author = {Felderman, RE and Kulawik, AE and Seitz, CL and Seizovic, J},
title = {{Myrinet: A Gigabit-per-Second Local Area Network}},
journal = {IEEE Micro},
year = {1995},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {As soon as the cut-through-routing circuit decodes the head- er, it advances the packet into the required outgoing channel if it is not already in use. Otherwise, the packet is blocked, as in the top-center node, until the outgoing channel becomes available. The x-then-y dimension- ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.9782&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1995/Felderman/Myrinet_A_Gigabit-per-Second_Local_Area_Network_1995_Felderman.pdf},
file = {{Myrinet_A_Gigabit-per-Second_Local_Area_Network_1995_Felderman.pdf:/Users/njustn/Dropbox/Papers2/Articles/1995/Felderman/Myrinet_A_Gigabit-per-Second_Local_Area_Network_1995_Felderman.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/220A7250-A74C-41C5-97BD-D5ED27CC197B}}
}

@inproceedings{Katabi:2002vy,
author = {Katabi, D and Handley, M},
title = {{Congestion control for high bandwidth-delay product networks}},
booktitle = {Proceedings of the 2002 {\ldots}},
year = {2002},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {ABSTRACT Theory and experiments show that as the per-flow product of band- width and latency increases, TCP becomes inefficient and prone to instability, regardless of the queuing scheme. This failing becomes increasingly important as the Internet evolves to ...},
url = {http://portal.acm.org/citation.cfm?id=633035},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2002/Katabi/Congestion_control_for_high_bandwidth-delay_product_networks_2002_Katabi.pdf},
file = {{Congestion_control_for_high_bandwidth-delay_product_networks_2002_Katabi.pdf:/Users/njustn/Dropbox/Papers2/Articles/2002/Katabi/Congestion_control_for_high_bandwidth-delay_product_networks_2002_Katabi.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CB310224-15E7-4ACE-94A7-EAD72E8D290C}}
}

@inproceedings{Nataraj:2007hn,
author = {Nataraj, A and Morris, A and Malony, AD},
title = {{The ghost in the machine: observing the effects of kernel operation on parallel application performance}},
crossref = {supercomputing},
year = {2007},
pages = {1--12},
doi = {10.1145/1362622.1362662},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Page 1. The Ghost in the Machine : Observing the Effects of Kernel  Operation on Parallel Application  Performance Aroon Nataraj Department of Computer {\&} Information Science University of Oregon Eugene, OR anataraj@cs.uoregon.edu ...},
url = {http://portal.acm.org/citation.cfm?id=1362662},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Nataraj/The_ghost_in_the_machine_observing_the_effects_of_kernel_operation_on_parallel_application_performance_2007_Nataraj.pdf},
file = {{The_ghost_in_the_machine_observing_the_effects_of_kernel_operation_on_parallel_application_performance_2007_Nataraj.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Nataraj/The_ghost_in_the_machine_observing_the_effects_of_kernel_operation_on_parallel_application_performance_2007_Nataraj.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1362622.1362662}}
}

@inproceedings{Bae:2012ix,
author = {Bae, Chang S and Xia, Lei and Dinda, Peter and Lange, John},
title = {{Dynamic adaptive virtual core mapping to improve power, energy, and performance in multi-socket multicores}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2012},
publisher = {ACM},
month = jun,
doi = {10.1145/2287076.2287114},
rating = {0},
date-added = {2012-11-06T07:32:23GMT},
date-modified = {2014-07-05T17:42:14GMT},
abstract = {Consider a multithreaded parallel application running inside a multicore virtual machine context that is itself hosted on a multi-socket multicore physical machine. How should the VMM map virtual cores to physical cores? We compare a local mapping},
url = {http://portal.acm.org/citation.cfm?id=2287076.2287114&coll=DL&dl=GUIDE&CFID=194014339&CFTOKEN=38243166},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Bae/Dynamic_adaptive_virtual_core_mapping_to_improve_power_energy_and_performance_in_multi-socket_multicores_2012_Bae.pdf},
file = {{Dynamic_adaptive_virtual_core_mapping_to_improve_power_energy_and_performance_in_multi-socket_multicores_2012_Bae.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Bae/Dynamic_adaptive_virtual_core_mapping_to_improve_power_energy_and_performance_in_multi-socket_multicores_2012_Bae.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2287076.2287114}}
}

@inproceedings{Manovit:2006ua,
author = {Manovit, C and Hangal, S and Chafi, H},
title = {{Testing implementations of transactional memory}},
booktitle = {Proceedings of the {\ldots}},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {ABSTRACT Transactional memory is an attractive design concept for scalable multiprocessors because it offers efficient lock-free synchronization and greatly simplifies parallel software. Given the subtle issues involved with concurrency and atom- icity, however, it is important that ...},
url = {http://portal.acm.org/citation.cfm?id=1152177},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Manovit/Testing_implementations_of_transactional_memory_2006_Manovit.pdf},
file = {{Testing_implementations_of_transactional_memory_2006_Manovit.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Manovit/Testing_implementations_of_transactional_memory_2006_Manovit.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C513954C-0D9E-4948-8262-CDEE041A6DDB}}
}

@article{Zheng:2005dl,
author = {Zheng, Xuan and Veeraraghavan, M and Rao, N.S.V and Wu, Qishi and Zhu, Mengxia},
title = {{CHEETAH: circuit-switched high-speed end-to-end transport architecture testbed}},
journal = {Communications Magazine, IEEE},
year = {2005},
volume = {43},
number = {8},
doi = {10.1109/MCOM.2005.1497551},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=1497551&queryText%3D%28cheetah+circuit+switched+high+speed+end+to+end+transport+architecture%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/Zheng/CHEETAH_circuit-switched_high-speed_end-to-end_transport_architecture_testbed_2005_Zheng.pdf},
file = {{CHEETAH_circuit-switched_high-speed_end-to-end_transport_architecture_testbed_2005_Zheng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Zheng/CHEETAH_circuit-switched_high-speed_end-to-end_transport_architecture_testbed_2005_Zheng.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/MCOM.2005.1497551}}
}

@article{Petrini:2001cn,
author = {Petrini, F and Feng, Wu{-chun} and Hoisie, A and Coll, Salvador and Frachtenberg, E},
title = {{The Quadrics network (QsNet): high-performance clustering technology}},
journal = {Hot Interconnects 9, 2001},
year = {2001},
pages = {125--130},
doi = {10.1109/HIS.2001.946704},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {The Quadrics interconnection network (QsNet) contributes two novel innovations to the field of high-performance interconnects: (I) integration of the virtual-address spaces of individual nodes into a single, global, virtual-address space and (2) network fault tolerance via link-level and end-to-end protocols that can detect faults and automatically re-transmit packets. QsNet achieves these feats by extending the native operating system in the nodes with a network operating system and specialized hardware support in the network interface. As these and other important features of QsNet can be found in the InfiniBand specification, QsNet can be viewed as a precursor to InfiniBand. In this paper, we present an initial performance evaluation of QsNet. We first describe the main hardware and software features of QsNet, followed by the results of benchmarks that we ran on our experimental, Intel-based, Linux cluster built around QsNet. Our initial analysis indicates that QsNet performs remarkably well, e.g., user-level latency under 2 $\mu$s and bandwidth over 300 MB/s},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=946704&queryText%3D%28the+quadrics+network+qsnet+high+performance+clustering+technology%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2001/Petrini/The_Quadrics_network_(QsNet)_high-performance_clustering_technology_2001_Petrini.pdf},
file = {{The_Quadrics_network_(QsNet)_high-performance_clustering_technology_2001_Petrini.pdf:/Users/njustn/Dropbox/Papers2/Articles/2001/Petrini/The_Quadrics_network_(QsNet)_high-performance_clustering_technology_2001_Petrini.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/HIS.2001.946704}}
}

@article{Chu:2007wta,
author = {Chu, CT and Kim, SK and Lin, YA and Yu, YY},
title = {{Map-reduce for machine learning on multicore}},
journal = {Advances in Neural {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Map - Reduce for Machine Learning on Multicore Cheng-Tao Chu Sang Kyun Kim Yi-An Lin chengtao@ stanford. edu skkim38@ stanford. edu ianl@ stanford. edu YuanYuan Yu Gary Bradski Andrew Y. Ng yuanyuan@ stanford. edu garybradski@ gmail ang@ cs. ...},
url = {http://books.google.com/books?hl=en&lr=&id=Tbn1l9P1220C&oi=fnd&pg=PA281&dq=map+reduce+for+machine+learning+on+multicore&ots=V2k8Fipm-Y&sig=SUR6X-90YrhpWkrrM89YFryHKPM},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Chu/Map-reduce_for_machine_learning_on_multicore_2007_Chu-2.pdf},
file = {{Map-reduce_for_machine_learning_on_multicore_2007_Chu-2.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Chu/Map-reduce_for_machine_learning_on_multicore_2007_Chu-2.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/226FF92F-30D7-4C62-8A41-3BAAF9397275}}
}

@inproceedings{Augonnet:2009uc,
author = {Augonnet, C{\'e}dric and Thibault, Samuel and Namyst, Raymond and Wacrenier, Pierre-Andr{\'e}},
title = {{StarPU: A Unified Platform for Task Scheduling on Heterogeneous Multicore Architectures}},
booktitle = {International Euro-Par Conference on Parallel Processing},
year = {2009},
publisher = { Springer-Verlag},
month = aug,
keywords = {ipdps11-omp-co},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:49:55GMT},
date-modified = {2014-07-05T17:30:46GMT},
abstract = {In the field of HPC, the current hardware trend is to design multiprocessor architectures that feature heterogeneous technologies such as specialized coprocessors (<em>e.g.</em> Cell/BE SPUs) or data-parallel accelerators (<em>e.g.</em>},
url = {http://www.springerlink.com/index/h013578235633mw3.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Augonnet/StarPU_A_Unified_Platform_for_Task_Scheduling_on_Heterogeneous_Multicore_Architectures_2009_Augonnet.pdf},
file = {{StarPU_A_Unified_Platform_for_Task_Scheduling_on_Heterogeneous_Multicore_Architectures_2009_Augonnet.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Augonnet/StarPU_A_Unified_Platform_for_Task_Scheduling_on_Heterogeneous_Multicore_Architectures_2009_Augonnet.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1E43F8DE-3270-4AE9-8F14-06F2C7C2E5DE}}
}

@webpage{Anonymous:ZsDVQW-d,
title = {{RFC 1323 TCP Extensions for High Performance}},
year = {2007},
month = oct,
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:18GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Unknown/RFC_1323_TCP_Extensions_for_High_Performance_2007.webarchive},
file = {{RFC_1323_TCP_Extensions_for_High_Performance_2007.webarchive:/Users/njustn/Dropbox/Papers2/Articles/2007/Unknown/RFC_1323_TCP_Extensions_for_High_Performance_2007.webarchive:application/x-safari}},
uri = {\url{papers2://publication/uuid/66C0D541-6F9D-4354-975B-5D0EEAF08281}}
}

@inproceedings{Seltzer:2000un,
author = {Seltzer, MI and Ganger, GR and McKusick, MK},
title = {{Journaling versus soft updates: Asynchronous meta-data protection in file systems}},
booktitle = {Proceedings of the {\ldots}},
year = {2000},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:51:09GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {...  Journaling versus soft  updates : asynchronous  meta - data  protection in file  systems . ...  systems use an auxiliary log to record meta - data operations and Soft  Updates uses ordered writes to ... The commercial sector has moved en masse to journaling  file  systems , as evidenced by their ...},
url = {http://portal.acm.org/citation.cfm?id=1267730},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Seltzer/Journaling_versus_soft_updates_Asynchronous_meta-data_protection_in_file_systems_2000_Seltzer.pdf},
file = {{Journaling_versus_soft_updates_Asynchronous_meta-data_protection_in_file_systems_2000_Seltzer.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Seltzer/Journaling_versus_soft_updates_Asynchronous_meta-data_protection_in_file_systems_2000_Seltzer.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/BE329C36-0DB0-4F4F-991F-34E8EDA28A5A}}
}

@article{Moravan:2006vr,
author = {Moravan, MJ and Bobba, J and Moore, KE and Yen, L},
title = {{Supporting nested transactional memory in LogTM}},
journal = {ACM SIGPLAN {\ldots}},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {This work is supported in part by the National Science Foundation (NSF), with grants CCF-0085949, CCR-0105721, EIA/CNS-0205286, CCR-0324878, as well as dona- tions from Intel and Sun Microsystems. Bobba has an Intel Foundation Ph.D. Fellow- ship and Yen a ...},
url = {http://portal.acm.org/citation.cfm?id=1168902},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Moravan/Supporting_nested_transactional_memory_in_LogTM_2006_Moravan.pdf},
file = {{Supporting_nested_transactional_memory_in_LogTM_2006_Moravan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Moravan/Supporting_nested_transactional_memory_in_LogTM_2006_Moravan.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/90DB352A-00BC-48E5-B2A0-510BC95DE1F4}}
}

@inproceedings{Zhang:2007dx,
author = {Zhang, Zhe and Wang, Chao and Vazhkudai, Sudharshan S and Ma, Xiaosong and Pike, Gregory G and Cobb, John W and Mueller, Frank},
title = {{Optimizing center performance through coordinated data staging, scheduling and recovery}},
crossref = {supercomputing},
year = {2007},
pages = {1--11},
doi = {10.1145/1362622.1362696},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:04GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Procurement and the optimized utilization of Petascale supercomputers and centers is a renewed national priority. Sustained performance and availability of such large centers is a key technical challenge significantly impacting their usability. Storage systems are known to be the primary fault source leading to data unavailability and job resubmissions. This results in reduced center performance, partially due to the lack of coordination between I/O activities and job scheduling. In this work, we propose the coordination of job scheduling with data staging/offloading and on-demand staged data reconstruction to address the availability of job input data and to improve center-wide performance. Fundamental to both mechanisms is the efficient management of transient data: in the way it is scheduled and recovered. Collectively, from a center's standpoint, these techniques optimize resource usage and increase its data/service availability. From a user's standpoint, they reduce the job turnaround time and optimize the allocated time usage.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5348792&queryText%3D%28optimizing+center+performance+through+coordinated+data+staging+scheduling+and+recovery%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Zhang/Optimizing_center_performance_through_coordinated_data_staging_scheduling_and_recovery_2007_Zhang.pdf},
file = {{Optimizing_center_performance_through_coordinated_data_staging_scheduling_and_recovery_2007_Zhang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Zhang/Optimizing_center_performance_through_coordinated_data_staging_scheduling_and_recovery_2007_Zhang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1362622.1362696}}
}

@inproceedings{Hengartner:2000bj,
author = {Hengartner, U and Bolliger, J and Gross, T},
title = {{TCP Vegas revisited}},
booktitle = {INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE},
year = {2000},
pages = {1546--1555},
doi = {10.1109/INFCOM.2000.832553},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {The innovative techniques of TCP Vegas have been the subject of much debate in recent years. Several studies have reported that TCP Vegas provides better performance than TCP Reno. However, the question of which of the new techniques are responsible for the impressive performance gains remains unanswered so far. This paper presents a detailed performance evaluation of TCP Vegas. By decomposing TCP Vegas into the various novel mechanisms proposed and assessing the effect of each of these mechanisms on performance, we show that the reported performance gains are achieved primarily by TCP Vegas's new techniques for slow start and congestion recovery. TCP Vegas's innovative congestion avoidance mechanism is shown to have only a minor influence on throughput. Furthermore, we find that the congestion avoidance mechanism exhibits fairness problems even if all competing connections operate with the same round trip time},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=832553&queryText%3D%28tcp+vegas+revisited%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Hengartner/TCP_Vegas_revisited_2000_Hengartner.pdf},
file = {{TCP_Vegas_revisited_2000_Hengartner.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Hengartner/TCP_Vegas_revisited_2000_Hengartner.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/INFCOM.2000.832553}}
}

@article{Regnier:2004en,
author = {Regnier, G and Makineni, S and Illikkal, I and Iyer, R},
title = {{TCP onloading for data center servers}},
journal = {IEEE Computer},
year = {2004},
volume = {37},
number = {11},
pages = {48--58},
doi = {10.1109/MC.2004.223},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-07-05T20:47:53GMT},
abstract = {The Internet and the applications it enables have transformed data center architectures from a simple single-server model to a multitier model in which Web servers , application servers , databases, and stor- age servers work together to respond to each client's request. As a ...},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1362588},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2004/Regnier/TCP_onloading_for_data_center_servers_2004_Regnier.pdf},
file = {{TCP_onloading_for_data_center_servers_2004_Regnier.pdf:/Users/njustn/Dropbox/Papers2/Articles/2004/Regnier/TCP_onloading_for_data_center_servers_2004_Regnier.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/MC.2004.223}}
}

@article{Ha:2008ui,
author = {Ha, S and Rhee, I},
title = {{CUBIC: a new TCP-friendly high-speed TCP variant}},
journal = {ACM SIGOPS Operating Systems Review},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {...  HighSpeed  TCP (HSTCP) [15] uses a generalized AIMD where the linear increase factor and multiplicative ... of BIC- TCP (especially, its stability and scalability), simplifies the window control and enhances its TCP  friendliness . We introduce a new  high - speed  TCP  variant : CUBIC . ...},
url = {http://portal.acm.org/citation.cfm?id=1400105},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Ha/CUBIC_a_new_TCP-friendly_high-speed_TCP_variant_2008_Ha.pdf},
file = {{CUBIC_a_new_TCP-friendly_high-speed_TCP_variant_2008_Ha.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Ha/CUBIC_a_new_TCP-friendly_high-speed_TCP_variant_2008_Ha.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/28998B3F-4F60-467C-94E0-DE64DF369094}}
}

@article{Shpeisman:2007tt,
author = {Shpeisman, T and Menon, V and Adl-Tabatabai, AR},
title = {{Enforcing isolation and ordering in STM}},
journal = {ACM SIGPLAN {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {{tatiana.shpeisman,vijay.s.menon,ali-reza.adl-tabatabai,rick.hudson,bratin.saha}@intel.com {alaska,djg,kfm}@cs.washington.edu ... Abstract Transactional memory provides a new concurrency control mech- anism that avoids many of the pitfalls of lock-based synchroniza- tion. High- ...},
url = {http://portal.acm.org/citation.cfm?id=1250744},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Shpeisman/Enforcing_isolation_and_ordering_in_STM_2007_Shpeisman.pdf},
file = {{Enforcing_isolation_and_ordering_in_STM_2007_Shpeisman.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Shpeisman/Enforcing_isolation_and_ordering_in_STM_2007_Shpeisman.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/7CA59643-2E95-45FC-95BA-957CEAB03EFD}}
}

@article{Pike:1995ts,
author = {Pike, R},
title = {{Plumbing and other utilities}},
journal = {Plan 9 User's manual},
year = {1995},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {The core of the plumbing system is a program called the plumber, which handles all messages and dispatches and reformats them according to configuration rules written in a special-purpose language. This approach allows the contents and context of a piece of data to define how ...},
url = {http://www.usenix.org/event/usenix2000/general/full_papers/pikeplumb/pikeplumb_html/},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1995/Pike/Plumbing_and_other_utilities_1995_Pike.pdf},
file = {{Plumbing_and_other_utilities_1995_Pike.pdf:/Users/njustn/Dropbox/Papers2/Articles/1995/Pike/Plumbing_and_other_utilities_1995_Pike.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CC49504F-AFEE-4DA9-830A-2D90B4E36385}}
}

@article{Mo:1999kt,
author = {Mo, J and La, RJ and Anantharam, V},
title = {{Analysis and comparison of TCP Reno and Vegas}},
journal = {INFOCOM'99 Eighteenth {\ldots}},
year = {1999},
volume = {3},
pages = {1556--1563},
doi = {10.1109/INFCOM.1999.752178},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-07-03T15:22:44GMT},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=752178},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1999/Mo/Analysis_and_comparison_of_TCP_Reno_and_Vegas_1999_Mo.pdf},
file = {{Analysis_and_comparison_of_TCP_Reno_and_Vegas_1999_Mo.pdf:/Users/njustn/Dropbox/Papers2/Articles/1999/Mo/Analysis_and_comparison_of_TCP_Reno_and_Vegas_1999_Mo.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/INFCOM.1999.752178}}
}

@article{Chuang:2006we,
author = {Chuang, W and Narayanasamy, S and Venkatesh, G},
title = {{Unbounded page-based transactional memory}},
journal = {ACM SIGPLAN {\ldots}},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Weihaw Chuang  , Satish Narayanasamy  , Ganesh Venkatesh  , Jack Sampson  , ... Michael Van Biesbrouck  , Gilles Pokam  , Osvaldo Colavin  , and Brad Calder  ...  University of California - San Diego,  ST Microelectronics,  Microsoft ... Abstract Exploiting thread ...},
url = {http://portal.acm.org/citation.cfm?id=1168901},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Chuang/Unbounded_page-based_transactional_memory_2006_Chuang.pdf},
file = {{Unbounded_page-based_transactional_memory_2006_Chuang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Chuang/Unbounded_page-based_transactional_memory_2006_Chuang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/19E2596D-2E57-4611-A867-649EAEFC6FEC}}
}

@inproceedings{Banerjee:2006be,
author = {Banerjee, A and Feng, Wu{-chun} and Mukherjee, B and Ghosal, D},
title = {{RAPID: an end-system aware protocol for intelligent data transfer over lambda grids}},
crossref = {ipdps},
year = {2006},
doi = {10.1109/IPDPS.2006.1639329},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:08GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {Next-generation e-science applications will require the ability to transfer information at high data rates between distributed computing centers and data repositories. To support such applications, lambda grid networks have been built to provide large, on-demand bandwidth between end-points that are interconnected via optical circuit-switched lambdas. It is extremely important to develop an efficient transport protocol over such high-capacity, dedicated circuits. Because lambdas provide dedicated bandwidth between endpoints, they obviate the need for network congestion control. Consequently, past research has demonstrated that rate-based transport protocols, such as RBUDP, are more effective than TCP in transferring data over lambdas. However, while lambdas eliminate congestion in the network, they ultimately push the congestion to the endpoints - congestion that current rate-based transport protocols are ill-suited to handle. In this paper we introduce a "rate-adaptive protocol for intelligent delivery (RAPID)" of data that is lightweight and end-system performance-aware, so as to maximize end-to-end throughput while minimizing packet loss. Based on self monitoring of the dynamic task-priority at the receiving end-system, our protocol enables the receiver to proactively deliver feedback to the sender, so that the sender may adapt its sending rate to avoid congestion at the receiving end-system. This avoids large bursts of packet losses typically observed in current rate-based transport protocols. Over a 10-Gigabit link emulation of an optical circuit, RAPID reduces file-transfer time, and hence improves end-to-end throughput by as much as 25\%},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=1639329&queryText%3D%28rapid+an+end+system+aware+protocol%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Banerjee/RAPID_an_end-system_aware_protocol_for_intelligent_data_transfer_over_lambda_grids_2006_Banerjee.pdf},
file = {{RAPID_an_end-system_aware_protocol_for_intelligent_data_transfer_over_lambda_grids_2006_Banerjee.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Banerjee/RAPID_an_end-system_aware_protocol_for_intelligent_data_transfer_over_lambda_grids_2006_Banerjee.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2006.1639329}}
}

@inproceedings{Tan:2006jg,
author = {Tan, K and Song, J and Zhang, Q and Sridharan, M},
title = {{A Compound TCP Approach for High-Speed and Long Distance Networks}},
booktitle = {INFOCOM 2006. 25th IEEE International Conference on Computer Communications. Proceedings},
year = {2006},
pages = {1--12},
doi = {10.1109/INFOCOM.2006.188},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {First Page of the Article
},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=4146841&queryText%3D%28a+compound+tcp+approach+for+high+speed+and+long+distance+networks%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Tan/A_Compound_TCP_Approach_for_High-Speed_and_Long_Distance_Networks_2006_Tan.pdf},
file = {{A_Compound_TCP_Approach_for_High-Speed_and_Long_Distance_Networks_2006_Tan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Tan/A_Compound_TCP_Approach_for_High-Speed_and_Long_Distance_Networks_2006_Tan.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/INFOCOM.2006.188}}
}

@inproceedings{Ayguade:2003tw,
author = {Ayguad{\'e}, Eduard and Blainey, Bob and Duran, Alejandro and Labarta, Jes{\'u}s and Mart{\'\i}nez, Francisco and Martorell, Xavier and Silvera, Ra{\'u}l},
title = {{Is the Schedule Clause Really Necessary in OpenMP?}},
booktitle = {Workshop on OpenMP Applications and Tools},
year = {2003},
publisher = { Springer-Verlag},
month = jun,
doi = {10.1007/3-540-45009-2_12},
read = {Yes},
rating = {0},
date-added = {2012-01-23T04:48:22GMT},
date-modified = {2014-07-05T18:18:22GMT},
abstract = {Choosing the appropriate assignment of loop iterations to threads is one of the most important decisions that need to be taken when parallelizing Loops, the main source of parallelism in numerical applications. This is not an easy task, even for expert},
url = {http://portal.acm.org/citation.cfm?id=1761900.1761916&coll=DL&dl=GUIDE&CFID=63255266&CFTOKEN=12559758},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/Ayguad%C3%A9/Is_the_Schedule_Clause_Really_Necessary_in_OpenMP_2003_Ayguad%C3%A9-1.pdf},
file = {{Is_the_Schedule_Clause_Really_Necessary_in_OpenMP_2003_Ayguad-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/Ayguad/Is_the_Schedule_Clause_Really_Necessary_in_OpenMP_2003_Ayguad-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/3-540-45009-2_12}}
}

@article{Kurata:2000vx,
author = {Kurata, K and Hasegawa, G},
title = {{Fairness comparisons between TCP Reno and TCP Vegas for future deployment of TCP Vegas}},
journal = {at INET},
year = {2000},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Page 1. Fairness  Comparisons  between  TCP  Reno and TCP  Vegas for Future Deployment of TCP  Vegas Kenji Kurata Go Hasegawa Masayuki Murata Department of Informatics and Mathematical Science Graduate School ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.524&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Kurata/Fairness_comparisons_between_TCP_Reno_and_TCP_Vegas_for_future_deployment_of_TCP_Vegas_2000_Kurata.pdf},
file = {{Fairness_comparisons_between_TCP_Reno_and_TCP_Vegas_for_future_deployment_of_TCP_Vegas_2000_Kurata.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Kurata/Fairness_comparisons_between_TCP_Reno_and_TCP_Vegas_for_future_deployment_of_TCP_Vegas_2000_Kurata.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1281486B-149F-45F1-BF85-8246FCFE123A}}
}

@article{Bhamidipaty:1998vh,
author = {Bhamidipaty, A},
title = {{Very fast YACCcompatible parsers (for very little effort)}},
journal = {Software: Practice and {\ldots}},
year = {1998},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {We have developed a yacc - compatible parser generator that creates parsers that are 2.0 to 6.0 times faster than those generated by yacc or bison. Our tool, mule, creates directly-executable, hard-coded parsers in ANSI; yacc produces interpreted, table-driven ...},
url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-024X(199802)28:2%3C181::AID-SPE139%3E3.0.CO;2-4/abstract},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1998/Bhamidipaty/Very_fast_YACC%E2%80%90compatible_parsers_(for_very_little_effort)_1998_Bhamidipaty.pdf},
file = {{Very_fast_YACCcompatible_parsers_(for_very_little_effort)_1998_Bhamidipaty.pdf:/Users/njustn/Dropbox/Papers2/Articles/1998/Bhamidipaty/Very_fast_YACCcompatible_parsers_(for_very_little_effort)_1998_Bhamidipaty.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5D7CEEF9-5A8B-4242-90CA-A4A5F389EC09}}
}

@inproceedings{Song:2006wk,
author = {Song, KTJ and Zhang, Q},
title = {{Compound TCP: A scalable and TCP-friendly congestion control for high-speed networks}},
booktitle = {Proceedings of PFLDnet 2006},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Page 1. Compound  TCP : A Scalable and TCP -Friendly Congestion Control for High-speed Networks ... In this paper, we propose a novel Compound  TCP (CTCP) approach, which is a synergy of delay-based and loss-based ap- proach. ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.1595&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Song/Compound_TCP_A_scalable_and_TCP-friendly_congestion_control_for_high-speed_networks_2006_Song.pdf},
file = {{Compound_TCP_A_scalable_and_TCP-friendly_congestion_control_for_high-speed_networks_2006_Song.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Song/Compound_TCP_A_scalable_and_TCP-friendly_congestion_control_for_high-speed_networks_2006_Song.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CF51ABBC-E72B-42D6-9B0E-547F25C25DB6}}
}

@book{Dijsktra:1968wf,
author = {Dijsktra, EW},
title = {{GO TO Statement considered harmful}},
publisher = {Communications of the ACM},
year = {1968},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://scholar.google.com/scholar?q=related:8TLFG5EeAOMJ:scholar.google.com/&hl=en&num=30&as_sdt=0,5},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/1968/Dijsktra/GO_TO_Statement_considered_harmful_1968_Dijsktra.pdf},
file = {{GO_TO_Statement_considered_harmful_1968_Dijsktra.pdf:/Users/njustn/Dropbox/Papers2/Books/1968/Dijsktra/GO_TO_Statement_considered_harmful_1968_Dijsktra.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5F76211E-4BCB-48CE-9048-8DAEDD34C059}}
}

@article{SMITH:1981up,
author = {SMITH, TF and WATERMAN, MS},
title = {{Identification of Common Molecular Subsequences}},
journal = {Journal of Molecular Biology},
year = {1981},
volume = {147},
number = {1},
pages = {195--197},
affiliation = {Univ Calif Los Alamos Sci Lab,Los Alamos,Nm 87545},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.2897&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1981/SMITH/Identification_of_Common_Molecular_Subsequences_1981_SMITH.pdf},
file = {{Identification_of_Common_Molecular_Subsequences_1981_SMITH.pdf:/Users/njustn/Dropbox/Papers2/Articles/1981/SMITH/Identification_of_Common_Molecular_Subsequences_1981_SMITH.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/89F37E4C-AD19-4F8E-9527-E4F4E12644AD}}
}

@article{Fisk:0vu,
author = {Fisk, M and Feng, Wu{-chun}},
title = {{Dynamic adjustment of TCP window sizes}},
year = {0},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:11GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {The original design of TCP failed to support reason- able performance over networks with large bandwidths and high round-trip times. Subsequent work on TCP has enabled the use of larger flow-control windows, yet the use of these options is still relatively rare, because manual ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.9613&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/0/Fisk/Dynamic_adjustment_of_TCP_window_sizes_0_Fisk.pdf},
file = {{Dynamic_adjustment_of_TCP_window_sizes_0_Fisk.pdf:/Users/njustn/Dropbox/Papers2/Articles/0/Fisk/Dynamic_adjustment_of_TCP_window_sizes_0_Fisk.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2871DF11-ABB1-4C89-82D3-9E02F4CD7987}}
}

@article{Michael:2004to,
author = {Michael, MM},
title = {{Practical lock-free and wait-free LL/SC/VL implementations using 64-bit CAS}},
journal = {Distributed Computing},
year = {2004},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:14GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {... This paper presents practical  lock - free and wait - free implementa- tions of arbitrary-sized LL / SC / VL variables using  64 - bit  CAS (Compare- and-Swap). The implementations improve on Jayanti and Petrovic's 64 - bit  wait - free  implementations by reducing the space overhead per ...},
url = {http://www.springerlink.com/index/lqmmyal418kpt9d2.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2004/Michael/Practical_lock-free_and_wait-free_LLSCVL_implementations_using_64-bit_CAS_2004_Michael.pdf},
file = {{Practical_lock-free_and_wait-free_LLSCVL_implementations_using_64-bit_CAS_2004_Michael.pdf:/Users/njustn/Dropbox/Papers2/Articles/2004/Michael/Practical_lock-free_and_wait-free_LLSCVL_implementations_using_64-bit_CAS_2004_Michael.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F4D63989-FE7A-46FC-B267-495C2E850330}}
}

@article{He:2002tx,
author = {He, E and Leigh, J and Yu, O},
title = {{Reliable blast UDP: Predictable high performance bulk data transfer}},
journal = {Cluster Computing},
year = {2002},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:14GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {High speed bulk data transfer is an important part of many data -intensive scientific applications. This paper describes an aggressive bulk data transfer scheme, called Reliable Blast UDP (RBUDP), intended for extremely high bandwidth, dedicated- or Quality-of- ...},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1137760},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2002/He/Reliable_blast_UDP_Predictable_high_performance_bulk_data_transfer_2002_He.pdf},
file = {{Reliable_blast_UDP_Predictable_high_performance_bulk_data_transfer_2002_He.pdf:/Users/njustn/Dropbox/Papers2/Articles/2002/He/Reliable_blast_UDP_Predictable_high_performance_bulk_data_transfer_2002_He.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/AA5B4769-C64A-4921-8463-7E1A0BD660F8}}
}

@booklet{Lisong:te,
title = {{Binary increase congestion control (BIC) for fast long-distance networks}},
author = {Lisong, X and Harfoush, K},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:15GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://scholar.google.com/scholar?q=related:521E6ru5tjcJ:scholar.google.com/&hl=en&num=30&as_sdt=0,5},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/Unknown/Lisong/Binary_increase_congestion_control_(BIC)_for_fast_long-distance_networks__Lisong.pdf},
file = {{Binary_increase_congestion_control_(BIC)_for_fast_long-distance_networks__Lisong.pdf:/Users/njustn/Dropbox/Papers2/Books/Unknown/Lisong/Binary_increase_congestion_control_(BIC)_for_fast_long-distance_networks__Lisong.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/0A84EEB1-35C2-4EA7-BDEF-AE20FFF03ED3}}
}

@book{Semke:1998im,
author = {Semke, Jeffrey and Mahdavi, Jamshid and Mathis, Matthew and Semke, Jeffrey and Mahdavi, Jamshid and Mathis, Matthew},
title = {{Automatic TCP buffer tuning}},
publisher = {SIGCOMM '98 Proceedings of the ACM SIGCOMM '98 conference on Applications, technologies, architectures, and protocols for computer communication},
year = {1998},
volume = {28},
address = {New York, New York, USA},
month = oct,
doi = {10.1145/285243.285292},
isbn = {1-58113-003-1},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:15GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {With the growth of high performance networking, a single host may have simultaneous connections that vary in band- width by as many as six orders of magnitude. We identify requirements for an automatically- tuning TCP to achieve maximum throughput across all connections ...},
url = {http://portal.acm.org/citation.cfm?doid=285237.285292},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/1998/Semke/Automatic_TCP_buffer_tuning_1998_Semke.pdf},
file = {{Automatic_TCP_buffer_tuning_1998_Semke.pdf:/Users/njustn/Dropbox/Papers2/Books/1998/Semke/Automatic_TCP_buffer_tuning_1998_Semke.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/285243.285292}}
}

@inproceedings{Michael:2004uw,
author = {Michael, Maged M},
title = {{Scalable lock-free dynamic memory allocation}},
booktitle = {Conference on Programming Language Design and Implementation},
year = {2004},
publisher = {ACM},
month = jun,
doi = {10.1145/996841.996848},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:15GMT},
date-modified = {2014-07-05T17:37:49GMT},
abstract = {Dynamic memory allocators (malloc/free) rely on mutual exclusion locks for protecting the consistency of their shared data structures under multithreading. The use of locking has many disadvantages with respect to performance, availability, robustness},
url = {http://portal.acm.org/citation.cfm?id=996841.996848&coll=DL&dl=ACM&CFID=235641177&CFTOKEN=70799411},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2004/Michael/Scalable_lock-free_dynamic_memory_allocation_2004_Michael.pdf},
file = {{Scalable_lock-free_dynamic_memory_allocation_2004_Michael.pdf:/Users/njustn/Dropbox/Papers2/Articles/2004/Michael/Scalable_lock-free_dynamic_memory_allocation_2004_Michael.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/996841.996848}}
}

@inproceedings{Aila:2009ji,
author = {Aila, Timo and Laine, Samuli},
title = {{Understanding the efficiency of ray traversal on GPUs}},
booktitle = {HPG '09: Proceedings of the Conference on High Performance Graphics 2009},
year = {2009},
publisher = {ACM},
month = aug,
doi = {10.1145/1572769.1572792},
rating = {0},
date-added = {2012-03-30T03:32:30GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {We discuss the mapping of elementary ray tracing operations---acceleration structure traversal and primitive intersection---onto wide SIMD/SIMT machines. Our focus is on NVIDIA GPUs, but some of the observations should be valid for other wide machines},
url = {http://portal.acm.org/citation.cfm?id=1572769.1572792&coll=DL&dl=GUIDE&CFID=94423863&CFTOKEN=41081255},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Aila/Understanding_the_efficiency_of_ray_traversal_on_GPUs_2009_Aila.pdf},
file = {{Understanding_the_efficiency_of_ray_traversal_on_GPUs_2009_Aila.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Aila/Understanding_the_efficiency_of_ray_traversal_on_GPUs_2009_Aila.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1572769.1572792}}
}

@inproceedings{Bosilca:2011kw,
author = {Bosilca, George and Bouteiller, Aurelien and Danalis, Anthony and Faverge, Mathieu and Haidar, Azzam and Herault, Thomas and Kurzak, Jakub and Langou, Julien and Lemarinier, Pierre and Ltaief, Hatem and Luszczek, Piotr and YarKhan, Asim and Dongarra, Jack},
title = {{Flexible Development of Dense Linear Algebra Algorithms on Massively Parallel Architectures with DPLASMA}},
booktitle = {International Parallel and Distributed Processing Symposium, Workshops and Phd Forum},
year = {2011},
pages = {1432--1441},
publisher = {IEEE},
doi = {10.1109/IPDPS.2011.299},
isbn = {978-1-61284-425-1},
issn = {1530-2075},
language = {English},
read = {Yes},
rating = {0},
date-added = {2012-11-08T20:57:45GMT},
date-modified = {2014-07-05T17:41:29GMT},
abstract = {We present a method for developing dense linear algebra algorithms that seamlessly scales to thousands of cores. It can be done with our project called DPLASMA (Distributed PLASMA) that uses a novel generic distributed Direct Acyclic Graph Engine (DAGuE). The engine has been designed for high performance computing and thus it enables scaling of tile algorithms, originating in PLASMA, on large distributed memory systems. The underlying DAGuE framework has many appealing features when considering distributed-memory plat- forms with heterogeneous multicore nodes: DAG representation that is independent of the problem-size, automatic extraction of the communication from the dependencies, overlapping of communication and computation, task prioritization, and architecture-aware scheduling and management of tasks. The originality of this engine lies in its capacity to translate a sequential code with nested-loops into a concise and synthetic format which can then be interpreted and executed in a dis- tributed environment. We present three common dense linear algebra algorithms from PLASMA (Parallel Linear Algebra for Scalable Multi-core Architectures), namely: Cholesky, LU, and QR factorizations, to investigate their data driven expression and execution in a distributed system. We demonstrate through experimental results on the Cray XT5 Kraken system that our DAG-based approach has the potential to achieve sizable fraction of peak performance which is characteristic of the state-of-the-art distributed numerical software on current and emerging architectures.},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6008998},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Bosilca/Flexible_Development_of_Dense_Linear_Algebra_Algorithms_on_Massively_Parallel_Architectures_with_DPLASMA_2011_Bosilca.pdf},
file = {{Flexible_Development_of_Dense_Linear_Algebra_Algorithms_on_Massively_Parallel_Architectures_with_DPLASMA_2011_Bosilca.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Bosilca/Flexible_Development_of_Dense_Linear_Algebra_Algorithms_on_Massively_Parallel_Architectures_with_DPLASMA_2011_Bosilca.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2011.299}}
}

@inproceedings{Weigle:2002hm,
author = {Weigle, E and Feng, Wu{-chun}},
title = {{A comparison of TCP automatic tuning techniques for distributed computing}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2002},
pages = {265--272},
doi = {10.1109/HPDC.2002.1029926},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:15GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {Rather than painful, manual, static, per-connection optimization of TCP buffer sizes simply to achieve acceptable performance for distributed applications, many researchers have proposed techniques to perform this tuning automatically. This paper first discusses the relative merits of the various approaches in theory, and then provides substantial experimental data concerning two competing implementations-the buffer autotuning already present in Linux 2.4.x and "dynamic right-sizing." The paper reveals heretofore unknown aspects of the problem and current solutions, provides insight into the proper approach for different circumstances, and points toward ways to further improve performance.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=1029926&queryText%3D%28a+comparison+of+tcp+automatic+tuning+techniques+for+distributed+computing%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2002/Weigle/A_comparison_of_TCP_automatic_tuning_techniques_for_distributed_computing_2002_Weigle.pdf},
file = {{A_comparison_of_TCP_automatic_tuning_techniques_for_distributed_computing_2002_Weigle.pdf:/Users/njustn/Dropbox/Papers2/Articles/2002/Weigle/A_comparison_of_TCP_automatic_tuning_techniques_for_distributed_computing_2002_Weigle.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/HPDC.2002.1029926}}
}

@article{Michael:2004ia,
author = {Michael, M.M},
title = {{Hazard pointers: safe memory reclamation for lock-free objects}},
journal = {Parallel and Distributed Systems, IEEE Transactions on},
year = {2004},
volume = {15},
number = {6},
pages = {491--504},
doi = {10.1109/TPDS.2004.8},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:15GMT},
date-modified = {2014-04-01T13:52:35GMT},
abstract = {Lock-free objects offer significant performance and reliability advantages over conventional lock-based objects. However, the lack of an efficient portable lock-free method for the reclamation of the memory occupied by dynamic nodes removed from such objects is a major obstacle to their wide use in practice. We present hazard pointers, a memory management methodology that allows memory reclamation for arbitrary reuse. It is very efficient, as demonstrated by our experimental results. It is suitable for user-level applications - as well as system programs - without dependence on special kernel or scheduler support. It is wait-free. It requires only single-word reads and writes for memory access in its core operations. It allows reclaimed memory to be returned to the operating system. In addition, it offers a lock-free solution for the ABA problem using only practical single-word instructions. Our experimental results on a multiprocessor system show that the new methodology offers equal and, more often, significantly better performance than other memory management methods, in addition to its qualitative advantages regarding memory reclamation and independence of special hardware support. We also show that lock-free implementations of important object types, using hazard pointers, offer comparable performance to that of efficient lock-based implementations under no contention and no multiprogramming, and outperform them by significant margins under moderate multiprogramming and/or contention, in addition to guaranteeing continuous progress and availability, even in the presence of thread failures and arbitrary delays.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=1291819&queryText%3D%28hazard+pointers+safe+memory+reclamation+for+lock+free+objects%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2004/Michael/Hazard_pointers_safe_memory_reclamation_for_lock-free_objects_2004_Michael.pdf},
file = {{Hazard_pointers_safe_memory_reclamation_for_lock-free_objects_2004_Michael.pdf:/Users/njustn/Dropbox/Papers2/Articles/2004/Michael/Hazard_pointers_safe_memory_reclamation_for_lock-free_objects_2004_Michael.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/TPDS.2004.8}}
}

@inproceedings{Gibbons:1989wo,
author = {Gibbons, PB},
title = {{A more practical PRAM model}},
booktitle = {ACM Symposium on Parallelism in Algorithms and Architectures},
year = {1989},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:16GMT},
date-modified = {2014-07-05T17:45:25GMT},
abstract = {The PRAM model of computation consists of a collec- tion ofp sequential processors, each with its own private local memory, communicating with one another through a shared global memory. The processors execute in lock- step, although each processor does have its ...},
url = {http://doi.ieeecomputersociety.org/10.1145/72935.72953},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1989/Gibbons/A_more_practical_PRAM_model_1989_Gibbons.pdf},
file = {{A_more_practical_PRAM_model_1989_Gibbons.pdf:/Users/njustn/Dropbox/Papers2/Articles/1989/Gibbons/A_more_practical_PRAM_model_1989_Gibbons.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F4953980-EC65-4A62-AF06-101652B4DC04}}
}

@article{Blumrich:1995hl,
author = {Blumrich, MA and Dubnicki, C and Felten, EW and Li, K},
title = {{Virtual-memory-mapped network interfaces}},
journal = {Micro},
year = {1995},
volume = {15},
number = {1},
pages = {21--28},
doi = {10.1109/40.342014},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:16GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {Node A _ - ..._ _ _ _ _ _ _ ._ ,' Virtual - : memory : spaces Physical- \ ... Node 6 - . . . . . . . . - - - Virtual - 'I memory I :Physical- spaces jmemory I I j ... Virtual - memory - mapped communication Figure 1 illustrates the basic idea of virtual - memory - mapped communication: ...},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=342014},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1995/Blumrich/Virtual-memory-mapped_network_interfaces_1995_Blumrich.pdf},
file = {{Virtual-memory-mapped_network_interfaces_1995_Blumrich.pdf:/Users/njustn/Dropbox/Papers2/Articles/1995/Blumrich/Virtual-memory-mapped_network_interfaces_1995_Blumrich.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/40.342014}}
}

@booklet{Culler:1993tm,
title = {{LogP: Towards a realistic model of parallel computation}},
author = {Culler, D and Karp, R and Patterson, D and Sahay, A},
year = {1993},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:16GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Page 1. LogP : Towards aRealistic Model of Parallel  Computation  ... requires few machine parameters as long as a certain programming methodology is followed. We used the BSP as a starting point in our search for a parallel  model that would be realistic , yet ...},
url = {http://portal.acm.org/citation.cfm?id=155333},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/1993/Culler/LogP_Towards_a_realistic_model_of_parallel_computation_1993_Culler.pdf},
file = {{LogP_Towards_a_realistic_model_of_parallel_computation_1993_Culler.pdf:/Users/njustn/Dropbox/Papers2/Books/1993/Culler/LogP_Towards_a_realistic_model_of_parallel_computation_1993_Culler.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DC967CEA-C1F7-4018-9DA5-AB82D8CBE400}}
}

@book{Vetter:2006td,
author = {Vetter, JS},
title = {{Early Evaluation of the Cray XD1}},
publisher = {Proceedings of 20th International Parallel and {\ldots}},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:16GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://scholar.google.com/scholar?q=related:D_xWorUAHF0J:scholar.google.com/&hl=en&num=30&as_sdt=0,5},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2006/Vetter/Early_Evaluation_of_the_Cray_XD1_2006_Vetter.pdf},
file = {{Early_Evaluation_of_the_Cray_XD1_2006_Vetter.pdf:/Users/njustn/Dropbox/Papers2/Books/2006/Vetter/Early_Evaluation_of_the_Cray_XD1_2006_Vetter.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A18B1189-679E-4A3E-92A8-7369D5AD6B81}}
}

@article{Adiga:2002vu,
author = {Adiga, NR and Almasi, G and Almasi, GS and Aridor, Y and Barik, R and Beece, D and Bellofatto, R and Bhanot, G and Bickford, R and Blumrich, M and Bright, AA and Brunheroto, J and Cascaval, C and Castanos, J and Chan, W and Ceze, L and Coteus, P and Chatterjee, S and Chen, D and Chiu, G and Cipolla, TM and Crumley, P and Desai, KM and Deutsch, A and Domany, T and Dombrowa, MB and Donath, W and Eleftheriou, M and Erway, C and Esch, J and Fitch, B and Gagliano, J and Gara, A and Garg, R and Germain, R and Giampapa, ME and Gopalsamy, B and Gunnels, J and Gupta, M and Gustavson, F and Hall, S and Haring, RA and Heidel, D and Heidelberger, P and Herger, LM and Hoenicke, D and Jackson, RD and Jamal-Eddine, T and Kopcsay, GV and Krevat, E and Kurhekar, MP and Lanzetta, AP and Lieber, D and Liu, LK and Lu, M and Mendell, M and Misra, A and Moatti, Y and Mok, L and Moreira, JE and Nathanson, BJ and Newton, M and Ohmacht, M and Oliner, A and Pandit, V and Pudota, RB and Rand, R and Regan, R and Rubin, B and Ruehli, A and Rus, S and Sahoo, RK and Sanomiya, A and Schenfeld, E and Sharma, M and Shmueli, E and Singh, S and Song, P and Srinivasan, V and Steinmacher-Burow, BD and Strauss, K and Surovic, C and Swetz, R and Takken, T and Tremaine, RB and Tsao, M and Umamaheshwaran, AR and Verma, P and Vranas, P and Ward, TJC and Wazlowski, M},
title = {{An Overview of the BlueGene/L Supercomputer}},
year = {2002},
pages = {1--22},
month = jul,
affiliation = {IBM and Lawrence Livermore National Laboratory},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:16GMT},
date-modified = {2014-03-21T11:56:18GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2002/Adiga/An_Overview_of_the_BlueGeneL_Supercomputer_2002_Adiga.pdf},
file = {{An_Overview_of_the_BlueGeneL_Supercomputer_2002_Adiga.pdf:/Users/njustn/Dropbox/Papers2/Articles/2002/Adiga/An_Overview_of_the_BlueGeneL_Supercomputer_2002_Adiga.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/EC7449F1-82E2-43A0-947B-15DB7E20D7DA}}
}

@article{Habata:2003wf,
author = {Habata, S and Yokokawa, M},
title = {{The earth simulator system}},
journal = {NEC Research and {\ldots}},
year = {2003},
read = {Yes},
rating = {0},
date-added = {2011-04-10T15:17:16GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {The Earth Simulator , developed by the Japanese government's initiative `` Earth Simulator Project,'' is a highly parallel vector supercomputer system that consists of 640 processor nodes and interconnection network. The processor node is a shared memory parallel vector ...},
url = {http://www.clear.rice.edu/elec526/handouts/papers/earth-sim-nec.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/Habata/The_earth_simulator_system_2003_Habata.pdf},
file = {{The_earth_simulator_system_2003_Habata.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/Habata/The_earth_simulator_system_2003_Habata.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/27BC78F5-8434-4455-A8E9-D987128AAD85}}
}

@inproceedings{Wolfe:2010bk,
author = {Wolfe, Michael},
title = {{Implementing the PGI Accelerator Model}},
booktitle = {Annual Workshop on General Purpose Processing with Graphics Processing Units},
year = {2010},
publisher = {ACM},
month = mar,
keywords = {ipdps11-omp-co},
doi = {10.1145/1735688.1735697},
read = {Yes},
rating = {0},
date-added = {2011-11-13T00:58:08GMT},
date-modified = {2014-07-05T17:33:36GMT},
abstract = {The PGI Accelerator model is a high-level programming model for accelerators, such as GPUs, similar in design and scope to the widely-used OpenMP directives. This paper presents some details of the design of the compiler that implements the model, focusing},
url = {http://portal.acm.org/citation.cfm?id=1735688.1735697&coll=DL&dl=GUIDE&CFID=53317199&CFTOKEN=95945713},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Wolfe/Implementing_the_PGI_Accelerator_Model_2010_Wolfe.pdf},
file = {{Implementing_the_PGI_Accelerator_Model_2010_Wolfe.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Wolfe/Implementing_the_PGI_Accelerator_Model_2010_Wolfe.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1735688.1735697}}
}

@article{McCurdy:ur,
author = {McCurdy, C and Vetter, J and Worley, PH},
title = {{Memphis on an XT5: Pinpointing Memory Performance Problems on Cray Platforms}},
journal = {cug.org
},
rating = {0},
date-added = {2012-04-10T01:54:32GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {ABSTRACT: Memphis is a tool that makes use of Instruction Based Sampling (IBS) hardware counters, available in recent AMD processors, to help pinpoint the sources of memory system performance problems. This paper describes our experiences porting Memphis to ... 
},
url = {https://cug.org/5-publications/proceedings_attendee_lists/CUG11CD/pages/1-program/final_program/Monday/04C-McCurdy-Paper.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/McCurdy/Memphis_on_an_XT5_Pinpointing_Memory_Performance_Problems_on_Cray_Platforms__McCurdy.pdf},
file = {{Memphis_on_an_XT5_Pinpointing_Memory_Performance_Problems_on_Cray_Platforms__McCurdy.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/McCurdy/Memphis_on_an_XT5_Pinpointing_Memory_Performance_Problems_on_Cray_Platforms__McCurdy.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/3DD0D1CD-C8E5-4FCA-9A41-F3E41C06090C}}
}

@article{Che:2008kg,
author = {Che, Shuai and Boyer, Michael and Meng, Jiayuan and Tarjan, David and Sheaffer, Jeremy W and Skadron, Kevin},
title = {{A performance study of general-purpose applications on graphics processors using CUDA}},
journal = {Journal of parallel and Distributed Computing},
year = {2008},
volume = {68},
number = {10},
pages = {1370--1380},
month = oct,
doi = {10.1016/j.jpdc.2008.05.014},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-03-08T18:47:41GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Graphics processors (GPUs) provide a vast number of simple, data-parallel, deeply multithreaded cores and high memory bandwidths. GPU architectures are becoming increasingly programmable, offering the potential for dramatic speedups for a variety of ... 
},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0743731508000932},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Che/A_performance_study_of_general-purpose_applications_on_graphics_processors_using_CUDA_2008_Che.pdf},
file = {{A_performance_study_of_general-purpose_applications_on_graphics_processors_using_CUDA_2008_Che.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Che/A_performance_study_of_general-purpose_applications_on_graphics_processors_using_CUDA_2008_Che.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.jpdc.2008.05.014}}
}

@inproceedings{huang-hppac09-gpu,
author = {Huang, Song and Xiao, Shucai and Feng, Wu{-chun}},
title = {{On the Energy Efficiency of Graphics Processing Units for Scientific Computing}},
crossref = {ipdps},
year = {2009},
pages = {1--8},
address = {Rome, Italy},
doi = {10.1109/IPDPS.2009.5160980},
rating = {0},
date-added = {2013-03-16T15:46:24GMT},
date-modified = {2014-07-05T20:55:56GMT},
abstract = {The graphics processing unit (GPU) has emerged as a computational accelerator that dramatically reduces the time to discovery in high-end computing (HEC). However, while today's state-of-the-art GPU can easily reduce the execution time of a parallel code by many orders of magnitude, it arguably comes at the expense of significant power and energy consumption. For example, the NVIDIA GTX 280 video card is rated at 236 watts, which is as much as the rest of a compute node, thus requiring a 500-W power supply. As a consequence, the GPU has been viewed as a ldquonon-greenrdquo computing solution. This paper seeks to characterize, and perhaps debunk, the notion of a ldquopower-hungry GPUrdquo via an empirical study of the performance, power, and energy characteristics of GPUs for scientific computing. Specifically, we take an important biological code that runs in a traditional CPU environment and transform and map it to a hybrid CPU+GPU environment. The end result is that our hybrid CPU+GPU environment, hereafter referred to simply as GPU environment, delivers an energy-delay product that is multiple orders of magnitude better than a traditional CPU environment, whether unicore or multicore. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5160980&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22On+the+Energy+Efficiency+of+Graphics+Processing+Units+for+Scientific+Computing%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Huang/On_the_Energy_Efficiency_of_Graphics_Processing_Units_for_Scientific_Computing_2009_Huang.pdf},
file = {{On_the_Energy_Efficiency_of_Graphics_Processing_Units_for_Scientific_Computing_2009_Huang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Huang/On_the_Energy_Efficiency_of_Graphics_Processing_Units_for_Scientific_Computing_2009_Huang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5160980}}
}

@inproceedings{Luo:2010wc,
author = {Luo, L and Wong, M and Hwu, W},
title = {{An Effective GPU Implementation of Breadth-First Search}},
booktitle = {Proceedings of the 47th Design Automation {\ldots}},
year = {2010},
read = {Yes},
rating = {0},
date-added = {2013-07-31T17:41:12GMT},
date-modified = {2014-07-05T20:23:57GMT},
abstract = {Abstract Breadth - first search (BFS) has wide applications in electronic design automation (EDA) as well as in other fields. Researchers have tried to accelerate BFS on the GPU , but the two published works are both asymptotically slower than the fastest CPU ... 
},
url = {http://dl.acm.org/citation.cfm?id=1837289},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Luo/An_Effective_GPU_Implementation_of_Breadth-First_Search_2010_Luo.pdf},
file = {{An_Effective_GPU_Implementation_of_Breadth-First_Search_2010_Luo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Luo/An_Effective_GPU_Implementation_of_Breadth-First_Search_2010_Luo.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A77F653E-7569-4724-AD29-25B65182E949}}
}

@inproceedings{Hong:2011fa,
author = {Hong, Sungpack and Kim, Sang Kyun and Oguntebi, Tayo and Olukotun, Kunle},
title = {{Accelerating CUDA graph algorithms at maximum warp}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2011},
pages = {267--276},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/1941553.1941590},
isbn = {9781450301190},
rating = {0},
date-added = {2013-07-31T18:35:27GMT},
date-modified = {2014-07-05T18:32:04GMT},
url = {http://portal.acm.org/citation.cfm?doid=1941553.1941590},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Hong/Accelerating_CUDA_graph_algorithms_at_maximum_warp_2011_Hong.pdf},
file = {{Accelerating_CUDA_graph_algorithms_at_maximum_warp_2011_Hong.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Hong/Accelerating_CUDA_graph_algorithms_at_maximum_warp_2011_Hong.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1941553.1941590}}
}

@inproceedings{Giacomoni:2008hh,
author = {Giacomoni, John and Moseley, Tipp and Vachharajani, Manish},
title = {{FastForward for efficient pipeline parallelism: a cache-optimized concurrent lock-free queue}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2008},
publisher = {ACM},
month = feb,
doi = {10.1145/1345206.1345215},
read = {Yes},
rating = {0},
date-added = {2013-08-15T15:01:31GMT},
date-modified = {2014-07-05T17:36:15GMT},
abstract = {Low overhead core-to-core communication is critical for efficient pipeline-parallel software applications. This paper presents FastForward, a cache-optimized single-producer/single-consumer concurrent lock-free queue for pipeline parallelism on multicore},
url = {http://portal.acm.org/citation.cfm?id=1345206.1345215&coll=DL&dl=ACM&CFID=239412494&CFTOKEN=79786133},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Giacomoni/FastForward_for_efficient_pipeline_parallelism_a_cache-optimized_concurrent_lock-free_queue_2008_Giacomoni.pdf},
file = {{FastForward_for_efficient_pipeline_parallelism_a_cache-optimized_concurrent_lock-free_queue_2008_Giacomoni.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Giacomoni/FastForward_for_efficient_pipeline_parallelism_a_cache-optimized_concurrent_lock-free_queue_2008_Giacomoni.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1345206.1345215}}
}

@article{Bosilca:2011cv,
author = {Bosilca, George and Bouteiller, Aurelien and Danalis, A and Herault, T and Lemarinier, P and Dongarra, Jack},
title = {{DAGuE: A Generic Distributed DAG Engine for High Performance Computing}},
journal = {Parallel and Distributed Processing Workshops and Phd Forum (IPDPSW), 2011 IEEE International Symposium on},
year = {2011},
pages = {1151--1158},
publisher = { IEEE Computer Society},
doi = {10.1109/IPDPS.2011.281},
read = {Yes},
rating = {0},
date-added = {2012-11-08T22:44:02GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {The frenetic development of the current architectures places a strain on the current state-of-the-art programming environments. Harnessing the full potential of such architectures has been a tremendous task for the whole scientific computing community. We present DAGuE a generic framework for architecture aware scheduling and management of micro-tasks on distributed many-core heterogeneous architectures. Applications we consider can be represented as a Direct Acyclic Graph of tasks with labeled edges designating data dependencies. DAGs are represented in a compact, problem-size independent format that can be queried on-demand to discover data dependencies, in a totally distributed fashion. DAGuE assigns computation threads to the cores, overlaps communications and computations and uses a dynamic, fully-distributed scheduler based on cache awareness, data-locality and task priority. We demonstrate the efficiency of our approach, using several micro-benchmarks to analyze the performance of different components of the framework, and a Linear Algebra factorization as a use case. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6008964&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22DAGuE%3A+A+generic+distributed+DAG+engine+for+high+performance+computing.%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Bosilca/DAGuE_A_Generic_Distributed_DAG_Engine_for_High_Performance_Computing_2011_Bosilca.pdf},
file = {{DAGuE_A_Generic_Distributed_DAG_Engine_for_High_Performance_Computing_2011_Bosilca.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Bosilca/DAGuE_A_Generic_Distributed_DAG_Engine_for_High_Performance_Computing_2011_Bosilca.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2011.281}}
}

@inproceedings{lcrq,
author = {Morrison, Adam and Afek, Yehuda},
title = {{Fast concurrent queues for x86 processors}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2013},
publisher = {ACM},
month = feb,
doi = {10.1145/2442516.2442527},
read = {Yes},
rating = {0},
date-added = {2013-08-19T17:39:57GMT},
date-modified = {2014-07-05T17:36:15GMT},
abstract = {Conventional wisdom in designing concurrent data structures is to use the most powerful synchronization primitive, namely compare-and-swap (CAS), and to avoid contended hot spots. In building concurrent FIFO queues, this reasoning has led researchers},
url = {http://portal.acm.org/citation.cfm?id=2442516.2442527&coll=DL&dl=ACM&CFID=239412494&CFTOKEN=79786133},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Morrison/Fast_concurrent_queues_for_x86_processors_2013_Morrison.pdf},
file = {{Fast_concurrent_queues_for_x86_processors_2013_Morrison.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Morrison/Fast_concurrent_queues_for_x86_processors_2013_Morrison.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2442516.2442527}}
}

@article{room-sync,
author = {Blelloch, Guy E and Cheng, Perry and Gibbons, Phillip B},
title = {{Scalable Room Synchronizations}},
journal = {Theory of Computing Systems},
year = {2003},
volume = {36},
number = {5},
pages = {397--430},
month = aug,
doi = {10.1007/s00224-003-1081-y},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-08-28T16:08:50GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://link.springer.com/10.1007/s00224-003-1081-y},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/Blelloch/Scalable_Room_Synchronizations_2003_Blelloch-2.pdf},
file = {{Scalable_Room_Synchronizations_2003_Blelloch-2.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/Blelloch/Scalable_Room_Synchronizations_2003_Blelloch-2.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/s00224-003-1081-y}}
}

@article{gottlieb-1983,
author = {Gottlieb, Allan and Lubachevsky, Boris D and Rudolph, Larry},
title = {{Basic Techniques for the Efficient Coordination of Very Large Numbers of Cooperating Sequential Processors}},
journal = {Transactions on Programming Languages and Systems (TOPLAS},
year = {1983},
volume = {5},
number = {2},
month = apr,
publisher = {ACM},
doi = {10.1145/69624.357206},
read = {Yes},
rating = {0},
date-added = {2013-08-28T16:11:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://portal.acm.org/citation.cfm?id=69624.357206&coll=DL&dl=GUIDE&CFID=356544635&CFTOKEN=19534165},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1983/Gottlieb/Basic_Techniques_for_the_Efficient_Coordination_of_Very_Large_Numbers_of_Cooperating_Sequential_Processors_1983_Gottlieb-2.pdf},
file = {{Basic_Techniques_for_the_Efficient_Coordination_of_Very_Large_Numbers_of_Cooperating_Sequential_Processors_1983_Gottlieb-2.pdf:/Users/njustn/Dropbox/Papers2/Articles/1983/Gottlieb/Basic_Techniques_for_the_Efficient_Coordination_of_Very_Large_Numbers_of_Cooperating_Sequential_Processors_1983_Gottlieb-2.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/69624.357206}}
}

@article{Henry:2013uj,
author = {Henry, Sylvain and Barthou, Denis and Denis, Alexandre and Namyst, Raymond and Counilh, Marie-Christine},
title = {{SOCL: An OpenCL Implementation with Automatic Multi-Device Adaptation Support}},
journal = {hal.inria.fr},
year = {2013},
month = aug,
read = {Yes},
rating = {0},
date-added = {2013-08-28T19:00:05GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {To fully tap into the potential of today's heterogeneous machines, offloading parts of an application on accelerators is not sufficient. The real challenge is to build systems where the application would permanently spread across the entire machine, that is, where parallel tasks would be dynamically scheduled over the full set of available processing units. In this report we present SOCL, an OpenCL implementation that improves and simplifies the programming experience on heterogeneous architectures. SOCL enables applications to dynamically dispatch computation kernels over processing devices so as to maximize their utilization. OpenCL applications can incrementally make use of light extensions to automatically schedule kernels in a controlled manner on multi-device architectures. A preliminary automatic granularity adaptation extension is also provided. We demonstrate the relevance of our approach by experimenting with several OpenCL applications on a range of representative heterogeneous architectures. We show that performance portability is enhanced by using SOCL extensions.},
url = {http://hal.inria.fr/hal-00853423},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Henry/SOCL_An_OpenCL_Implementation_with_Automatic_Multi-Device_Adaptation_Support_2013_Henry.pdf},
file = {{SOCL_An_OpenCL_Implementation_with_Automatic_Multi-Device_Adaptation_Support_2013_Henry.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Henry/SOCL_An_OpenCL_Implementation_with_Automatic_Multi-Device_Adaptation_Support_2013_Henry.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/D04F278C-D5B5-424E-8A49-19DCDE4D7E1B}}
}

@article{Beckmann:2013vg,
author = {Beckmann, N and Sanchez, D},
title = {{Jigsaw: scalable software-defined caches}},
journal = {International Conference on Parallel Architectures and Compilation Techniques (PACT 13)},
year = {2013},
rating = {0},
date-added = {2013-09-16T23:30:43GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Abstract Shared last-level caches , widely used in chip-multiprocessors (CMPs), face two fundamental limitations. First, the latency and energy of shared caches degrade as the system scales up. Second, when multiple workloads share the CMP, they suffer from ... 
},
url = {http://dl.acm.org/citation.cfm?id=2523752},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Beckmann/Jigsaw_scalable_software-defined_caches_2013_Beckmann.pdf},
file = {{Jigsaw_scalable_software-defined_caches_2013_Beckmann.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Beckmann/Jigsaw_scalable_software-defined_caches_2013_Beckmann.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C90B704F-CD3A-4EB1-8BAC-1B7CAF1D5569}}
}

@article{Krotkiewski:2013jk,
author = {Krotkiewski, Marcin and Dabrowski, Marcin},
title = {{Efficient 3D stencil computations using CUDA}},
journal = {Parallel Computing},
year = {2013},
volume = {39},
number = {10},
pages = {533--548},
month = oct,
doi = {10.1016/j.parco.2013.08.002},
language = {English},
read = {Yes},
rating = {0},
date-added = {2014-07-07T18:42:17GMT},
date-modified = {2014-07-08T19:25:20GMT},
abstract = {Abstract We present an efficient implementation of 7-point and 27-point stencils on high-end Nvidia GPUs. A new method of reading the data from the global memory to the shared memory of thread blocks is developed. The method avoids conditional statements and},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016781911300094X},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Krotkiewski/Efficient_3D_stencil_computations_using_CUDA_2013_Krotkiewski.pdf},
file = {{Efficient_3D_stencil_computations_using_CUDA_2013_Krotkiewski.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Krotkiewski/Efficient_3D_stencil_computations_using_CUDA_2013_Krotkiewski.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.parco.2013.08.002}}
}

@misc{Anonymous:2013ut,
title = {{OpenMP 4.0 Specification}},
author = {{OpenMP ARB}},
howpublished = {\url{http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf}},
month = jun,
year = {2013},
publisher = {\url{http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf}},
rating = {0},
date-added = {2014-04-17T03:31:57GMT},
date-modified = {2014-07-05T21:22:12GMT},
url = {http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf},
uri = {\url{papers2://publication/uuid/1B47F998-E1C8-412C-AB8E-B20FE62C3C88}}
}

@misc{openacc,
title = {{OpenACC 2.0 Application Programming Interface Specification}},
howpublished = {\url{http://www.openacc.org/sites/default/files/OpenACC%202%200.pdf}},
month = jun,
year = {2013},
rating = {0},
date-added = {2014-04-17T03:34:54GMT},
date-modified = {2014-04-17T03:37:43GMT},
uri = {\url{papers2://publication/uuid/B38F207C-C941-4C98-954D-F41C295A9862}}
}

@inproceedings{Mariano:vs,
author = {Mariano, Artur and Alves, Ricardo and Barbosa, Joao and Santos, Luis Paulo and Proenca, Alberto},
title = {{A (Ir) regularity-Aware Task Scheduler for Heterogeneous Platforms}},
booktitle = {HPC-UA},
year = {2012},
read = {Yes},
rating = {0},
date-added = {2012-11-26T15:26:09GMT},
date-modified = {2014-07-05T21:01:43GMT},
url = {http://hpc-ua.org/hpc-ua-12/files/proceedings/8.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Mariano/A_(Ir)_regularity-Aware_Task_Scheduler_for_Heterogeneous_Platforms_2012_Mariano-1.pdf},
file = {{A_(Ir)_regularity-Aware_Task_Scheduler_for_Heterogeneous_Platforms_2012_Mariano-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Mariano/A_(Ir)_regularity-Aware_Task_Scheduler_for_Heterogeneous_Platforms_2012_Mariano-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/EBE04EE6-708A-4CEA-A8F1-85E772E446C1}}
}

@inproceedings{Elteir:2011ec,
author = {Elteir, Marwa and Lin, Heshan and Feng, Wu{-chun} and Scogland, Thomas R W},
title = {{StreamMR: An Optimized MapReduce Framework for AMD GPUs}},
booktitle = {International Conference on Parallel and Distributed Systems},
year = {2011},
pages = {364--371},
doi = {10.1109/ICPADS.2011.131},
read = {Yes},
rating = {0},
date-added = {2012-05-03T22:29:18GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {MapReduce is a programming model from Google that facilitates parallel processing on a cluster of thousands of commodity computers. The success of MapReduce in cluster environments has motivated several studies of implementing MapReduce on a graphics processing unit (GPU), but generally focusing on the NVIDIA GPU. Our investigation reveals that the design and mapping of the MapReduce framework needs to be revisited for AMD GPUs due to their notable architectural differences from NVIDIA GPUs. For instance, current state-of-the-art MapReduce implementations employ atomic operations to coordinate the execution of different threads. However, atomic operations can implicitly cause inefficient memory access, and in turn, severely impact performance. In this paper, we propose Streamer, an OpenCL MapReduce framework optimized for AMD GPUs. With efficient atomic-free algorithms for output handling and intermediate result shuffling, Stream MR is superior to atomic-based MapReduce designs and can outperform existing atomic-free MapReduce implementations by nearly five-fold on an AMD Radeon HD 5870. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6121299&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%282011.131+AND+p_Title%3A%22StreamMR%3A+An+Optimized+MapReduce+Framework+for+AMD+GPUs%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Elteir/StreamMR_An_Optimized_MapReduce_Framework_for_AMD_GPUs_2011_Elteir.pdf},
file = {{StreamMR_An_Optimized_MapReduce_Framework_for_AMD_GPUs_2011_Elteir.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Elteir/StreamMR_An_Optimized_MapReduce_Framework_for_AMD_GPUs_2011_Elteir.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPADS.2011.131}}
}

@article{Lauer:1979wr,
author = {Lauer, HC},
title = {{On the duality of operating system structures}},
journal = {ACM SIGOPS Operating Systems Review},
year = {1979},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:51:49GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {Because the original of the following paper by Lauer and Needham is not widely available, we are reprinting it here. If the paper is referenced in published work, the citation should read: "Lauer, HC, Needham, RM, " On the Duality of Operating Systems Structures ," in Proc. ...},
url = {http://portal.acm.org/citation.cfm?id=850658},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1979/Lauer/On_the_duality_of_operating_system_structures_1979_Lauer.pdf},
file = {{On_the_duality_of_operating_system_structures_1979_Lauer.pdf:/Users/njustn/Dropbox/Papers2/Articles/1979/Lauer/On_the_duality_of_operating_system_structures_1979_Lauer.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/AA8D1917-9409-46B2-B0A7-146940300EA3}}
}

@book{Anonymous:2014ta,
publisher = {Springer Berlin Heidelberg},
year = {2014},
address = {Berlin, Heidelberg},
isbn = {978-3-642-54420-0},
rating = {0},
date-added = {2014-04-20T18:43:06GMT},
date-modified = {2014-04-26T22:51:08GMT},
uri = {\url{papers2://publication/uuid/1A6B3797-B837-4DA7-A000-DAA3FBA8CBD6}}
}

@inproceedings{Bauer:2012ku,
author = {Bauer, M and Treichler, S and Slaughter, E and Aiken, A},
title = {{Legion: Expressing locality and independence with logical regions}},
booktitle = {High Performance Computing, Networking, Storage and Analysis (SC), 2012 International Conference for},
year = {2012},
pages = {1--11},
publisher = { IEEE Computer Society},
doi = {10.1109/SC.2012.71},
read = {Yes},
rating = {0},
date-added = {2014-04-22T15:51:28GMT},
date-modified = {2014-04-26T22:51:08GMT},
abstract = {Modern parallel architectures have both heterogeneous processors and deep, complex memory hierarchies. We present Legion, a programming model and runtime system for achieving high performance on these machines. Legion is organized around logical regions, which express both locality and independence of program data, and tasks, functions that perform computations on regions. We describe a runtime system that dynamically extracts parallelism from Legion programs, using a distributed, parallel scheduling algorithm that identifies both independent tasks and nested parallelism. Legion also enables explicit, programmer controlled movement of data through the memory hierarchy and placement of tasks based on locality information via a novel mapping interface. We evaluate our Legion implementation on three applications: fluid-flow on a regular grid, a three-level AMR code solving a heat diffusion equation, and a circuit simulation. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6468504&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Legion%3A+Expressing+locality+and+independence+with+logical+regions%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Bauer/Legion_Expressing_locality_and_independence_with_logical_regions_2012_Bauer.pdf},
file = {{Legion_Expressing_locality_and_independence_with_logical_regions_2012_Bauer.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Bauer/Legion_Expressing_locality_and_independence_with_logical_regions_2012_Bauer.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SC.2012.71}}
}

@techreport{Scogland:2012wi,
author = {Scogland, Thomas R W and Feng, Wu{-chun} and Rountree, B and de Supinski, B R},
title = {{CoreTSAR: Task Scheduling for Accelerator-aware Runtimes}},
year = {2012},
number = {TR-12-20},
publisher = {Virginia Tech},
read = {Yes},
rating = {0},
date-added = {2012-12-03T15:48:45GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {Abstract Heterogeneous supercomputers that incorporate computational accelerators such as GPUs are increasingly popular due to their high peak performance, energy efficiency and comparatively low cost. Unfortunately, the programming models and frameworks designed ... 
},
url = {http://eprints.cs.vt.edu/archive/00001212/},
uri = {\url{papers2://publication/uuid/DFEC9610-C154-4A3B-957E-5EEB35FB3FAE}}
}

@article{Gebhart:wx,
author = {Gebhart, M and Keckler, S W and Khailany, B and Krashinsky, R and Dally, William J},
title = {{Unifying Primary Cache, Scratch, and Register File Memories in a Throughput Processor}},
journal = {cs.utexas.edu
},
read = {Yes},
rating = {0},
date-added = {2012-12-17T00:47:19GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {Abstract Modern throughput processors such as GPUs employ thousands of threads to drive high-bandwidth, long-latency memory systems. These threads require substantial on- chip storage for registers, cache , and scratchpad memory . Existing designs hard-partition this ... 
},
url = {http://www.cs.utexas.edu/users/mgebhart/papers/MICRO_2012.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Gebhart/Unifying_Primary_Cache_Scratch_and_Register_File_Memories_in_a_Throughput_Processor__Gebhart.pdf},
file = {{Unifying_Primary_Cache_Scratch_and_Register_File_Memories_in_a_Throughput_Processor__Gebhart.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Gebhart/Unifying_Primary_Cache_Scratch_and_Register_File_Memories_in_a_Throughput_Processor__Gebhart.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/4E59E0C0-ED0F-4CF6-96D7-26FA5426B846}}
}

@incollection{Jaeger:2014ft,
author = {Jaeger, Julien and Carribault, Patrick and P{\'e}rache, Marc},
title = {{Data-Management Directory for OpenMP 4.0 and OpenACC}},
year = {2014},
pages = {168--177},
publisher = {Springer Berlin Heidelberg},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-54420-0_17},
isbn = {978-3-642-54420-0},
read = {Yes},
rating = {0},
date-added = {2014-04-20T18:42:59GMT},
date-modified = {2014-04-26T22:51:08GMT},
abstract = {... Section 2, we present three motivating examples to detail the important problems to tackle while managing  data with these ... In this paper, we explained how it is posssible to handle such cases with this type of directory . ...  Data - Management  Directory for OpenMP 4.0 and OpenACC  ... 
},
url = {http://link.springer.com/10.1007/978-3-642-54420-0_17},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2014/Jaeger/Data-Management_Directory_for_OpenMP_4.0_and_OpenACC_2014_Jaeger.pdf},
file = {{Data-Management_Directory_for_OpenMP_4.0_and_OpenACC_2014_Jaeger.pdf:/Users/njustn/Dropbox/Papers2/Books/2014/Jaeger/Data-Management_Directory_for_OpenMP_4.0_and_OpenACC_2014_Jaeger.pdf:application/pdf;Data-Management_Directory_for_OpenMP_4.0_and_OpenACC_2014_Jaeger.pdf:/Users/njustn/Dropbox/Papers2/Books/2014/Jaeger/Data-Management_Directory_for_OpenMP_4.0_and_OpenACC_2014_Jaeger.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-54420-0_17}}
}

@incollection{Stratton:2008iy,
author = {Stratton, John A and Stone, Sam S and Hwu, Wen-mei W},
title = {{MCUDA: An Efficient Implementation of CUDA Kernels for Multi-core CPUs}},
year = {2008},
pages = {16--30},
publisher = {Springer Berlin Heidelberg},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-540-89740-8_2},
isbn = {978-3-540-89740-8},
read = {Yes},
rating = {0},
date-added = {2013-03-29T19:30:32GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Abstract CUDA is a data parallel programming model that supports several key abstractions- thread blocks, hierarchical memory and barrier synchronization-for writing applications. This model has proven effective in programming GPUs. In this paper we describe a framework ... 
},
url = {http://www.springerlink.com/index/10.1007/978-3-540-89740-8_2},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2008/Stratton/MCUDA_An_Efficient_Implementation_of_CUDA_Kernels_for_Multi-core_CPUs_2008_Stratton.pdf},
file = {{MCUDA_An_Efficient_Implementation_of_CUDA_Kernels_for_Multi-core_CPUs_2008_Stratton.pdf:/Users/njustn/Dropbox/Papers2/Books/2008/Stratton/MCUDA_An_Efficient_Implementation_of_CUDA_Kernels_for_Multi-core_CPUs_2008_Stratton.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-540-89740-8_2}}
}

@inproceedings{Rafique:2011it,
author = {Rafique, M Mustafa and Cadambi, Srihari and Rao, Kunal and Butt, Ali R and Chakradhar, Srimat},
title = {{Symphony: A Scheduler for Client-Server Applications on Coprocessor-Based Heterogeneous Clusters}},
booktitle = {Cluster Computing (CLUSTER), 2011 IEEE International Conference on},
year = {2011},
pages = {353--362},
doi = {10.1109/CLUSTER.2011.46},
rating = {0},
date-added = {2011-11-12T20:50:18GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {Coprocessors such as GPUs are increasingly being deployed in clusters to process scientific and compute-intensive jobs. In this work, we study if GPU-based heterogeneous clusters can benefit client-server applications. Specifically, we consider the practical situation where multiple client-server applications share a heterogeneous cluster (multi-tenancy), and experience unpredictable variations in incoming client request rates, including steep load spikes. Even for "compute-intensive" client-server applications, it is unclear if a GPU-based cluster can seamlessly deliver acceptable response times in the presence of multi-tenancy and load spikes. We argue that a cluster-level scheduler that is aware of application load, request deadlines and the heterogeneity is necessary in this situation. We propose a novel scheduler called Symphony that enables efficient, dynamic sharing of a GPU-based heterogeneous cluster across multiple concurrently-executing client-server applications, each with arbitrary load spikes. Symphony performs three key tasks: it (i) monitors the load on each application, (ii) collects past performance data and dynamically builds simple performance models of available processing resources and (iii) computes a priority for pending requests based on the above parameters and the requests' slack. Based on this, it reorders client requests across different applications to achieve acceptable response times. We also define how client-server applications should interact with a scheduler such as Symphony, and develop an API to this end. We deploy Symphony as user-space middleware on a high-end heterogeneous cluster with dual quad-core Xeon CPUs and dual NVIDIA Fermi GPUs. An evaluation using representative applications shows that in the presence of load spikes (i) Symphony incurs 2-20x fewer requests that do not meet response time constraints compared with other schedulers, and (ii) in order to achieve the same performance as Symphony, other schedulers need 2- - x more cluster nodes.},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6061154},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Rafique/Symphony_A_Scheduler_for_Client-Server_Applications_on_Coprocessor-Based_Heterogeneous_Clusters_2011_Rafique.pdf},
file = {{Symphony_A_Scheduler_for_Client-Server_Applications_on_Coprocessor-Based_Heterogeneous_Clusters_2011_Rafique.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Rafique/Symphony_A_Scheduler_for_Client-Server_Applications_on_Coprocessor-Based_Heterogeneous_Clusters_2011_Rafique.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/CLUSTER.2011.46}}
}

@article{Banga:1998va,
author = {Banga, G and Druschel, P},
title = {{Resource containers: A new facility for resource management in server systems}},
journal = {Operating Systems Review},
year = {1998},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:14:45GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {Page 1. Resource  containers : A new  facility for resource  management in server  systems * Gaurav Banga Peter Druschel Jeffrey C. Mogul Dept. of Computer Science Western Research Laboratory Rice University Compaq Computer Corporation Houston, TX 77005 ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.3856&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1998/Banga/Resource_containers_A_new_facility_for_resource_management_in_server_systems_1998_Banga.pdf},
file = {{Resource_containers_A_new_facility_for_resource_management_in_server_systems_1998_Banga.pdf:/Users/njustn/Dropbox/Papers2/Articles/1998/Banga/Resource_containers_A_new_facility_for_resource_management_in_server_systems_1998_Banga.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2706F78D-509D-4F61-A588-B806A376F83A}}
}

@book{Anonymous:2008ta,
publisher = {Springer Berlin Heidelberg},
year = {2008},
address = {Berlin, Heidelberg},
isbn = {978-3-540-89740-8},
rating = {0},
date-added = {2013-03-29T19:30:38GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/4299AE9C-32F4-4F90-B1FE-A127D61A5DB8}}
}

@inproceedings{Clarke:2012uo,
author = {Clarke, David and Ilic, Aleksandar and Lastovetsky, Alexey and Sousa, Leonel},
title = {{Hierarchical partitioning algorithm for scientific computing on highly heterogeneous CPU + GPU clusters}},
booktitle = {International Euro-Par Conference on Parallel Processing},
year = {2012},
publisher = { Springer-Verlag},
month = aug,
read = {Yes},
rating = {0},
date-added = {2012-12-17T01:46:09GMT},
date-modified = {2014-07-05T17:30:46GMT},
abstract = {Hierarchical level of heterogeneity exists in many modern high performance clusters in the form of heterogeneity between computing nodes, and within a node with the addition of specialized accelerators, such as GPUs. To achieve high performance of scientific},
url = {http://portal.acm.org/citation.cfm?id=2402420.2402479&coll=DL&dl=GUIDE&CFID=158011868&CFTOKEN=78978175},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Clarke/Hierarchical_partitioning_algorithm_for_scientific_computing_on_highly_heterogeneous_CPU_+_GPU_clusters_2012_Clarke.pdf},
file = {{Hierarchical_partitioning_algorithm_for_scientific_computing_on_highly_heterogeneous_CPU_+_GPU_clusters_2012_Clarke.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Clarke/Hierarchical_partitioning_algorithm_for_scientific_computing_on_highly_heterogeneous_CPU_+_GPU_clusters_2012_Clarke.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C8346C2C-CF68-40C2-BC6F-6FBF65D31387}}
}

@inproceedings{Petrini:2000kk,
author = {Petrini, F and Feng, Wu{-chun}},
title = {{Buffered Coscheduling: a New Methodology for Multitasking Parallel Jobs on Distributed Systems}},
crossref = {ipdps},
year = {2000},
doi = {10.1109/IPDPS.2000.846019},
read = {Yes},
rating = {0},
date-added = {2012-12-22T15:28:31GMT},
date-modified = {2014-07-05T21:03:16GMT},
abstract = {Buffered coscheduling is a scheduling methodology for time-sharing communicating processes in parallel and distributed systems. The methodology has two primary features: communication buffering and strobing. With communication buffering, communication generated by each processor is buffered and performed at the end of regular intervals to amortize communication and scheduling overhead. This infrastructure is then leveraged by a strobing mechanism to perform a total exchange of information at the end of each interval, thus providing global information to more efficiently schedule communicating processes. This paper describes how buffered coscheduling can optimize resource utilization by analyzing workloads with varying computational granularities, load imbalances, and communication patterns. The experimental results, performed using a detailed simulation model, show that buffered coscheduling is very effective on fast SANs such as Myrinet as well as slower switch-based LANs View full abstract},
url = {http://portal.acm.org/citation.cfm?id=846234.849351&coll=DL&dl=GUIDE&CFID=235034789&CFTOKEN=23748388},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Petrini/Buffered_Coscheduling_a_New_Methodology_for_Multitasking_Parallel_Jobs_on_Distributed_Systems_2000_Petrini-1.pdf},
file = {{Buffered_Coscheduling_a_New_Methodology_for_Multitasking_Parallel_Jobs_on_Distributed_Systems_2000_Petrini-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Petrini/Buffered_Coscheduling_a_New_Methodology_for_Multitasking_Parallel_Jobs_on_Distributed_Systems_2000_Petrini-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2000.846019}}
}

@inproceedings{Yang:2012bc,
author = {Yang, Yi and Xiang, Ping and Mantor, Mike and Rubin, Norm and Zhou, Huiyang},
title = {{Shared memory multiplexing: a novel way to improve GPGPU throughput}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2012},
publisher = {ACM},
month = sep,
doi = {10.1145/2370816.2370858},
rating = {0},
date-added = {2013-04-03T18:29:31GMT},
date-modified = {2014-07-05T17:37:18GMT},
abstract = {On-chip shared memory (a.k.a. local data share) is a critical resource to many GPGPU applications. In current GPUs, the shared memory is allocated when a thread block (also called a workgroup) is dispatched to a streaming multiprocessor (SM) and is released},
url = {http://portal.acm.org/citation.cfm?id=2370816.2370858&coll=DL&dl=GUIDE&CFID=200475685&CFTOKEN=41320441},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Yang/Shared_memory_multiplexing_a_novel_way_to_improve_GPGPU_throughput_2012_Yang.pdf},
file = {{Shared_memory_multiplexing_a_novel_way_to_improve_GPGPU_throughput_2012_Yang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Yang/Shared_memory_multiplexing_a_novel_way_to_improve_GPGPU_throughput_2012_Yang.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2370816.2370858}}
}

@inproceedings{Meng:2012fl,
author = {Meng, Jiayuan and Morozov, V A and Vishwanath, V and Kumaran, K},
title = {{Dataflow-driven GPU performance projection for multi-kernel transformations}},
crossref = {supercomputing},
year = {2012},
pages = {1--11},
publisher = { IEEE Computer Society Press},
doi = {10.1109/SC.2012.42},
rating = {0},
date-added = {2013-04-09T13:58:07GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Applications often have a sequence of parallel operations to be offloaded to graphics processors; each operation can become an individual GPU kernel. Developers typically explore a variety of transformations for each kernel. Furthermore, it is well known that efficient data management is critical in achieving high GPU performance and that "fusing" multiple kernels into one may greatly improve data locality. Doing so, however, requires transformations across multiple, potentially nested, parallel loops; at the same time, the original code semantics and data dependency must be preserved. Since each kernel may have distinct data access patterns, their combined dataflow can be nontrivial. As a result, the complexity of multi-kernel transformations often leads to significant effort with no guarantee of performance benefits. This paper proposes a dataflow-driven analytical framework to project GPU performance for a sequence of parallel operations. Users need only provide CPU code skeletons for a sequence of parallel loops. The framework can then automatically identify opportunities for multi-kernel transformations and data management. It is also able to project the overall performance without implementing GPU code or using physical hardware. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6468531&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Title%3A%22Dataflow-Driven+GPU+Performance+Projection+for+Multi-Kernel+Transformations%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Meng/Dataflow-driven_GPU_performance_projection_for_multi-kernel_transformations_2012_Meng.pdf},
file = {{Dataflow-driven_GPU_performance_projection_for_multi-kernel_transformations_2012_Meng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Meng/Dataflow-driven_GPU_performance_projection_for_multi-kernel_transformations_2012_Meng.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SC.2012.42}}
}

@inproceedings{Vetter:2010uf,
author = {McCurdy, Collin and Vetter, Jeffrey},
title = {{Memphis: Finding and fixing NUMA-related performance problems on multi-core platforms}},
booktitle = {amp; Software (ISPASS 2010)},
year = {2010},
pages = {87--96},
publisher = {IEEE},
doi = {10.1109/ISPASS.2010.5452060},
isbn = {978-1-4244-6023-6},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-12-07T00:29:01GMT},
date-modified = {2014-04-17T19:10:42GMT},
abstract = {Abstract Until recently, most high-end scientific applications have been immune to performance problems caused by Non-Uniform Memory Access (NUMA). However, current trends in micro-processor design are pushing NUMA to smaller and smaller scales. This  ...},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5452060},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/McCurdy/Memphis_Finding_and_fixing_NUMA-related_performance_problems_on_multi-core_platforms_2010_McCurdy.pdf},
file = {{Memphis_Finding_and_fixing_NUMA-related_performance_problems_on_multi-core_platforms_2010_McCurdy.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/McCurdy/Memphis_Finding_and_fixing_NUMA-related_performance_problems_on_multi-core_platforms_2010_McCurdy.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ISPASS.2010.5452060}}
}

@inproceedings{Sidelnik:2012if,
author = {Sidelnik, Albert and Maleki, Saeed and Chamberlain, Bradford L and Garzar{\'a}n, Maria J and Padua, David},
title = {{Performance Portability with the Chapel Language}},
crossref = {ipdps},
year = {2012},
publisher = { IEEE Computer Society},
month = may,
doi = {10.1109/IPDPS.2012.60},
read = {Yes},
rating = {0},
date-added = {2012-12-29T18:38:27GMT},
date-modified = {2014-07-05T21:10:35GMT},
abstract = {It has been widely shown that high-throughput computing architectures such as GPUs offer large performance gains compared with their traditional low-latency counterparts for many applications. The downside to these architectures is that the current programming},
url = {http://portal.acm.org/citation.cfm?id=2357496.2358638&coll=DL&dl=GUIDE&CFID=503165723&CFTOKEN=23231624},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Sidelnik/Performance_Portability_with_the_Chapel_Language_2012_Sidelnik.pdf},
file = {{Performance_Portability_with_the_Chapel_Language_2012_Sidelnik.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Sidelnik/Performance_Portability_with_the_Chapel_Language_2012_Sidelnik.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2012.60}}
}

@inproceedings{Lee:2012dr,
author = {Lee, Dongyoon and Chen, Peter M and Flinn, Jason and Narayanasamy, Satish},
title = {{Chimera: hybrid program analysis for determinism}},
booktitle = {Conference on Programming Language Design and Implementation},
year = {2012},
publisher = {ACM},
month = jun,
doi = {10.1145/2254064.2254119},
read = {Yes},
rating = {0},
date-added = {2013-04-09T18:30:24GMT},
date-modified = {2014-07-05T17:37:49GMT},
abstract = {Chimera uses a new hybrid program analysis to provide deterministic replay for commodity multiprocessor systems. Chimera leverages the insight that it is easy to provide deterministic multiprocessor replay for data-race-free programs (one can just record},
url = {http://portal.acm.org/citation.cfm?id=2254064.2254119&coll=DL&dl=ACM&CFID=202542847&CFTOKEN=39779172},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Lee/Chimera_hybrid_program_analysis_for_determinism_2012_Lee.pdf},
file = {{Chimera_hybrid_program_analysis_for_determinism_2012_Lee.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Lee/Chimera_hybrid_program_analysis_for_determinism_2012_Lee.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2254064.2254119}}
}

@inproceedings{Muralidharan:-RgVcyZB,
author = {Muralidharan, Saurav and Shantharam, Manu and Hall, Mary and Garland, Michael and Catanzaro, Bryan},
title = {{Nitro: A Framework for Adaptive Code Variant Tuning}},
crossref = {ipdps},
rating = {0},
date-added = {2014-06-04T01:35:23GMT},
date-modified = {2014-07-05T17:43:45GMT},
url = {http://www.cs.utah.edu/~sauravm/docs/nitro_ipdps2014.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Muralidharan/Nitro_A_Framework_for_Adaptive_Code_Variant_Tuning__Muralidharan.pdf},
file = {{Nitro_A_Framework_for_Adaptive_Code_Variant_Tuning__Muralidharan.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Muralidharan/Nitro_A_Framework_for_Adaptive_Code_Variant_Tuning__Muralidharan.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F9181573-2641-4984-ADC0-7B32EFE1A88D}}
}

@inproceedings{Nikolopoulos:2000km,
author = {Nikolopoulos, D.S. and Papatheodorou, T.S. and Polychronopoulos, C.D. and Labarta, J. and Ayguad{\'e}, Eduard},
title = {{Is Data Distribution Necessary in OpenMP?}},
crossref = {supercomputing},
year = {2000},
pages = {47},
doi = {10.1109/SC.2000.10025},
read = {Yes},
rating = {0},
date-added = {2014-06-07T18:59:44GMT},
date-modified = {2014-07-05T21:02:27GMT},
abstract = {This paper investigates the performance implications of data placement in OpenMP programs running on modern ccNUMA multiprocessors. Data locality and minimization of the rate of remote memory accesses are critical for sustaining high performance on these systems. We show that due to the low remote-to-local memory access latency ratio of state-of-the-art ccNUMA architectures, reasonably balanced page placement schemes, such as round-robin or random distribution of pages incur modest performance losses. We also show that performance leaks stemming from suboptimal page placement schemes can be remedied with a smart user-level page migration engine. The main body of the paper describes how the OpenMP runtime environment can use page migration for implementing implicit data distribution and redistribution schemes without programmer intervention. Our experimental results support the effectiveness of these mechanisms and provide a proof of concept that there is no need to introduce data distribution directives in OpenMP and warrant the portability of the programming model. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1592760&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22is+data+distribution+necessary+in+openmp%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Nikolopoulos/Is_Data_Distribution_Necessary_in_OpenMP_2000_Nikolopoulos-1.pdf},
file = {{Is_Data_Distribution_Necessary_in_OpenMP_2000_Nikolopoulos-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Nikolopoulos/Is_Data_Distribution_Necessary_in_OpenMP_2000_Nikolopoulos-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SC.2000.10025}}
}

@inproceedings{Ganai:2012kq,
author = {Ganai, Malay and Lee, Dongyoon and Gupta, Aarti},
title = {{DTAM: dynamic taint analysis of multi-threaded programs for relevancy}},
booktitle = {FSE '12: Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
year = {2012},
publisher = {ACM},
month = nov,
doi = {10.1145/2393596.2393650},
read = {Yes},
rating = {0},
date-added = {2013-04-09T18:30:49GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Testing and debugging multi-threaded programs are notoriously difficult due to non-determinism not only in inputs but also in OS schedules. In practice, dynamic analysis and failure replay systems instrument the program to record events of interest in},
url = {http://portal.acm.org/citation.cfm?id=2393596.2393650&coll=DL&dl=ACM&CFID=202542847&CFTOKEN=39779172},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Ganai/DTAM_dynamic_taint_analysis_of_multi-threaded_programs_for_relevancy_2012_Ganai.pdf},
file = {{DTAM_dynamic_taint_analysis_of_multi-threaded_programs_for_relevancy_2012_Ganai.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Ganai/DTAM_dynamic_taint_analysis_of_multi-threaded_programs_for_relevancy_2012_Ganai.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2393596.2393650}}
}

@inproceedings{Spafford:2011ix,
author = {Spafford, Kyle and Meredith, Jeremy S and Vetter, Jeffrey S},
title = {{Quantifying NUMA and contention effects in multi-GPU systems}},
booktitle = {Annual Workshop on General Purpose Processing with Graphics Processing Units},
year = {2011},
pages = {1},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/1964179.1964194},
isbn = {9781450305693},
read = {Yes},
rating = {0},
date-added = {2014-06-09T18:30:48GMT},
date-modified = {2014-07-05T17:33:37GMT},
abstract = {Abstract As system architects strive for increased density and power efficiency, the traditional compute node is being augmented with an increasing number of graphics processing units ( GPUs ). The integration of multiple GPUs per node introduces complex performance ... 
},
url = {http://www.kylespafford.com/wp-content/uploads/2011/02/numa.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Spafford/Quantifying_NUMA_and_contention_effects_in_multi-GPU_systems_2011_Spafford-1.pdf},
file = {{Quantifying_NUMA_and_contention_effects_in_multi-GPU_systems_2011_Spafford-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Spafford/Quantifying_NUMA_and_contention_effects_in_multi-GPU_systems_2011_Spafford-1.pdf:application/pdf;Quantifying_NUMA_and_contention_effects_in_multi-GPU_systems_2011_Spafford-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Spafford/Quantifying_NUMA_and_contention_effects_in_multi-GPU_systems_2011_Spafford-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1964179.1964194}}
}

@book{Vetter:2013ve,
author = {Vetter, Jeffrey S},
title = {{Contemporary High Performance Computing}},
publisher = {Chapman {\&} Hall},
year = {2013},
series = {From Petascale Toward Exascale},
month = mar,
isbn = {9781466568341},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-04-14T14:43:31GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {"While there are many important systems in high performance computing (HPC) available today, the HPC community lacks a single reference on the key aspects of the systems, such as application workloads, procurement timeline, and facilities specification. This book provides the first comprehensive resource to describe these systems and their hardware and software architectures. The first part of the book explores current trends in HPC. The second part presents detailed descriptions of deployed systems thatspan a number of architectures, application workloads, facilities, and sponsors"--},
url = {http://books.google.com/books?id=sFA0LgEACAAJ&dq=Contemporary+High+Performance+Computing+From+Petascale+toward+Exascale&hl=&cd=1&source=gbs_api},
uri = {\url{papers2://publication/uuid/D580D758-C27C-4614-AC4E-59C793EB7A60}}
}

@article{Gebhart:2012jy,
author = {Gebhart, Mark and Johnson, Daniel R and Tarjan, David and Keckler, Stephen W and Dally, William J and Lindholm, Erik and Skadron, Kevin},
title = {{A Hierarchical Thread Scheduler and Register File for Energy-Efficient Throughput Processors}},
journal = {Transactions on Computer Systems (TOCS},
year = {2012},
volume = {30},
number = {2},
month = apr,
publisher = {ACM},
doi = {10.1145/2166879.2166882},
read = {Yes},
rating = {0},
date-added = {2012-05-05T15:50:14GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Modern graphics processing units (GPUs) employ a large number of hardware threads to hide both function unit and memory access latency. Extreme multithreading requires a complex thread scheduler as well as a large register file, which is expensive to},
url = {http://portal.acm.org/citation.cfm?id=2166879.2166882&coll=DL&dl=GUIDE&CFID=80768635&CFTOKEN=20419610},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Gebhart/A_Hierarchical_Thread_Scheduler_and_Register_File_for_Energy-Efficient_Throughput_Processors_2012_Gebhart.pdf},
file = {{A_Hierarchical_Thread_Scheduler_and_Register_File_for_Energy-Efficient_Throughput_Processors_2012_Gebhart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Gebhart/A_Hierarchical_Thread_Scheduler_and_Register_File_for_Energy-Efficient_Throughput_Processors_2012_Gebhart.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2166879.2166882}}
}

@inproceedings{Spafford:2010ut,
author = {Spafford, Kyle and Meredith, Jeremy and Vetter, Jeffrey},
title = {{Maestro: Data Orchestration and Tuning for OpenCL Devices}},
booktitle = {International Euro-Par Conference on Parallel Processing},
year = {2010},
publisher = { Springer-Verlag},
month = aug,
read = {Yes},
rating = {0},
date-added = {2012-05-10T18:19:34GMT},
date-modified = {2014-07-06T22:05:32GMT},
abstract = {As heterogeneous computing platforms become more prevalent, the programmer must account for complex memory hierarchies in addition to the difficulties of parallel programming. OpenCL is an open standard for parallel computing that helps alleviate this},
url = {http://portal.acm.org/citation.cfm?id=1885276.1885305&coll=DL&dl=GUIDE&CFID=81795097&CFTOKEN=86816679},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Spafford/Maestro_Data_Orchestration_and_Tuning_for_OpenCL_Devices_2010_Spafford-1.pdf},
file = {{Maestro_Data_Orchestration_and_Tuning_for_OpenCL_Devices_2010_Spafford-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Spafford/Maestro_Data_Orchestration_and_Tuning_for_OpenCL_Devices_2010_Spafford-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6C009730-C98A-42C5-9770-A087DBBA531B}}
}

@inproceedings{Min:2013jv,
author = {Min, Changwoo and Eom, Young Ik},
title = {{Can Lock-Free and Combining Techniques Co-Exist? A Novel Approach on Concurrent Queue}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2013},
pages = {403},
doi = {10.1109/PACT.2013.6618837},
read = {Yes},
rating = {0},
date-added = {2014-06-11T01:20:32GMT},
date-modified = {2014-07-05T19:31:46GMT},
abstract = {Concurrent queues are one of the most fundamental concurrent data structures. Most previous research focuses on how to avoid the contended hot spots, Head and Tail, and there are two contradictory approaches: (1) lock-free techniques [1], [2], which increase the degree of parallelism to improve performance and (2) combining techniques [3], where a single combining thread performs a batch operation for the pending requests from other threads to reduce synchronization cost in a high degree of parallelism. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6618837&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Can+lock-free+and+combining+techniques+co-exist%3F%3A+a+novel+approach+on+concurrent+queue%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Min/Can_Lock-Free_and_Combining_Techniques_Co-Exist_A_Novel_Approach_on_Concurrent_Queue_2013_Min-1.pdf},
file = {{Can_Lock-Free_and_Combining_Techniques_Co-Exist_A_Novel_Approach_on_Concurrent_Queue_2013_Min-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Min/Can_Lock-Free_and_Combining_Techniques_Co-Exist_A_Novel_Approach_on_Concurrent_Queue_2013_Min-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/PACT.2013.6618837}}
}

@inproceedings{feng-globecom2002-green,
author = {Feng, Wu{-chun} and Kapadia, Apu C and Thulasidasan, Sunil},
title = {{GREEN: Proactive Queue Management over a Best-Effort Network}},
booktitle = {IEEE GlobeCom (GLOBECOM 2002)},
year = {2002},
address = {Taipei, Taiwan},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:51GMT},
uri = {\url{papers2://publication/uuid/7D6637B2-B69D-4521-A9BC-32ABF6F494C8}}
}

@inproceedings{Grass:2013co,
author = {Grass, T},
title = {{Task Sampling: Computer Architecture Simulation in the Many-Core Era}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2013},
pages = {405},
doi = {10.1109/PACT.2013.6618838},
read = {Yes},
rating = {0},
date-added = {2014-06-11T01:27:29GMT},
date-modified = {2014-07-05T20:45:12GMT},
abstract = {Chip Multi-Processors (CMPs) are evolving towards ever increasing core counts. Task-based programming models are a promising candidate for exploiting the parallelism offered by these machines. Simulation, the prevailing design methodology in computer architecture, is prohibitively time consuming, when it comes to CMPs featuring 1000s of cores. Sampled simulation is a standard technique for reducing simulation time for single-threaded architectures. Recently, these techniques have been extended to allow for simulation of multi-threaded systems. However, they have not been assessed for dynamically scheduled multi-threaded programs. In this work we use the OmpSs programming model [4]. OmpSs, an extension of OpenMP, allows to declare code blocks as tasks and to specify data consumed and produced by each task. The runtime environment executes tasks, potentially out of program order, on available cores, similar to the out-oforder execution in a superscalar processor. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6618838&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Task+Sampling+Computer+Architecture+Simulation+in+the+Many-Core+Era%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Grass/Task_Sampling_Computer_Architecture_Simulation_in_the_Many-Core_Era_2013_Grass-1.pdf},
file = {{Task_Sampling_Computer_Architecture_Simulation_in_the_Many-Core_Era_2013_Grass-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Grass/Task_Sampling_Computer_Architecture_Simulation_in_the_Many-Core_Era_2013_Grass-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/PACT.2013.6618838}}
}

@inproceedings{Basumallik:2007ic,
author = {Basumallik, A and Min, Seung-Jai and Eigenmann, R},
title = {{Programming Distributed Memory Sytems Using OpenMP}},
crossref = {ipdps},
year = {2007},
pages = {1--8},
doi = {10.1109/IPDPS.2007.370397},
rating = {0},
date-added = {2014-07-03T15:21:37GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {OpenMP has emerged as an important model and language extension for shared-memory parallel programming. On shared-memory platforms, OpenMP offers an intuitive, incremental approach to parallel programming. In this paper, we present techniques that extend the ease of shared-memory parallel programming in OpenMP to distributed-memory platforms as well. First, we describe a combined compile-time/runtime system that uses an underlying software distributed shared memory system and exploits repetitive data access behavior in both regular and irregular program sections. We present a compiler algorithm to detect such repetitive data references and an API to an underlying software distributed shared memory system to orchestrate the learning and proactive reuse of communication patterns. Second, we introduce a direct translation of standard OpenMP into MPI message-passing programs for execution on distributed memory systems. We present key concepts and describe techniques to analyze and efficiently handle both regular and irregular accesses to shared data. Finally, we evaluate the performance achieved by our approaches on representative OpenMP applications. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4228125&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Programming+Distributed+Memory+Sytems+Using%22%29},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2007.370397}}
}

@inproceedings{banerjee-ipdps2006-rapid,
author = {Banerjee, Amitabha and Feng, Wu{-chun} and Mukherjee, Biswanath and Ghosal, Dipak},
title = {{RAPID: An End-System Aware Protocol for Intelligent Data-Transfer over LambdaGrids}},
crossref = {ipdps},
year = {2006},
address = {Rhodes, Greece},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:51GMT},
uri = {\url{papers2://publication/uuid/9DFB0FCC-5574-486D-865D-488CBB5ADD1A}}
}

@techreport{hsu-feb2005-dvs,
author = {Hsu, Chung-hsing and Feng, Wu{-chun}},
title = {{When Discreteness Meets Continuity: Energy-Optimal DVS Scheduling Revisited}},
year = {2005},
month = feb,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:51GMT},
uri = {\url{papers2://publication/uuid/8C70561E-05CF-4E99-A15B-5C99140DD4BD}}
}

@inproceedings{gardner-icvci2009-eco,
author = {Gardner, Mark K and Herr, Adam and Mazary, David and Lin, Heshan and Scogland, Thomas R W and Feng, Wu{-chun}},
title = {{A Flexible and Extensible Framework for Delivering Designer Images for K-12 Pedagogy}},
booktitle = {3rd International Conference on the Virtual Computing Initiative (ICVCI)},
year = {2009},
address = {Research Triangle Park, NC},
month = oct,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {Motivation K-12 schools are ``under the gun'' because they are increasingly expected to do more with less funding. The strains on already-strapped school districts make it extremely challenging for these schools to adopt any meaningful curricular changes to improve the ... 
},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.172.1090&rep=rep1&type=pdf},
uri = {\url{papers2://publication/uuid/C0F8F298-E432-4219-A729-C1557B4EFE0B}}
}

@article{hsu-lncs2005-voltagescaling,
author = {Hsu, Chung-hsing and Feng, Wu{-chun}},
title = {{Effective Dynamic Voltage Scaling through CPU-Boundedness Detection}},
journal = {Lecture Notes in Computer Science},
year = {2005},
pages = {135--149},
month = feb,
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
url = {http://www.springerlink.com/index/7741468844462829.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/Hsu/Effective_Dynamic_Voltage_Scaling_through_CPU-Boundedness_Detection_2005_Hsu.pdf},
file = {{Effective_Dynamic_Voltage_Scaling_through_CPU-Boundedness_Detection_2005_Hsu.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Hsu/Effective_Dynamic_Voltage_Scaling_through_CPU-Boundedness_Detection_2005_Hsu.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/D180EFE8-E693-45A2-BE1C-1F41CE999F0A}}
}

@inproceedings{feng05:10gige_toe,
author = {Feng, Wu{-chun} and Balaji, Pavan and Baron, Chris and Bhuyan, Laxmi and Panda, Dhabaleswar},
title = {{Performance Characterization of a 10-Gigabit Ethernet TOE}},
booktitle = {13th IEEE International Symposium on High-Performance Interconnects (Hot Interconnects)},
year = {2005},
address = {Palo Alto, California},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T19:10:09GMT},
uri = {\url{papers2://publication/uuid/3D38BFF3-4AED-4D82-829B-E4026D632CC3}}
}

@inproceedings{Bailey:1991kk,
author = {Bailey, D H and Barszcz, E and Barton, J.T and Browning, D.S and Carter, R.L and Dagum, L and Fatoohi, R.A and Frederickson, P.O and Lasinski, T.A and Schreiber, R.S and Simon, H.D and Venkatakrishnan, V and Weeratunga, S.K},
title = {{The {NAS} Parallel Benchmarks Summary and Preliminary Results}},
crossref = {supercomputing},
year = {1991},
pages = {158--165},
keywords = {ipdps11-omp-co},
doi = {10.1145/125826.125925},
read = {Yes},
rating = {0},
date-added = {2011-11-13T01:01:52GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {A new set of benchmarks has been developed for the performance evaluation of highly parallel supercomputers. These benchmarks consist of five "parallel kernel" benchmarks and three "simulated application" benchmarks. Together they mimic the computation and data movement characteristics of large scale computational fluid dynamics applications. The principal distinguishing feature of these benchmarks is their "pencil and paper" specification-all details of these benchmarks are specified only algorithmically. In this way many of the difficulties associated with conventional benchmarking approaches on highly parallel systems are avoided.},
url = {http://portal.acm.org/citation.cfm?id=125826.125925},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1991/Bailey/The_%7BNAS%7D_Parallel_Benchmarks_Summary_and_Preliminary_Results_1991_Bailey.pdf},
file = {{The_{NAS}_Parallel_Benchmarks_Summary_and_Preliminary_Results_1991_Bailey.pdf:/Users/njustn/Dropbox/Papers2/Articles/1991/Bailey/The_{NAS}_Parallel_Benchmarks_Summary_and_Preliminary_Results_1991_Bailey.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/125826.125925}}
}

@techreport{feng-2006-machineroom_talk,
author = {Feng, Wu{-chun}},
title = {{Global Climate Warming? Yes {\ldots} In the Machine Room}},
year = {2006},
month = sep,
annote = {(invited talk)},
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B768CF3D-A259-4A99-9692-2B9DAB7A5F11}}
}

@techreport{ayyorgun-oct2003-interference,
author = {Ayyorgun, Sami and Cruz, R},
title = {{Interference Control at Packet-level in Wireless Networks with Quality of Service Support}},
year = {2003},
month = oct,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-03-21T11:56:15GMT},
uri = {\url{papers2://publication/uuid/45438299-120F-41DC-8CED-B72785509FF4}}
}

@inproceedings{feng-green500list-year2,
author = {Feng, Wu{-chun} and Lin, Heshan},
title = {{The Green500 List: Year Two}},
crossref = {hppac},
year = {2010},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/33480E06-D034-4848-B3D6-2F6D5BADEDA3}}
}

@inproceedings{hsu-cluster2005-power_feasibility,
author = {Hsu, Chung-hsing and Feng, Wu{-chun}},
title = {{A Feasibility Analysis of Power Awareness in Commodity-Based High-Performance Clusters}},
booktitle = {7th IEEE International Conference on Cluster Computing (CLUSTER'05)},
year = {2005},
address = {Boston, Massachusetts},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5F74B3E1-0CFA-4642-B90B-EF000576AF94}}
}

@article{Kirk:1984vb,
author = {Kirk, M and McKusick, MK and Joy, WN and Leffler, SJ},
title = {{A Fast File System for UNIX*}},
year = {1984},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:15:27GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {A reimplementation of the UNIX file system is described. The reimplementation provides substantially higher throughput rates by using more flexible allocation policies that allow better locality of reference and can be adapted to a wide range of peripheral and processor characteristics. The new ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.38.5275},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1984/Kirk/A_Fast_File_System_for_UNIX_1984_Kirk.pdf},
file = {{A_Fast_File_System_for_UNIX_1984_Kirk.pdf:/Users/njustn/Dropbox/Papers2/Articles/1984/Kirk/A_Fast_File_System_for_UNIX_1984_Kirk.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DA5E9FDE-259C-4863-B56B-AAFB96DF7FD4}}
}

@article{Satish:2012hh,
author = {Satish, N and Kim, C and Chhugani, J and Saito, H and Krishnaiyer, R and Smelyanskiy, M and Girkar, M and Dubey, P},
title = {{Can traditional programming bridge the Ninja performance gap for parallel computing applications?}},
journal = {Computer Architecture (ISCA), 2012 39th Annual International Symposium on},
year = {2012},
pages = {440--451},
doi = {10.1109/ISCA.2012.6237038},
read = {Yes},
rating = {0},
date-added = {2013-09-20T13:10:51GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Current processor trends of integrating more cores with wider SIMD units, along with a deeper and complex memory hierarchy, have made it increasingly more challenging to extract performance from applications. It is believed by some that traditional approaches to programming do not apply to these modern processors and hence radical new languages must be discovered. In this paper, we question this thinking and offer evidence in support of traditional programming methods and the performance-vs-programming effort effectiveness of common multi-core processors and upcoming manycore architectures in delivering significant speedup, and close-to-optimal performance for commonly used parallel computing workloads. We first quantify the extent of the ``Ninja gap'', which is the performance gap between naively written C/C++ code that is parallelism unaware (often serial) and best-optimized code on modern multi-/many-core processors. Using a set of representative throughput computing benchmarks, we show that there is an average Ninja gap of 24X (up to 53X) for a recent 6-core Intel{\textregistered} Core{\texttrademark} i7 X980 Westmere CPU, and that this gap if left unaddressed will inevitably increase. We show how a set of well-known algorithmic changes coupled with advancements in modern compiler technology can bring down the Ninja gap to an average of just 1.3X. These changes typically require low programming effort, as compared to the very high effort in producing Ninja code. We also discuss hardware support for programmability that can reduce the impact of these changes and even further increase programmer productivity. We show equally encouraging results for the upcoming Intel{\textregistered} Many Integrated Core architecture (Intel{\textregistered} MIC) which has more cores and wider SIMD. We thus demonstrate that we can contain the otherwise uncontrolled growth of the Ninja gap and offer a more stable and predictable performance growth over future archit- ctures, offering strong evidence that radical language changes are not required. View full abstract},
url = {http://dl.acm.org/citation.cfm?id=2337210},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Satish/Can_traditional_programming_bridge_the_Ninja_performance_gap_for_parallel_computing_applications_2012_Satish.pdf},
file = {{Can_traditional_programming_bridge_the_Ninja_performance_gap_for_parallel_computing_applications_2012_Satish.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Satish/Can_traditional_programming_bridge_the_Ninja_performance_gap_for_parallel_computing_applications_2012_Satish.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ISCA.2012.6237038}}
}

@article{Swift:2005un,
author = {Swift, MM and Bershad, BN},
title = {{Improving the reliability of commodity operating systems}},
journal = {{\ldots} on Computer Systems (TOCS)},
year = {2005},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:58:30GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Despite decades of research in extensible operating system technology, extensions such as device drivers remain a significant cause of system failures. In Windows XP, for example, drivers account for 85\% of recently reported failures. This article describes Nooks, a reliability ...},
url = {http://portal.acm.org/citation.cfm?id=1047919},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/Swift/Improving_the_reliability_of_commodity_operating_systems_2005_Swift.pdf},
file = {{Improving_the_reliability_of_commodity_operating_systems_2005_Swift.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Swift/Improving_the_reliability_of_commodity_operating_systems_2005_Swift.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/B8490DBB-78F8-4AEA-B7FE-E540689A3027}}
}

@inproceedings{aji-biocomputing-iccabs11,
author = {Bisset, Keith and Aji, Ashwin M and Marathe, Madhav and Feng, Wu{-chun}},
title = {{High-Performance Biocomputing for Simulating the Spread of Contagion over Large Contact Networks}},
booktitle = {IEEE International Conference on Computational Advances in Bio and medical Sciences (ICCABS)},
year = {2011},
address = {Orlando, Florida, USA},
month = feb,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/CE074479-2135-484D-8331-D7756A4521A0}}
}

@techreport{gardner-thesis1999-rts,
author = {Gardner, Mark K},
title = {{Probabilistic Analysis and Scheduling of Critical Soft Real-Time Systems}},
year = {1999},
month = sep,
annote = {[Based on research performed at UIUC]},
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/7CCCCB23-4894-43B1-9D04-4505875C91E3}}
}

@inproceedings{huang-hppac08-ixp,
author = {Huang, Song and Luo, Yan and Feng, Wu{-chun}},
title = {{Modeling and Analysis of Power in Multicore Network Processors}},
crossref = {hppac},
year = {2008},
address = {Miami, Florida, USA},
month = apr,
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {With the emergence of multicore network processors in support of high-performance computing and networking applications, power consumption has become a problem of increasing significance. Lower- power multicore proces- sors, such as the Intel IXP network ...},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4536224},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Huang/Modeling_and_Analysis_of_Power_in_Multicore_Network_Processors_2008_Huang.pdf},
file = {{Modeling_and_Analysis_of_Power_in_Multicore_Network_Processors_2008_Huang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Huang/Modeling_and_Analysis_of_Power_in_Multicore_Network_Processors_2008_Huang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F13DB6B8-86E6-4E8C-BD92-3620853F169A}}
}

@inproceedings{Jiao:2010cb,
author = {Jiao, Y and Lin, H and Balaji, Pavan and Feng, Wu{-chun}},
title = {{Power and Performance Characterization of Computational Kernels on the GPU}},
booktitle = {Green Computing and Communications (GreenCom), 2010 IEEE/ACM Int'l Conference on {\&} Int'l Conference on Cyber, Physical and Social Computing (CPSCom},
year = {2010},
pages = {221--228},
publisher = { IEEE Computer Society},
doi = {10.1109/GreenCom-CPSCom.2010.143},
read = {Yes},
rating = {0},
date-added = {2012-01-29T23:08:22GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {Nowadays Graphic Processing Units (GPU) are gaining increasing popularity in high performance computing (HPC). While modern GPUs can offer much more computational power than CPUs, they also consume much more power. Energy efficiency is one of the most important factors that will affect a broader adoption of GPUs in HPC. In this paper, we systematically characterize the power and energy efficiency of GPU computing. Specifically, using three different applications with various degrees of compute and memory intensiveness, we investigate the correlation between power consumption and different computational patterns under various voltage and frequency levels. Our study revealed that energy saving mechanisms on GPUs behave considerably different than CPUs. The characterization results also suggest possible ways to improve the 'greenness' of GPU computing.},
url = {http://ieeexplore.ieee.org/search/freesrchabstract.jsp?tp=&arnumber=5724833},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Jiao/Power_and_Performance_Characterization_of_Computational_Kernels_on_the_GPU_2010_Jiao.pdf},
file = {{Power_and_Performance_Characterization_of_Computational_Kernels_on_the_GPU_2010_Jiao.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Jiao/Power_and_Performance_Characterization_of_Computational_Kernels_on_the_GPU_2010_Jiao.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/GreenCom-CPSCom.2010.143}}
}

@inproceedings{feng-hppac2007-green,
author = {Feng, Wu{-chun} and Ching, Avery and Hsu, Chung-hsing},
title = {{Green Supercomputing in a Desktop Box}},
crossref = {hppac},
year = {2007},
address = {Long Beach, California},
month = mar,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/744A556D-BB6C-465F-B8D0-F6E96C6CFAF7}}
}

@article{Sato:2000ta,
author = {Sato, M and Harada, H and Ishikawa, Y},
title = {{OpenMP Compiler for a Software Distributed Shared Memory System SCASH}},
journal = {WOMPAT},
year = {2000},
rating = {0},
date-added = {2014-07-03T15:26:23GMT},
date-modified = {2014-07-05T19:29:58GMT},
abstract = {In this paper, we present an implementation of OpenMP compiler for a page-based software distributed shared memory system , SCASH on a cluster of PCs. For programming distributed memory multiprocessors such as clusters of PC/WS and MPP, message passing is usually},
url = {http://www.pccluster.org:443/score_doc/score-5.2.0/papers/sato00.pdf},
uri = {\url{papers2://publication/uuid/93DE4E14-A2E3-400F-ACB4-617A5A5159C8}}
}

@techreport{ayyorgun-sep2003-traffic,
author = {Ayyorgun, Sami and Feng, Wu{-chun}},
title = {{A New Traffic Model and Its Implications over Multiplexers and Switches}},
year = {2003},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/E952B060-CA21-4AC7-9040-A7BA91FB972A}}
}

@inproceedings{aji-gpu-rmap-cse10,
author = {Aji, Ashwin M and Zhang, Liqing and Feng, Wu{-chun}},
title = {{GPU-RMAP: Accelerating Short-Read Mapping on Graphics Processors}},
booktitle = {13th IEEE International Conference on Computational Science and Engineering},
year = {2010},
address = {Hong Kong, China},
month = dec,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/167E5A95-617B-40E5-AF71-CA70FCC55EC2}}
}

@article{feng-jsc2002-magnet,
author = {Feng, Wu{-chun} and Gardner, Mark K and Hay, Jeffrey R},
title = {{The MAGNeT Toolkit: Design, Evaluation, and Implementation}},
journal = {Journal of Supercomputing},
year = {2002},
volume = {23},
number = {1},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/A3364CF9-C26A-45E3-8F41-AA628B384728}}
}

@article{Asanovic:2006vb,
author = {Asanovic, K and Bodik, R and Catanzaro, B C and Gebis, J J and Husbands, P and Keutzer, K and Patterson, D A and Plishker, W L and Shalf, J and Williams, S W},
title = {{The landscape of parallel computing research: A view from berkeley}},
journal = {EECS Department University of California Berkeley Tech Rep UCBEECS2006183},
year = {2006},
volume = {18},
number = {UCB/EECS-2006-183},
publisher = {Citeseer},
read = {Yes},
rating = {0},
date-added = {2012-01-31T01:57:37GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://www.mendeley.com/research/the-landscape-of-parallel-computing-research-a-view-from-berkeley/},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Asanovic/The_landscape_of_parallel_computing_research_A_view_from_berkeley_2006_Asanovic.pdf},
file = {{The_landscape_of_parallel_computing_research_A_view_from_berkeley_2006_Asanovic.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Asanovic/The_landscape_of_parallel_computing_research_A_view_from_berkeley_2006_Asanovic.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5EC5EE0C-2F4F-482C-A309-A1739DD40B2A}}
}

@inproceedings{balaji-ppopp2008-paramedic_poster,
author = {Balaji, Pavan and Feng, Wu{-chun} and Archuleta, Jeremy and Lin, Heshan and Kettimuthu, Rajkumar and Thakur, Rajeev and Ma, Xiaosong},
title = {{Semantics-Based Distributed {I/O} for {mpiBLAST}}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2008},
address = {Salt Lake City, Utah, USA},
month = feb,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T18:23:00GMT},
uri = {\url{papers2://publication/uuid/38AFF232-98BB-482F-9608-FFBADA671E42}}
}

@inproceedings{Ho:2012gv,
author = {Ho, Chen-Han and de Kruijf, M and Sankaralingam, K and Rountree, B and Schulz, M and de Supinski, B R},
title = {{Mechanisms and Evaluation of Cross-Layer Fault-Tolerance for Supercomputing}},
booktitle = {International Conference on Parallel Processing},
year = {2012},
pages = {510--519},
doi = {10.1109/ICPP.2012.37},
rating = {0},
date-added = {2013-04-14T17:47:51GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {Reliability is emerging as an important constraint for future microprocessors. Cooperative hardware and software approaches for error tolerance can solve this hardware reliability challenge. Cross-layer fault tolerance frameworks expose hardware failures to upper-layers, like the compiler, to help correct faults. Such cooperative approaches require less hardware complexity than masking all faults at the hardware level and are generally more energy efficient. This paper provides a detailed design and an implementation study of cross-layer fault tolerance for supercomputing. Since supercomputers necessarily involve large component counts, they have more frequent failures than consumer electronics and small systems. Conventionally, these systems use redundancy and check pointing to achieve reliable computing. However, redundancy increases acquisition as well as recurring energy costs. This paper describes a simple language-level mechanism coupled with complementary compilation and lightweight hardware error detection that provides efficient reliability and cross-layer fault-tolerance for supercomputers. Our evaluation focuses on strong scaling problems for which we can trade computing power for redundancy. Our results show a range of 1.07 to 2.5 speedup when employing cross-layer error-tolerance compared to conventional full dual modular redundancy (DMR) to contain all errors within hardware. Further, we demonstrate the approach can sustain 7\% to 50\% lower energy. The most important result of this work is qualitative: we can use a simplified hardware design with relaxed architectural correctness guarantees. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6337612&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Mechanisms+and+Evaluation+of+Cross-Layer+Fault-Tolerance+for+Supercomputing%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Ho/Mechanisms_and_Evaluation_of_Cross-Layer_Fault-Tolerance_for_Supercomputing_2012_Ho.pdf},
file = {{Mechanisms_and_Evaluation_of_Cross-Layer_Fault-Tolerance_for_Supercomputing_2012_Ho.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Ho/Mechanisms_and_Evaluation_of_Cross-Layer_Fault-Tolerance_for_Supercomputing_2012_Ho.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPP.2012.37}}
}

@inproceedings{gardner-sc2006-adhocgrid,
author = {Gardner, Mark K and Feng, Wu{-chun} and Archuleta, Jeremy S and Lin, Heshan and Ma, Xiaosong},
title = {{Parallel Genomic Sequence-Searching on an Ad-Hoc Grid: Experiences, Lessons Learned, and Implications}},
crossref = {supercomputing},
year = {2006},
month = nov,
annote = {Best Paper Nominee},
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/0EA069DA-48AB-4DCC-8BF4-C1263994CBB5}}
}

@inproceedings{aji-intranode-comm-ashes12,
author = {Ji, Feng and Aji, Ashwin and Dinan, James and Buntinas, Darius and Balaji, Pavan and Feng, Wu{-chun} and Ma, Xiaosong},
title = {{Efficient Intranode Communication in GPU-Accelerated Systems}},
booktitle = {International Workshop on Accelerators and Hybrid Exascale Systems (in conjunction with the 26th IEEE International Parallel and Distributed Processing Symposium)},
year = {2012},
address = {Shanghai, China},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F01CC591-4ED2-4A26-9826-1AF81392E727}}
}

@inproceedings{gardner-icvci-hi-fi-monitoring,
author = {Feng, Wu{-chun} and Vishwanath, Venkatram and Leigh, Jason and Gardner, Mark},
title = {{High-Fidelity Monitoring in Virtual Computing Environments}},
booktitle = {International Conference on the Virtual Computing Initiative (ICVCI)},
year = {2007},
address = {Research Triangle Park, NC},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/C35398D5-58B7-4C0C-8FA8-03D6180AB10D}}
}

@inproceedings{balaji-hpdc08-paramedic,
author = {Balaji, Pavan and Feng, Wu{-chun} and Lin, Heshan},
title = {{Semantic-based Distributed I/O with the ParaMEDIC Framework.}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2008},
address = {Boston, Massachusetts, USA},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:57GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/08C20C8A-A940-4874-8AAA-60D3A78C1E97}}
}

@article{Lin:uh,
author = {Lin, Heshan and Ma, Xiaosong and Feng, Wu{-chun} and Samatova, N F},
title = {{Coordinating Computation and I/O in Massively Parallel Sequence Search}},
journal = {Parallel and Distributed Systems, IEEE Transactions on},
read = {Yes},
rating = {0},
date-added = {2011-03-31T02:40:06GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {With the explosive growth of genomic information, the searching of sequence databases has emerged as one of the most computation and data-intensive scientific applications. Our previous studies suggested that parallel genomic sequence-search possesses highly irregular computation and I/O patterns. Effectively addressing these runtime irregularities is thus the key to designing scalable sequence-search tools on massively parallel computers. While the computation scheduling for irregular scientific applications and the optimization of noncontiguous file accesses have been well-studied independently, little attention has been paid to the interplay between the two. In this paper, we systematically investigate the computation and I/O scheduling for data-intensive, irregular scientific applications within the context of genomic sequence search. Our study reveals that the lack of coordination between computation scheduling and I/O optimization could result in severe performance issues. We then propose an integrated scheduling approach that effectively improves sequence-search throughput by gracefully coordinating the dynamic load balancing of computation and high-performance noncontiguous I/O.
                      
                 
                	
                	
                	
                			
             				
             					
             					Read More},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5473216&queryText%3D%28feng+wuchun%29%26openedRefinements%3D*%26sortType%3Ddesc_Publication+Year%26matchBoolean%3Dtrue%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Lin/Coordinating_Computation_and_IO_in_Massively_Parallel_Sequence_Search__Lin.pdf},
file = {{Coordinating_Computation_and_IO_in_Massively_Parallel_Sequence_Search__Lin.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Lin/Coordinating_Computation_and_IO_in_Massively_Parallel_Sequence_Search__Lin.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E89E15FD-2A3A-4E0B-8938-E7D6EC22A838}}
}

@inproceedings{feng-iscas2010-gpusync,
author = {Feng, Wu{-chun} and Xiao, Shucai},
title = {{To GPU Synchronize or Not GPU Synchronize?}},
booktitle = {IEEE International Symposium on Circuits and Systems (ISCAS)},
year = {2010},
address = {Paris, France},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/DBDD804C-10E2-42DD-9AA3-2F40034F651A}}
}

@article{feng-jgc2003-flowcontrol,
author = {Feng, Wu{-chun} and Gardner, Mark K and Fisk, Michael E and Weigle, Eric},
title = {{Automatic Flow-Control Adaptation for Enhancing Network Performance in Computational Grids}},
journal = {Journal of Grid Gomputing (inaugural issue)},
year = {2003},
volume = {1},
number = {1},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/55686EFB-E313-4C86-BA03-5EE5CC3774E2}}
}

@article{Woo:2008tl,
author = {Woo, D H and Lee, HHS},
title = {{Extending Amdahl's law for energy-efficient computing in the many-core era}},
journal = {IEEE Computer},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2013-09-27T12:49:40GMT},
date-modified = {2014-07-05T20:47:53GMT},
abstract = {Abstract An updated take on Amdahl's analytical model uses modern design constraints to analyze many-core design alternatives. The revised models provide computer architects with a better understanding of many-core design types, enabling them to make more ... 
},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4712496},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Woo/Extending_Amdahl's_law_for_energy-efficient_computing_in_the_many-core_era_2008_Woo.pdf},
file = {{Extending_Amdahl's_law_for_energy-efficient_computing_in_the_many-core_era_2008_Woo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Woo/Extending_Amdahl's_law_for_energy-efficient_computing_in_the_many-core_era_2008_Woo.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/82A1A480-802E-4432-8707-C710D352ED74}}
}

@inproceedings{arisoylu-ccn2008-multihop,
author = {Arisoylu, Mustafa and Feng, Wu{-chun}},
title = {{Achieving Edge-Based Fairness in a Multi-Hop Environment}},
booktitle = {5th IEEE Consumer Communications and Networking Conference},
year = {2008},
pages = {414--419},
address = {Las Vegas, Nevada, USA},
month = jan,
doi = {10.1109/ccnc08.2007.99},
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {We propose efficient buffer-accounting algorithms that achieve edge-based max-min and proportional fairness in a multi-hop (MH), multi-bottleneck network environment by extending and generalizing an existing proactive queue-management scheme called GREEN. We call our scheme GREEN-MH. We envision deploying GREEN-MH at an institutional gateway in the context of a larger multi-hop and multi-bottleneck network environment. GREEN-MH uses a dynamic buffer-accounting algorithm on a per-flow basis such that certain edge-based fairness policies (e.g., max-min and proportional) are enforced among the competing TCP flows.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=4446397&queryText%3D%28achieving+edge+based+fairness+in+a+multi+hop+environment%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Arisoylu/Achieving_Edge-Based_Fairness_in_a_Multi-Hop_Environment_2008_Arisoylu.pdf},
file = {{Achieving_Edge-Based_Fairness_in_a_Multi-Hop_Environment_2008_Arisoylu.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Arisoylu/Achieving_Edge-Based_Fairness_in_a_Multi-Hop_Environment_2008_Arisoylu.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ccnc08.2007.99}}
}

@article{Yao:2009eu,
author = {Yao, Erlin and Bao, Yungang and Tan, Guangming and Chen, Mingyu},
title = {{Extending Amdahl's law in the multicore era}},
journal = {SIGMETRICS Perform. Eval. Rev.},
year = {2009},
volume = {37},
number = {2},
pages = {24--26},
month = oct,
publisher = {ACM},
doi = {10.1145/1639562.1639571},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-09-27T12:49:08GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {The scalability problem is in the first place of the dozen long-term information-technology research goals indicated by Jim Gray [2]. Chip multiprocessors (CMPs) or multicores are emerging as the dominant computing platform. In the multicore era, the scalability problem ... 
},
url = {http://portal.acm.org/citation.cfm?doid=1639562.1639571},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Yao/Extending_Amdahl's_law_in_the_multicore_era_2009_Yao.pdf},
file = {{Extending_Amdahl's_law_in_the_multicore_era_2009_Yao.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Yao/Extending_Amdahl's_law_in_the_multicore_era_2009_Yao.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1639562.1639571}}
}

@techreport{fisk-techreport2000-tcpwindow,
author = {Fisk, Michael E and Feng, Wu{-chun}},
title = {{Dynamic Adjustment of TCP Window Sizes}},
year = {2000},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/42C4F9A5-767E-44B8-A746-B072ACF8E5CD}}
}

@inproceedings{gardner-tacas1999-stochastic,
author = {Gardner, Mark K and Liu, Jane W S},
title = {{Analyzing Stochastic Fixed-Priority Real-Time Systems}},
booktitle = {5th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, Joint European Conferences on Theory and Practice of Software},
year = {1999},
month = mar,
annote = {Also in Lecture Notes in Computer Science, Vol. 1579},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/uuid/AB2A773C-BFF5-460C-B033-B0B9C80F6A85}}
}

@inproceedings{daga-mm-iccabs11,
author = {Daga, Mayank and Feng, Wu{-chun} and Scogland, Thomas R W},
title = {{Towards accelerating molecular modeling via multi-scale approximation on a GPU}},
booktitle = {International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)},
year = {2011},
pages = {75--80},
doi = {10.1109/ICCABS.2011.5729946},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:23:14GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {Research efforts to analyze biomolecular properties contribute towards our understanding of biomolecular function. Calculating non-bonded forces (or in our case, electrostatic surface potential) is often a large portion of the computational complexity in analyzing biomolecular properties. Therefore, reducing the computational complexity of these force calculations, either by improving the computational algorithm or by improving the underlying hardware on which the computational algorithm runs, can help to accelerate the discovery process. Traditional approaches seek to parallelize the electrostatic calculations to run on large-scale supercomputers, which are expensive and highly contended resources. Leveraging our multi-scale approximation algorithm for calculating electrostatic surface potential, we present a novel mapping and optimization of this algorithm on the graphics processing unit (GPU) of a desktop personal computer (PC). Our mapping and optimization of the algorithm results in a speed-up as high as four orders of magnitude, when compared to running serially on the same desktop PC, without deteriorating the accuracy of our results. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5729946&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_DOI%3A10.1109%2FICCABS.2011.5729946%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Daga/Towards_accelerating_molecular_modeling_via_multi-scale_approximation_on_a_GPU_2011_Daga.pdf},
file = {{Towards_accelerating_molecular_modeling_via_multi-scale_approximation_on_a_GPU_2011_Daga.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Daga/Towards_accelerating_molecular_modeling_via_multi-scale_approximation_on_a_GPU_2011_Daga.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICCABS.2011.5729946}}
}

@article{banerjee-tpds2008-lambdagrid,
author = {Banerjee, Amitabha and Feng, Wu{-chun} and Ghosal, Dipak and Mukherjee, Biswanath},
title = {{Algorithms for Integrated Routing and Scheduling for Aggregating Data from Distributed Resources on a Lambda Grid}},
journal = {IEEE Transactions on Parallel and Distributed Systems},
year = {2008},
volume = {19},
number = {1},
month = jan,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B88CBA6D-CC1F-4E84-A241-4AFE2470685C}}
}

@inproceedings{gardner-hpdc2002-drsftp,
author = {Gardner, Mark K and Feng, Wu{-chun} and Fisk, Michael E},
title = {{Dynamic Right-Sizing in FTP (drsFTP): An Automatic Technique for Enhancing Grid Performance}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2002},
address = {Edinburgh, Scotland},
month = jul,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/D3307ABF-848C-47A9-854C-E02CC27775DD}}
}

@article{Zong:2011go,
author = {Zong, Ziliang and Manzanares, A and Ruan, Xiaojun and Qin, Xiao},
title = {{EAD and PEBD: Two Energy-Aware Duplication Scheduling Algorithms for Parallel Tasks on Homogeneous Clusters}},
journal = {Computers, IEEE Transactions on},
year = {2011},
volume = {60},
number = {3},
pages = {360--374},
doi = {10.1109/TC.2010.216},
read = {Yes},
rating = {0},
date-added = {2013-04-15T03:25:22GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {High-performance clusters have been widely deployed to solve challenging and rigorous scientific and engineering tasks. On one hand, high performance is certainly an important consideration in designing clusters to run parallel applications. On the other hand, the ever increasing energy cost requires us to effectively conserve energy in clusters. To achieve the goal of optimizing both performance and energy efficiency in clusters, in this paper, we propose two energy-efficient duplication-based scheduling algorithms-Energy-Aware Duplication (EAD) scheduling and Performance-Energy Balanced Duplication (PEBD) scheduling. Existing duplication-based scheduling algorithms replicate all possible tasks to shorten schedule length without reducing energy consumption caused by duplication. Our algorithms, in contrast, strive to balance schedule lengths and energy savings by judiciously replicating predecessors of a task if the duplication can aid in performance without degrading energy efficiency. To illustrate the effectiveness of EAD and PEBD, we compare them with a nonduplication algorithm, a traditional duplication-based algorithm, and the dynamic voltage scaling (DVS) algorithm. Extensive experimental results using both synthetic benchmarks and real-world applications demonstrate that our algorithms can effectively save energy with marginal performance degradation. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5611491&contentType=Journals+%26+Magazines&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22EAD+and+PEBD%3A+Two+Energy-Aware+Duplication+Scheduling+Algorithms+for+Parallel+Tasks+on+Homogeneous+Clusters%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Zong/EAD_and_PEBD_Two_Energy-Aware_Duplication_Scheduling_Algorithms_for_Parallel_Tasks_on_Homogeneous_Clusters_2011_Zong.pdf},
file = {{EAD_and_PEBD_Two_Energy-Aware_Duplication_Scheduling_Algorithms_for_Parallel_Tasks_on_Homogeneous_Clusters_2011_Zong.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Zong/EAD_and_PEBD_Two_Energy-Aware_Duplication_Scheduling_Algorithms_for_Parallel_Tasks_on_Homogeneous_Clusters_2011_Zong.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/TC.2010.216}}
}

@inproceedings{ayyorgun-icccn2004-qos,
author = {Ayyorgun, Sami and Feng, Wu{-chun}},
title = {{A Systematic Approach for Providing End-to-end Probabilistic QoS Guarantee}},
booktitle = {13th IEEE International Conference on Computer Communications and Networks (ICCCN'04)},
year = {2004},
address = {Chicago, Illinois},
month = oct,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/DE01F86D-50F7-4957-A2B3-0594796DC320}}
}

@inproceedings{Nawaz:2008fv,
author = {Nawaz, Z and Al-Ars, Z and Bertels, K and Shabbir, M},
title = {{Acceleration of Smith-Waterman using Recursive Variable Expansion}},
booktitle = {Digital System Design Architectures, Methods and Tools, 2008. DSD '08. 11th EUROMICRO Conference on},
year = {2008},
pages = {915--922},
publisher = { IEEE Computer Society},
doi = {10.1109/DSD.2008.32},
read = {Yes},
rating = {0},
date-added = {2013-05-02T18:25:31GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {The Smith-Waterman (SW) algorithm is a local sequence alignment algorithm that attempts to align two biological sequences of varying length such that the alignment score is maximum. In this paper, we propose a new approach to reduce the time needed to perform the SW algorithm. This is done by applying the concept of recursive variable expansion, which exposes more parallelism in the algorithm than any other published method. The paper estimates the speed and hardware overhead for the newly proposed approach relative to other known acceleration methods. Using the new approach, it is possible to achieve a minimum speedup of 400 times better than the serial case for a typical sequence length of 500, which is 1.6 times higher than any other published method. The paper also shows that further speedup can be achieved using extra hardware to expose even more parallelism in the algorithm. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4669333&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Acceleration+of+Smith-Waterman+using+Recursive+Variable+Expansion%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Nawaz/Acceleration_of_Smith-Waterman_using_Recursive_Variable_Expansion_2008_Nawaz.pdf},
file = {{Acceleration_of_Smith-Waterman_using_Recursive_Variable_Expansion_2008_Nawaz.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Nawaz/Acceleration_of_Smith-Waterman_using_Recursive_Variable_Expansion_2008_Nawaz.pdf:application/pdf;Acceleration_of_Smith-Waterman_using_Recursive_Variable_Expansion_2008_Nawaz.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Nawaz/Acceleration_of_Smith-Waterman_using_Recursive_Variable_Expansion_2008_Nawaz.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/DSD.2008.32}}
}

@inproceedings{cao-acmcf2010-chip,
author = {Cao, Yong and Patnaik, Debprakash and Ponce, Sean and Archuleta, Jeremy and Butler, Patrick and Feng, Wu{-chun} and Ramakrishnan, Naren},
title = {{Towards Chip-on-Chip Neuroscience: Fast Mining of Neuronal Spike Streams Using Graphics Hardware}},
booktitle = {ACM International Conference on Computing Frontiers},
year = {2010},
address = {Bertinoro, Italy},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/256E3D21-CFE2-4FAA-87BF-7CD3672CE1E0}}
}

@inproceedings{feng-ieeecc2004-greendestiny,
author = {Feng, Wu{-chun} and Hsu, Chung-hsing},
title = {{The Origin and Evolution of Green Destiny}},
booktitle = {IEEE Cool Chips VII: An International Symposium on Low-Power and High-Speed Chips},
year = {2004},
address = {Yokohama, Japan},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/D3938C81-FFAC-4589-BB9A-2E71073E93DC}}
}

@article{Hill:2008wy,
author = {Hill, M D and Marty, M R},
title = {{Amdahl's law in the multicore era}},
journal = {IEEE Computer},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2013-09-27T13:06:21GMT},
date-modified = {2014-07-05T20:47:53GMT},
abstract = {Abstract Augmenting Amdahl's law with a corollary for multicore hardware makes it relevant to future generations of chips with multiple processor cores. Obtaining optimal multicore performance will require further research in both extracting more parallelism and making ... 
},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4563876},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Hill/Amdahl's_law_in_the_multicore_era_2008_Hill.pdf},
file = {{Amdahl's_law_in_the_multicore_era_2008_Hill.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Hill/Amdahl's_law_in_the_multicore_era_2008_Hill.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/CD58D79B-AE33-47CD-A957-43077643CDA7}}
}

@inproceedings{hsu-pldi2003-cpuenergy,
author = {Hsu, Chung-hsing and Kremer, Ulrich},
title = {{The Design, Implementation, and Evaluation of a Compiler Algorithm for CPU Energy Reduction}},
booktitle = {Conference on Programming Language Design and Implementation},
year = {2003},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:37:49GMT},
uri = {\url{papers2://publication/uuid/DE191D16-F4C7-4B4F-96EF-09B346C33362}}
}

@inproceedings{King:2003tz,
author = {King, Samuel T and Dunlap, George W and Chen, Peter M},
title = {{Operating system support for virtual machines}},
booktitle = {Proceedings of the USENIX Annual Technical Conference},
year = {2003},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:15:56GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {A virtual -machine monitor (VMM) is a useful technique for adding functionality below existing operating system and application software. One class of VMMs (called Type II VMMs) builds on the abstractions provided by a host operating system . Type II VMMs are elegant and ...},
url = {http://portal.acm.org/citation.cfm?id=1247346},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/King/Operating_system_support_for_virtual_machines_2003_King.pdf},
file = {{Operating_system_support_for_virtual_machines_2003_King.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/King/Operating_system_support_for_virtual_machines_2003_King.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/45201608-5111-4687-878B-E643FB2FF541}}
}

@inproceedings{ji-hpcc12-dma-assisted,
author = {Ji, Feng and Aji, Ashwin M and Dinan, James and Buntinas, Darius and Balaji, Pavan and Thakur, Rajeev and Feng, Wu{-chun} and Ma, Xiaosong},
title = {{DMA-Assisted, Intranode Communication in GPU Accelerated Systems}},
booktitle = {14th IEEE International Conference on High Performance Computing and Communications},
year = {2012},
address = {Liverpool, UK},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/EC349A74-472F-4F9C-A6DD-659BCFF8C673}}
}

@inproceedings{feng-icpp2000-tcpcongestion,
author = {Feng, Wu{-chun} and Tinnakornsrisuphap, Peerapol},
title = {{The Adverse Impact of the TCP Congestion-Control Mechanism in Heterogeneous Computing Systems}},
booktitle = {29th International Conference on Parallel Processing (ICPP'00)},
year = {2000},
address = {Toronto, Canada},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B856DF69-794D-411F-B51F-3382AB9D3F31}}
}

@article{deCatalunyaDepartamentdArquitecturadeComputadors:2012wz,
author = {de Catalunya Departament d'Arquitectura de Computadors, Universitat Polit{\`e}cnica},
title = {{Task-based Parallel Breadth-First Search in Heterogeneous Environments}},
year = {2012},
pages = {1--10},
month = aug,
rating = {0},
date-added = {2013-05-08T15:52:16GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {<div class="expandable">Breadth-first search (BFS) is an essentialgraph traversal strategy widely used in many computingapplications. Because of its irregular data access patterns,BFS has become a non-trivial problem hard to parallelizeefficiently. In this paper, we introduce a parallelizationstrategy that allows the load balancing of computationresources as well as the execution of graph traversals inhybrid environments composed of CPUs and GPUs. Toachieve that goal, we use a fine-grained task-based parallelizationscheme and the OmpSs programming model. Weobtain processing rates up to 2.8 billion traversed edgesper second with a single GPU and a multi-core processor.Our study shows high processing rates are achievablewith hybrid environments despite the GPU communicationlatency and memory coherence.</div>},
url = {http://www.recercat.net/handle/2072/208442},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/de_Catalunya_Departament_d'Arquitectura_de_Computadors/Task-based_Parallel_Breadth-First_Search_in_Heterogeneous_Environments_2012_de_Catalunya_Departament_d'Arquitectura_de_Computadors.pdf},
file = {{Task-based_Parallel_Breadth-First_Search_in_Heterogeneous_Environments_2012_de_Catalunya_Departament_d'Arquitectura_de_Computadors.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/de_Catalunya_Departament_d'Arquitectura_de_Computadors/Task-based_Parallel_Breadth-First_Search_in_Heterogeneous_Environments_2012_de_Catalunya_Departament_d'Arquitectura_de_Computadors.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/35913120-E351-4368-9FCE-50D18C5D4E55}}
}

@article{Wang:vm,
author = {Wang, Hao and Luo, Miao and Kandalla, Krishna and Sur, Sayantan and Panda, Dhabaleswar K},
title = {{Can Streaming SIMD Non-Temporal Instructions Benefit Intra-node MPI Communication on Modern Multi-core Platforms?}},
rating = {0},
date-added = {2013-05-08T20:49:02GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://www.cse.ohio-state.edu/~luom/cse_web/About_me_files/TR29.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Wang/Can_Streaming_SIMD_Non-Temporal_Instructions_Benefit_Intra-node_MPI_Communication_on_Modern_Multi-core_Platforms__Wang.pdf},
file = {{Can_Streaming_SIMD_Non-Temporal_Instructions_Benefit_Intra-node_MPI_Communication_on_Modern_Multi-core_Platforms__Wang.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Wang/Can_Streaming_SIMD_Non-Temporal_Instructions_Benefit_Intra-node_MPI_Communication_on_Modern_Multi-core_Platforms__Wang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/162FE549-DF8B-440C-BEC3-25C23E1099D1}}
}

@inproceedings{balaji-sc2007-iwarp,
author = {Balaji, Pavan and Feng, Wu{-chun} and Bhagvat, Sitha and Panda, Dhabaleswar and Thakur, Rajeev and Gropp, William},
title = {{Analyzing the Impact of Supporting Out-of-Order Communication on In- Order Performance with iWARP}},
crossref = {supercomputing},
year = {2007},
address = {Reno, Nevada, USA},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/1926977E-0B18-4233-BEE3-7D07032413C0}}
}

@techreport{darling-bosc2005-mpiblast_talk,
author = {Darling, Aaron E},
title = {{mpiBLAST evolves: success, collaborations, and challenges}},
year = {2005},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-03-21T11:56:16GMT},
uri = {\url{papers2://publication/uuid/B107672D-E2DB-4F0C-A342-2E0696B2D56E}}
}

@inproceedings{feng-compsac1999-corba,
author = {Feng, Wu{-chun}},
title = {{Dynamic Client-Side Scheduling in a Real-Time CORBA System}},
booktitle = {23rd International Computer Software {\&} Applications Conference (COMPSAC'99)},
year = {1999},
address = {Phoenix, Arizona},
month = oct,
annote = {[Based on research performed at UIUC]},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B31FA177-AFD5-46C5-9BD0-786780F55F46}}
}

@article{Foster:2001th,
author = {Foster, Ian and Kesselman, Carl and Tuecke, Steven},
title = {{The Anatomy of the Grid - Enabling Scalable Virtual Organizations}},
journal = {arXiv.org},
year = {2001},
eprint = {cs/0103025v1},
eprinttype = {arxiv},
eprintclass = {cs.AR},
month = mar,
annote = {24 pages, 5 figures},
read = {Yes},
rating = {0},
date-added = {2011-04-01T13:11:55GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {"Grid" computing has emerged as an important new field, distinguished from conventional distributed computing by its focus on large-scale resource sharing, innovative applications, and, in some cases, high-performance orientation. In this article, we define this new field. First, we review the "Grid problem," which we define as flexible, secure, coordinated resource sharing among dynamic collections of individuals, institutions, and resources-what we refer to as virtual organizations. In such settings, we encounter unique authentication, authorization, resource access, resource discovery, and other challenges. It is this class of problem that is addressed by Grid technologies. Next, we present an extensible and open Grid architecture, in which protocols, services, application programming interfaces, and software development kits are categorized according to their roles in enabling resource sharing. We describe requirements that we believe any such mechanisms must satisfy, and we discuss the central role played by the intergrid protocols that enable interoperability among different Grid systems. Finally, we discuss how Grid technologies relate to other contemporary technologies, including enterprise integration, application service provider, storage service provider, and peer-to-peer computing. We maintain that Grid concepts and technologies complement and have much to contribute to these other approaches.},
url = {http://citeseer.ist.psu.edu/492895.html},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2001/Foster/The_Anatomy_of_the_Grid_-_Enabling_Scalable_Virtual_Organizations_2001_Foster.pdf},
file = {{The_Anatomy_of_the_Grid_-_Enabling_Scalable_Virtual_Organizations_2001_Foster.pdf:/Users/njustn/Dropbox/Papers2/Articles/2001/Foster/The_Anatomy_of_the_Grid_-_Enabling_Scalable_Virtual_Organizations_2001_Foster.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/27EB84C2-8E33-4570-92FB-8D336787A80E}}
}

@article{Burrows:2006wz,
author = {Burrows, M},
title = {{The Chubby lock service for loosely-coupled distributed systems}},
journal = {{\ldots} of the 7th symposium on Operating systems design {\ldots}},
year = {2006},
read = {Yes},
rating = {0},
date-added = {2011-04-09T01:59:23GMT},
date-modified = {2014-03-21T11:56:15GMT},
abstract = {We describe our experiences with the Chubby lock ser- vice, which is intended to provide coarse-grained lock - ing as well as reliable (though low-volume) storage for a loosely - coupled distributed system. Chubby provides an interface much like a distributed file system with ...},
url = {http://portal.acm.org/citation.cfm?id=1298487},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Burrows/The_Chubby_lock_service_for_loosely-coupled_distributed_systems_2006_Burrows.pdf},
file = {{The_Chubby_lock_service_for_loosely-coupled_distributed_systems_2006_Burrows.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Burrows/The_Chubby_lock_service_for_loosely-coupled_distributed_systems_2006_Burrows.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/59B2FA40-C7CF-4A49-A00E-497DFDE2DBAB}}
}

@inproceedings{Baskaran:2010cd,
author = {Baskaran, Muthu Manikandan and Hartono, Albert and Tavarageri, Sanket and Henretty, Thomas and Ramanujam, J and Sadayappan, P},
title = {{Parameterized tiling revisited}},
booktitle = {CGO '10: Proceedings of the 8th annual IEEE/ACM international symposium on Code generation and optimization},
year = {2010},
publisher = {ACM},
month = apr,
doi = {10.1145/1772954.1772983},
read = {Yes},
rating = {0},
date-added = {2013-09-28T23:02:38GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Tiling, a key transformation for optimizing programs, has been widely studied in literature. Parameterized tiled code is important for auto-tuning systems since they often execute a large number of runs with dynamically varied tile sizes. Previous work},
url = {http://portal.acm.org/citation.cfm?id=1772954.1772983&coll=DL&dl=ACM&CFID=249836282&CFTOKEN=69750083},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Baskaran/Parameterized_tiling_revisited_2010_Baskaran.pdf},
file = {{Parameterized_tiling_revisited_2010_Baskaran.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Baskaran/Parameterized_tiling_revisited_2010_Baskaran.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1772954.1772983}}
}

@techreport{ayyorgun-june2003-deterministic,
author = {Ayyorgun, S and Feng, Wu{-chun}},
title = {{A Deterministic Definition of Burstiness for Network Traffic Characterization}},
year = {2003},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5D936B6A-EBA5-44BB-A0C5-81A7CE2128B7}}
}

@techreport{feng-icpp2003-bioinfomagic_talk,
author = {Feng, Wu{-chun}},
title = {{Green Destiny + mpiBLAST = Bioinfomagic}},
year = {2003},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/1045B1C3-23F1-4818-BB73-5834384B5C10}}
}

@techreport{feng-isc2004-greendestiny_talk,
author = {Feng, Wu{-chun} and Hsu, Chung-hsing},
title = {{Green Destiny and Its Evolving Parts}},
year = {2004},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/BE59FFFD-B39A-422E-A85B-4EA892785DFA}}
}

@article{feng-ctwatch2005-lowpower,
author = {Feng, Wu{-chun}},
title = {{The Importance of Being Low Power in High-Performance Computing}},
journal = {Cyberinfrastructure Technology Watch Quarterly (CTWatch Quarterly)},
year = {2005},
volume = {1},
number = {3},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/32E74541-0A92-4F72-8632-79BDEF758FDC}}
}

@techreport{daga-gputc10-accel,
author = {Daga, Mayank and Feng, Wu{-chun}},
title = {{Accelerating Molecular Modeling using GPUs}},
year = {2010},
address = {San Jose, California},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/FBD249B8-8409-42C3-AEF4-D472F8AF6540}}
}

@inproceedings{banerjee-infocomhsnw2006-optical,
author = {Banerjee, Amitabha and Feng, Wu{-chun} and Mukherjee, Biswanath and Ghosal, Dipak},
title = {{End-system Performance Aware Transport over Optical Circuit-Switched Connections}},
booktitle = {IEEE INFOCOM High-Speed Networking Workshop: The Terabits Challenge (in conjunction with the 25th IEEE INFOCOM)},
year = {2006},
address = {Barcelona, Spain},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/8455821C-D17B-4A68-AE80-7BE0C25AECB0}}
}

@article{Vandierendonck:2013vv,
author = {Vandierendonck, H and Chronaki, K and Nikolopoulos, D.S.},
title = {{Deterministic Scale-Free Pipeline Parallelism with Hyperqueues}},
year = {2013},
read = {Yes},
rating = {0},
date-added = {2013-09-29T00:53:23GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {ABSTRACT Ubiquitous parallel computing aims to make parallel programming accessible to a wide variety of programming areas using deterministic and scale - free programming models built on a task abstraction. However, it remains hard to reconcile these attributes ... 
},
url = {http://www.cs.qub.ac.uk/~H.Vandierendonck/papers/SC13_hyperqueue.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Vandierendonck/Deterministic_Scale-Free_Pipeline_Parallelism_with_Hyperqueues_2013_Vandierendonck.pdf},
file = {{Deterministic_Scale-Free_Pipeline_Parallelism_with_Hyperqueues_2013_Vandierendonck.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Vandierendonck/Deterministic_Scale-Free_Pipeline_Parallelism_with_Hyperqueues_2013_Vandierendonck.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5DAC52D2-A984-4241-BEEC-0B4AC3D9267B}}
}

@article{Hoare:1978ep,
author = {Hoare, C A R},
title = {{Communicating sequential processes}},
journal = {Commun. ACM},
year = {1978},
volume = {21},
number = {8},
pages = {666--677},
month = aug,
doi = {10.1145/359576.359585},
read = {Yes},
rating = {0},
date-added = {2013-10-02T17:12:18GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://portal.acm.org/citation.cfm?doid=359576.359585},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1978/Hoare/Communicating_sequential_processes_1978_Hoare.pdf},
file = {{Communicating_sequential_processes_1978_Hoare.pdf:/Users/njustn/Dropbox/Papers2/Articles/1978/Hoare/Communicating_sequential_processes_1978_Hoare.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/359576.359585}}
}

@article{hurwitz-ieeemicro2004-10gige,
author = {Hurwitz, Justin Gus and Feng, Wu{-chun}},
title = {{End-to-End Performance of 10-Gigabit Ethernet on Commodity Systems}},
journal = {IEEE Micro},
year = {2004},
volume = {24},
number = {1},
pages = {10--22},
month = jan,
doi = {10.1109/MM.2004.1268985},
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {Apart form the success in local-area networks (LANs) and system-area networks and anticipated success in metropolitan and wide area networks (MANs and WANs), Ethernet continues to evolve to meet the increasing demands of packet-switched networks. Although the recently ratified 10-Gigabit Ethernet standard differs from earlier Ethernet standards, primarily in that 10GbE operates only over fiber and only in full-duplex mode, the differences are largely superficial. More importantly, l0GbE does not make obsolete current investments in network infrastructure. The 10GbE standard ensures interoperability not only with existing Ethernet but also with other networking technologies such as Sonet, thus paving the way for Ethernets expanded use in MANs and WANs. The world's first host-based 10GbE adapter, officially known as the Intel PRO/10GbE LR server adapter, introduces the benefits of l0GbE connectivity into LAN and system-area network environments, thereby accommodating the growing number of large-scale cluster systems and bandwidth-intensive applications, such as imaging and data mirroring. The 10GbE controller is optimized for servers that use the I/O bus backplanes of the peripheral component interface (PCI) and its higher speed extension, PCI-X.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=1268985&queryText%3D%28end+to+end+performance+of+10+gigabit+ethernet+on+commodity+systems%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2004/Hurwitz/End-to-End_Performance_of_10-Gigabit_Ethernet_on_Commodity_Systems_2004_Hurwitz.pdf},
file = {{End-to-End_Performance_of_10-Gigabit_Ethernet_on_Commodity_Systems_2004_Hurwitz.pdf:/Users/njustn/Dropbox/Papers2/Articles/2004/Hurwitz/End-to-End_Performance_of_10-Gigabit_Ethernet_on_Commodity_Systems_2004_Hurwitz.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/MM.2004.1268985}}
}

@inproceedings{feng-icpp2002-beowulf,
author = {Feng, Wu{-chun} and Warren, Michael and Weigle, Eric},
title = {{Honey, I Shrunk the Beowulf!}},
booktitle = {International Conference on Parallel Processing},
year = {2002},
address = {Vancouver, Canada},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/ADC479C3-2C68-4168-B40B-DDEC603057F5}}
}

@article{Keckler:kc,
author = {Keckler, Stephen W and Dally, William J and Khailany, Brucek and Garland, Michael and Glasco, David},
title = {{GPUs and the Future of Parallel Computing}},
journal = {IEEE Micro},
volume = {31},
number = {5},
pages = {7--17},
doi = {10.1109/MM.2011.89},
read = {Yes},
rating = {0},
date-added = {2013-10-04T12:40:19GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6045685},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Keckler/GPUs_and_the_Future_of_Parallel_Computing__Keckler.pdf},
file = {{GPUs_and_the_Future_of_Parallel_Computing__Keckler.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Keckler/GPUs_and_the_Future_of_Parallel_Computing__Keckler.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/MM.2011.89}}
}

@article{Nong:2011ta,
author = {Nong, Ge and Sen Zhang and Chan, Wai Hong},
title = {{Two Efficient Algorithms for Linear Time Suffix Array Construction}},
journal = {IEEE Transactions on Computers},
year = {2011},
volume = {60},
number = {10},
month = oct,
publisher = { IEEE Computer Society},
rating = {0},
date-added = {2013-10-09T13:40:33GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {We present, in this paper, two efficient algorithms for linear time suffix array construction. These two algorithms achieve their linear time complexities, using the techniques of divide-and-conquer, and recursion. What distinguish the proposed algorithms},
url = {http://portal.acm.org/citation.cfm?id=2052440.2052506&coll=DL&dl=GUIDE&CFID=252548995&CFTOKEN=69476074},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Nong/Two_Efficient_Algorithms_for_Linear_Time_Suffix_Array_Construction_2011_Nong.pdf},
file = {{Two_Efficient_Algorithms_for_Linear_Time_Suffix_Array_Construction_2011_Nong.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Nong/Two_Efficient_Algorithms_for_Linear_Time_Suffix_Array_Construction_2011_Nong.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/19647580-6F23-482D-9225-F0E0E388EC3F}}
}

@article{feng-elsevier-acce,
author = {Feng, Wu{-chun} and Manocha, Dinesh},
title = {{High-Performance Computing Using Accelerators}},
journal = {Parallel Computing},
year = {2007},
volume = {33},
number = {10-11},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/48C23B27-E3F9-4568-A0A2-74502937B29C}}
}

@inproceedings{balaji-power-meas-green500-greencom10,
author = {Subramaniam, Balaji and Feng, Wu{-chun}},
title = {{Understanding Power Measurement Implications in the Green500 List}},
booktitle = {IEEE/ACM International Conference on Green Computing and Communications (GreenCom)},
year = {2010},
address = {Hangzhou, China},
month = dec,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/4E7D7E43-C40F-491A-92EB-88592D2D85D3}}
}

@techreport{ayyorgun-sep2003-bipartite,
author = {Ayyorgun, Sami and Feng, Wu{-chun}},
title = {{A Restricted Matching Problem on Bipartite Graphs}},
year = {2003},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/087F4E97-85C3-4C88-9414-951D005F719A}}
}

@article{hurwitz-jpdc2005-mpi10gige,
author = {Hurwitz, Justin Gus and Feng, Wu{-chun}},
title = {{Analyzing MPI Performance over 10-Gigabit Ethernet}},
journal = {Journal of Parallel and Distributed Computing, Special Issue: Design and Performance of Networks for Super-, Cluster-, and Grid-Computing},
year = {2005},
volume = {65},
number = {10},
month = oct,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/7D169217-B7D3-4D62-B790-43CB68017811}}
}

@techreport{feng-sc2000-tcp_talk,
author = {Feng, Wu{-chun}},
title = {{Is TCP an Adequate Protocol for High-Performance Computing Needs ?}},
year = {2000},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/EB4D3754-B9BF-4F2E-BDC7-40278A94B0B9}}
}

@inproceedings{Scogland:2011ez,
author = {Scogland, Thomas R W and Subramaniam, Balaji and Feng, Wu{-chun}},
title = {{Emerging Trends on the Evolving Green500: Year Three}},
crossref = {hppac},
year = {2011},
pages = {822--828},
publisher = { IEEE Computer Society},
month = may,
doi = {10.1109/IPDPS.2011.229},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:25:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {It has been traditionally viewed that as the scale of a supercomputer increases, its energy efficiency decreases due to performance that scales sub-linearly and power consumption that scales at least linearly with size. However, based on the first three},
url = {http://portal.acm.org/citation.cfm?id=2058521.2058697&coll=DL&dl=GUIDE&CFID=53314169&CFTOKEN=89814738},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Scogland/Emerging_Trends_on_the_Evolving_Green500_Year_Three_2011_Scogland.pdf},
file = {{Emerging_Trends_on_the_Evolving_Green500_Year_Three_2011_Scogland.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Scogland/Emerging_Trends_on_the_Evolving_Green500_Year_Three_2011_Scogland.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2011.229}}
}

@article{Daga:2011ko,
author = {Daga, Mayank and Aji, Ashwin M},
title = {{On the Efficacy of a Fused CPU+GPU Processor (or APU) for Parallel Computing}},
journal = {Application Accelerators in High-Performance Computing (SAAHPC), 2011 Symposium on},
year = {2011},
pages = {141--149},
doi = {10.1109/SAAHPC.2011.29},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:25:04GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {The graphics processing unit (GPU) has made significant strides as an accelerator in parallel computing. However, because the GPU has resided out on PCIe as a discrete device, the performance of GPU applications can be bottlenecked by data transfers between the CPU and GPU over PCIe. Emerging heterogeneous computing architectures that "fuse" the functionality of the CPU and GPU, e.g., AMD Fusion and Intel Knights Ferry, hold the promise of addressing the PCIe bottleneck. In this paper, we empirically characterize and analyze the efficacy of AMD Fusion, an architecture that combines general-purpose x86 cores and programmable accelerator cores on the same silicon die. We characterize its performance via a set of micro-benchmarks (e.g., PCIe data transfer), kernel benchmarks(e.g., reduction), and actual applications (e.g., molecular dynamics). Depending on the benchmark, our results show that Fusion produces a 1.7 to 6.0-fold improvement in the data-transfer time, when compared to a discrete GPU. In turn, this improvement in data-transfer performance can significantly enhance application performance. For example, running a reduction benchmark on AMD Fusion with its mere 80 GPU cores improves performance by 3.5-fold over the discrete AMD Radeon HD 5870 GPU with its 1600 more powerful GPU cores.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=6031577&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28on+the+efficacy+of+a+fused+cpu+gpu+processor+or+apu+for+parallel+computing%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Daga/On_the_Efficacy_of_a_Fused_CPU+GPU_Processor_(or_APU)_for_Parallel_Computing_2011_Daga.pdf},
file = {{On_the_Efficacy_of_a_Fused_CPU+GPU_Processor_(or_APU)_for_Parallel_Computing_2011_Daga.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Daga/On_the_Efficacy_of_a_Fused_CPU+GPU_Processor_(or_APU)_for_Parallel_Computing_2011_Daga.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SAAHPC.2011.29}}
}

@inproceedings{banerjee-plfdnet2005-lambda,
author = {Banerjee, Amitabha and Feng, Wu{-chun} and Ghosal, Dipak and Mukherjee, Biswanath},
title = {{Routing and Scheduling Large File Transfers over Lambda Grids}},
booktitle = {3rd International Workshop on Protocols for Fast Long-Distance Networks (PFLDnet'05)},
year = {2005},
address = {Lyon, France},
month = feb,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/88043FA2-6654-4D6B-8AF3-7AABE7C2ED64}}
}

@inproceedings{hay-als2001-magnet,
author = {Hay, Jeffrey R and Feng, Wu{-chun} and Gardner, and M K},
title = {{Capturing Network Traffic with a MAGNeT}},
booktitle = {5th Annual Linux Showcase and Conference (ALS'01)},
year = {2001},
address = {Oakland, California},
month = nov,
annote = {SC2001 Pamphlet LA-UR 01-5656: PDF},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F7664E9B-19D6-48B2-9A8E-FFBC2F9C492D}}
}

@techreport{feng-osu1999-niccitizen_talk,
author = {Feng, Wu{-chun} and Minnich, R and Petrini, Fabrizio},
title = {{Network Interface Cards (NICs) as First-Class Citizens.}},
year = {1999},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/D21122FF-B88C-4F90-B957-A37A982433C1}}
}

@article{Gordon:2008ur,
author = {Gordon, JC and Fenley, AT},
title = {{An Analytical Approach To Computing Biomolecular Electrostatic Potential. II. Validation and Applications}},
journal = {The Journal of Chemical Physics},
year = {2008},
keywords = {ipdps11-omp-co},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:36:46GMT},
date-modified = {2014-07-05T20:29:54GMT},
abstract = {An ability to efficiently compute the electrostatic potential produced by molecular charge distributions under realistic solvation conditions is essential for a variety of applications. Here, the simple closed-form analytical approximation to the Poisson equation rigorously derived in Part I ...},
url = {http://link.aip.org/link/?JCPSA6/129/075102/1},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Gordon/An_Analytical_Approach_To_Computing_Biomolecular_Electrostatic_Potential._II._Validation_and_Applications_2008_Gordon.pdf},
file = {{An_Analytical_Approach_To_Computing_Biomolecular_Electrostatic_Potential._II._Validation_and_Applications_2008_Gordon.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Gordon/An_Analytical_Approach_To_Computing_Biomolecular_Electrostatic_Potential._II._Validation_and_Applications_2008_Gordon.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F19AE43D-9E4C-401D-89DC-3268FBE40913}}
}

@article{Fenley:2008hv,
author = {Fenley, Andrew T and Gordon, John C and Onufriev, Alexey},
title = {{An Analytical Approach to Computing Biomolecular Electrostatic Potential. I. Derivation and Analysis}},
journal = {The Journal of Chemical Physics},
year = {2008},
volume = {129},
number = {7},
pages = {075101},
keywords = {ipdps11-omp-co},
doi = {10.1063/1.2956497},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:36:42GMT},
date-modified = {2014-07-05T20:29:54GMT},
abstract = {Analytical approximations to fundamental equations of continuum electrostatics on simple shapes can lead to computationally inexpensive prescriptions for calculating electrostatic properties of realistic molecules. Here, we derive a closed-form analytical approximation to the ...},
url = {http://link.aip.org/link/JCPSA6/v129/i7/p075101/s1&Agg=doi},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Fenley/An_Analytical_Approach_to_Computing_Biomolecular_Electrostatic_Potential._I._Derivation_and_Analysis_2008_Fenley.pdf},
file = {{An_Analytical_Approach_to_Computing_Biomolecular_Electrostatic_Potential._I._Derivation_and_Analysis_2008_Fenley.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Fenley/An_Analytical_Approach_to_Computing_Biomolecular_Electrostatic_Potential._I._Derivation_and_Analysis_2008_Fenley.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1063/1.2956497}}
}

@inproceedings{feng-sc2000-tcpgrid,
author = {Feng, Wu{-chun} and Tinnakornsrisuphap, Peerapol},
title = {{The Failure of TCP in High-Performance Computational Grids}},
crossref = {supercomputing},
year = {2000},
address = {Dallas, Texas},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/9558FF12-D792-493C-8C34-AD05ACD085AB}}
}

@inproceedings{daga-saahpc11-apu-efficacy,
author = {Daga, Mayank and Aji, Ashwin and Feng, Wu{-chun}},
title = {{On the Efficacy of a Fused CPU+GPU Processor for Parallel Computing}},
booktitle = {Symposium on Application Accelerators in High-Performance Computing},
year = {2011},
address = {Knoxville, Tennessee, USA},
month = jul,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/59D9E81F-E2E4-45CE-B279-D443F9DA3935}}
}

@techreport{fisk-sc2001-drs_poster,
author = {Fisk, Michael E and Feng, Wu{-chun}},
title = {{Dynamic Right-Sizing: TCP Flow-Control Adaptation}},
year = {2001},
address = {Denver, Colorado},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/A0DB6711-997F-41B7-8494-FDC90A20E90B}}
}

@article{gardner-comcom2003-flowcontrol,
author = {Gardner, Mark K and Thulasidasan, Sunil and Feng, Wu{-chun}},
title = {{User-Space Auto-Tuning for TCP Flow Control in Computational Grids}},
journal = {Computer Communications, Special Issue on Network Support for Grid Computing,},
year = {2004},
volume = {27},
number = {14},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/C249AD38-9B4A-42CA-8593-6EED54832E4E}}
}

@inproceedings{frachtenberg-srmcc2001-gangscheduling,
author = {Frachtenberg, Eitan and Petrini, Fabrizio and Coll, Salvador and Feng, Wu{-chun}},
title = {{Gang Scheduling with Lightweight User-Level Communication}},
booktitle = {Workshop on Scheduling and Resource Management for Cluster Computing (in conjunction with the ICPP01) (SRMCC 2001)},
year = {2001},
address = {Valencia, Spain},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/45970E4A-EBD4-44A3-B372-A8994E3BA585}}
}

@book{Lee:2012wg,
author = {Lee, Seyong and Vetter, Jeffrey S},
title = {{Early evaluation of directive-based GPU programming models for productive exascale computing}},
publisher = {IEEE Computer Society Press},
year = {2012},
month = nov,
isbn = {978-1-4673-0804-5},
read = {Yes},
rating = {0},
date-added = {2013-10-10T01:49:18GMT},
date-modified = {2014-07-05T18:32:04GMT},
url = {http://dl.acm.org/citation.cfm?id=2388996.2389028},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Books/2012/Lee/Early_evaluation_of_directive-based_GPU_programming_models_for_productive_exascale_computing_2012_Lee.pdf},
file = {{Early_evaluation_of_directive-based_GPU_programming_models_for_productive_exascale_computing_2012_Lee.pdf:/Users/njustn/Dropbox/Papers2/Books/2012/Lee/Early_evaluation_of_directive-based_GPU_programming_models_for_productive_exascale_computing_2012_Lee.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/99BAE9CD-4F9A-4CB0-BE80-5EE5A1D0A900}}
}

@techreport{darling-csb2002-greendestiny_poster,
author = {Darling, Aaron E and Feng, Wu{-chun}},
title = {{BLASTing Off with Green Destiny}},
year = {2002},
address = {Palo Alto, California},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B86D5C56-A552-4F5B-8DAC-3AC2320EB131}}
}

@inproceedings{feng-wmdrtss1997-corba,
author = {Feng, Wu{-chun} and Syyid, Umar and Liu, Jane W S},
title = {{Providing for an Open Real-Time CORBA}},
booktitle = {IEEE Workshop on Middleware for Distributed Real-Time Systems and Services},
year = {1997},
month = dec,
annote = {[Based on research performed at UIUC]},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/A58843B0-AC4C-43B8-BB3E-60E74355267E}}
}

@inproceedings{David:2013fx,
author = {David, Tudor and Guerraoui, Rachid and Trigonakis, Vasileios},
title = {{Everything you always wanted to know about synchronization but were afraid to ask}},
booktitle = {ACM SIGOPS Symposium on Operating Systems Principles},
year = {2013},
publisher = {ACM},
month = nov,
doi = {10.1145/2517349.2522714},
read = {Yes},
rating = {0},
date-added = {2013-10-22T14:42:12GMT},
date-modified = {2014-07-05T18:32:04GMT},
abstract = {This paper presents the most exhaustive study of synchronization to date. We span multiple layers, from hardware cache-coherence protocols up to high-level concurrent software. We do so on different types of architectures, from single-socket -- uniform},
url = {http://portal.acm.org/citation.cfm?id=2517349.2522714&coll=DL&dl=ACM&CFID=255649915&CFTOKEN=70110474},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/David/Everything_you_always_wanted_to_know_about_synchronization_but_were_afraid_to_ask_2013_David.pdf},
file = {{Everything_you_always_wanted_to_know_about_synchronization_but_were_afraid_to_ask_2013_David.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/David/Everything_you_always_wanted_to_know_about_synchronization_but_were_afraid_to_ask_2013_David.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2517349.2522714}}
}

@techreport{100929-datoc-GHC-MyVICE,
author = {Datoc, Michelle and Feng, Wu{-chun}},
title = {{Enhancing Early Childhood Education with Computer Science Curriculum}},
year = {2010},
address = {Atlanta, GA},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/E5708D57-C93A-4E03-BAED-99344EB42122}}
}

@article{Saad:1999uz,
author = {Saad, Yousef and Zhang, Jun},
title = {{BILUTM: a domain-based multilevel block ILUT preconditioner for general sparse matrices}},
journal = {SIAM Journal on Matrix Analysis and Applications},
year = {1999},
volume = {21},
number = {1},
pages = {279--299},
publisher = {SIAM},
read = {Yes},
rating = {0},
date-added = {2013-10-24T19:15:38GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://epubs.siam.org/doi/abs/10.1137/S0895479898341268},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1999/Saad/BILUTM_a_domain-based_multilevel_block_ILUT_preconditioner_for_general_sparse_matrices_1999_Saad.pdf},
file = {{BILUTM_a_domain-based_multilevel_block_ILUT_preconditioner_for_general_sparse_matrices_1999_Saad.pdf:/Users/njustn/Dropbox/Papers2/Articles/1999/Saad/BILUTM_a_domain-based_multilevel_block_ILUT_preconditioner_for_general_sparse_matrices_1999_Saad.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/66082C0E-B09C-4B8C-95D2-ACE20E3D8C0B}}
}

@article{feng-acmqueue2003-efficient,
author = {Feng, Wu{-chun}},
title = {{Making a Case for Efficient Supercomputing}},
journal = {ACM Queue},
year = {2003},
volume = {1},
number = {7},
month = oct,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/D5B7B682-C4D0-41AA-AE74-5AD070DB59EA}}
}

@article{Orozco:2012kr,
author = {Orozco, Daniel and Garcia, Elkin and Khan, Rishi and Livingston, Kelly and Gao, Guang R},
title = {{Toward high-throughput algorithms on many-core architectures}},
journal = {ACM Transactions on Architecture and Code Optimization},
year = {2012},
volume = {8},
number = {4},
pages = {1--21},
month = jan,
doi = {10.1145/2086696.2086728},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-10-29T14:23:16GMT},
date-modified = {2014-04-30T19:46:30GMT},
url = {http://dl.acm.org/citation.cfm?doid=2086696.2086728},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Orozco/Toward_high-throughput_algorithms_on_many-core_architectures_2012_Orozco.pdf},
file = {{Toward_high-throughput_algorithms_on_many-core_architectures_2012_Orozco.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Orozco/Toward_high-throughput_algorithms_on_many-core_architectures_2012_Orozco.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2086696.2086728}}
}

@inproceedings{hsu-sc2005-powerruntime,
author = {Hsu, Chung-hsing and Feng, Wu{-chun}},
title = {{A Power-Aware Run-Time System for High-Performance Computing}},
crossref = {supercomputing},
year = {2005},
pages = {1},
address = {Seattle, Washington},
month = nov,
isbn = {1595930612},
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T20:58:04GMT},
url = {http://dl.acm.org/citation.cfm?id=1105766},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/Hsu/A_Power-Aware_Run-Time_System_for_High-Performance_Computing_2005_Hsu.pdf},
file = {{A_Power-Aware_Run-Time_System_for_High-Performance_Computing_2005_Hsu.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Hsu/A_Power-Aware_Run-Time_System_for_High-Performance_Computing_2005_Hsu.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/D68E5E81-DAFE-4248-87F6-27D21461C240}}
}

@inproceedings{Lof:2005:AIP:1088149.1088201,
author = {L{\"o}f, Henrik and Holmgren, Sverker},
title = {{Affinity-on-next-touch: Increasing the Performance of an Industrial PDE Solver on a cc-NUMA System}},
booktitle = {ACM International Conference on Supercomputing},
year = {2005},
pages = {387--392},
publisher = {ACM},
doi = {10.1145/1088149.1088201},
isbn = {1-59593-167-8},
read = {Yes},
rating = {0},
date-added = {2013-10-30T17:37:57GMT},
date-modified = {2014-07-06T21:44:10GMT},
abstract = {... ICS '05, June 20-22, Boston, MA, USA Copyright 2005 ACM 1 - 59593 - 167 - 8 /06/2005 ...$5.00 ... Led by this observation, we manage to reduce the overhead of the procedure by increasing the page size ... Using Hardware Coun- ters to Automatically Improve Memory Performance . ... 
},
url = {http://doi.acm.org/10.1145/1088149.1088201},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2005/L%C3%B6f/Affinity-on-next-touch_Increasing_the_Performance_of_an_Industrial_PDE_Solver_on_a_cc-NUMA_System_2005_L%C3%B6f.pdf},
file = {{Affinity-on-next-touch_Increasing_the_Performance_of_an_Industrial_PDE_Solver_on_a_cc-NUMA_System_2005_Lf.pdf:/Users/njustn/Dropbox/Papers2/Articles/2005/Lf/Affinity-on-next-touch_Increasing_the_Performance_of_an_Industrial_PDE_Solver_on_a_cc-NUMA_System_2005_Lf.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1088149.1088201}}
}

@inproceedings{elteir-ieeecluster11-atomic-operations,
author = {Elteir, Marwa and Lin, Heshan and Feng, Wu{-chun}},
title = {{Performance Characterization and Optimization of Atomic Operations on AMD GPUs}},
booktitle = {Cluster Computing (CLUSTER), 2011 IEEE International Conference on},
year = {2011},
pages = {234--243},
address = {Austin, TX, USA},
month = sep,
doi = {10.1109/CLUSTER.2011.34},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:32:08GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {Atomic operations are important building blocks in supporting general-purpose computing on graphics processing units (GPUs). For instance, they can be used to coordinate execution between concurrent threads, and in turn, assist in constructing complex data structures such as hash tables or implementing GPU-wide barrier synchronization. While the performance of atomic operations has improved substantially on the latest NVIDIA Fermi-based GPUs, system-provided atomic operations still incur significant performance penalties on AMD GPUs. A memory-bound kernel on an AMD GPU, for example, can suffer severe performance degradation when including an atomic operation, even if the atomic operation is never executed. In this paper, we first quantify the performance impact of atomic instructions to application kernels on AMD GPUs. We then propose a novel software-based implementation of atomic operations that can significantly improve the overall kernel performance. We evaluate its performance against the system-provided atomic using two micro-benchmarks and four real applications. The results show that using our software based atomic operations on an AMD GPU can speedup an application kernel by 67-fold over the same application kernel but with the (default) system-provided atomic operations.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=6061141&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28performance+characterization+and+optimization+of+atomic+operations+on+amd+gpus%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Elteir/Performance_Characterization_and_Optimization_of_Atomic_Operations_on_AMD_GPUs_2011_Elteir.pdf},
file = {{Performance_Characterization_and_Optimization_of_Atomic_Operations_on_AMD_GPUs_2011_Elteir.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Elteir/Performance_Characterization_and_Optimization_of_Atomic_Operations_on_AMD_GPUs_2011_Elteir.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/CLUSTER.2011.34}}
}

@inproceedings{feng-iom2009-nics,
author = {Feng, Wu{-chun} and Balaji, Pavan and Singh, Ajeet},
title = {{Network Interface Cards as First-Class Citizens}},
booktitle = {IEEE Workshop on the Influence of I/O on Microprocessor Architecture},
year = {2009},
address = {Raleigh, NC},
month = feb,
rating = {0},
date-added = {2013-01-16T16:44:58GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/FAA0C0FE-81E6-4F4D-ADBD-20EA6B7A9CAE}}
}

@inproceedings{feng-parco2003-greendestiny,
author = {Feng, Wu{-chun}},
title = {{Green Destiny + mpiBLAST = Bioinfomagic}},
booktitle = {10th International Conference on Parallel Computing (ParCo)},
year = {2003},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/9676840A-6D3D-41C4-86E2-20BC11C85933}}
}

@article{forestgomp,
author = {Broquedis, Fran{\c c}ois and Furmento, Nathalie and Goglin, Brice and Wacrenier, Pierre-Andr{\'e} and Namyst, Raymond},
title = {{ForestGOMP: An Efficient OpenMP Environment for NUMA Architectures}},
journal = {International Journal of Parallel Programming},
year = {2010},
volume = {38},
number = {5-6},
pages = {418--439},
month = may,
doi = {10.1007/s10766-010-0136-3},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-10-30T17:37:57GMT},
date-modified = {2014-04-10T13:48:06GMT},
url = {http://link.springer.com/10.1007/s10766-010-0136-3},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Broquedis/ForestGOMP_An_Efficient_OpenMP_Environment_for_NUMA_Architectures_2010_Broquedis.pdf},
file = {{ForestGOMP_An_Efficient_OpenMP_Environment_for_NUMA_Architectures_2010_Broquedis.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Broquedis/ForestGOMP_An_Efficient_OpenMP_Environment_for_NUMA_Architectures_2010_Broquedis.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/s10766-010-0136-3}}
}

@inproceedings{Broquedis:2009we,
author = {Broquedis, Fran{\c c}ois and Furmento, Nathalie and Goglin, Brice and Namyst, Raymond and Wacrenier, Pierre-Andr{\'e}},
title = {{Dynamic Task and Data Placement Over NUMA Architectures: An OpenMP Runtime Perspective}},
booktitle = {International Workshop on OpenMP: Evolving OpenMP in an Age of Extreme Parallelism},
year = {2009},
publisher = { Springer-Verlag},
month = may,
read = {Yes},
rating = {0},
date-added = {2013-10-30T17:37:57GMT},
date-modified = {2014-07-06T21:47:28GMT},
abstract = {Exploiting the full computational power of current hierarchical multiprocessor machines requires a very careful distribution of threads and data among the underlying non-uniform architecture so as to avoid memory access penalties. Directive-based programming},
url = {http://portal.acm.org/citation.cfm?id=1567707.1567716&coll=DL&dl=GUIDE&CFID=503059456&CFTOKEN=23607131},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Broquedis/Dynamic_Task_and_Data_Placement_Over_NUMA_Architectures_An_OpenMP_Runtime_Perspective_2009_Broquedis.pdf},
file = {{Dynamic_Task_and_Data_Placement_Over_NUMA_Architectures_An_OpenMP_Runtime_Perspective_2009_Broquedis.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Broquedis/Dynamic_Task_and_Data_Placement_Over_NUMA_Architectures_An_OpenMP_Runtime_Perspective_2009_Broquedis.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/FD09DF6F-0CBC-45C8-984F-F0973E4FA509}}
}

@article{feng-ieeetose1997-schedulingrts,
author = {Feng, Wu{-chun} and Liu, Jane W S},
title = {{Algorithms for Scheduling Real-Time Tasks with Input Error and End-to-End Deadlines}},
journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
year = {1997},
volume = {23},
number = {2},
month = feb,
annote = {[Based on research performed at UIUC]},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/BE2EAC7D-F75C-4AC0-825F-F4DBC8ED2F93}}
}

@inproceedings{gardner-erts1999-scheduling,
author = {Gardner, Mark K and Liu, Jane W S},
title = {{Performance of Algorithms for Scheduling Real-Time Systems with Overrun and Overload}},
booktitle = {11th Euromicro Conference on Real-Time Systems. (ERTS)},
year = {1999},
address = {York, England},
month = jun,
annote = {[Based on research performed at UIUC]},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/FEF70DBF-B21C-422F-BAAA-886EE16DCA27}}
}

@article{Bull:2002vk,
author = {Bull, J Mark and Johnson, Chris},
title = {{Data distribution, migration and replication on a cc-NUMA architecture}},
year = {2002},
read = {Yes},
rating = {0},
date-added = {2013-10-30T17:37:57GMT},
date-modified = {2014-04-10T14:46:10GMT},
url = {http://www.compunity.org/events/pastevents/ewomp2002/EWOMP02-13-1_bull_papers.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2002/Bull/Data_distribution_migration_and_replication_on_a_cc-NUMA_architecture_2002_Bull.pdf},
file = {{Data_distribution_migration_and_replication_on_a_cc-NUMA_architecture_2002_Bull.pdf:/Users/njustn/Dropbox/Papers2/Articles/2002/Bull/Data_distribution_migration_and_replication_on_a_cc-NUMA_architecture_2002_Bull.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A7C3E69C-3EBF-4E2A-BF9A-BE5D0559512A}}
}

@inproceedings{Rafique:2009di,
author = {Rafique, M Mustafa and Rose, Benjamin and Butt, Ali R and Nikolopoulos, Dimitrios S.},
title = {{CellMR: A Framework for Supporting MapReduce on Asymmetric Cell-Based Clusters}},
crossref = {ipdps},
year = {2009},
pages = {1--12},
publisher = { IEEE Computer Society},
month = may,
keywords = {ipdps11-omp-co},
doi = {10.1109/IPDPS.2009.5161062},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:40:00GMT},
date-modified = {2014-07-05T21:03:54GMT},
abstract = {The use of asymmetric multi-core processors with on-chip computational accelerators is becoming common in a variety of environments ranging from scientific computing to enterprise applications. The focus of current research has been on making efficient},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5161062},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Rafique/CellMR_A_Framework_for_Supporting_MapReduce_on_Asymmetric_Cell-Based_Clusters_2009_Rafique-1.pdf},
file = {{CellMR_A_Framework_for_Supporting_MapReduce_on_Asymmetric_Cell-Based_Clusters_2009_Rafique-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Rafique/CellMR_A_Framework_for_Supporting_MapReduce_on_Asymmetric_Cell-Based_Clusters_2009_Rafique-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5161062}}
}

@inproceedings{feng-cncs1998-corba,
author = {Feng, Wu{-chun}},
title = {{Extending CORBA for Soft Real-Time Applications}},
booktitle = {International Conference on Networks {\&} Communication Systems},
year = {1998},
month = may,
annote = {[Based on research performed at UIUC] (electronic version unavailable)},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/ADCC8A79-03A2-4503-9945-C320301BACD2}}
}

@techreport{ayyorgun-sep2003-serviceguarantees,
author = {Ayyorgun, Sami and Feng, Wu{-chun}},
title = {{A Systematic Approach to Probablistic Quality of Service Guarantees in Communication Networks}},
year = {2003},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/D04F520F-262D-417E-9C9B-4E44821495A5}}
}

@inproceedings{balaji-stat-opt-greencom10,
author = {Subramaniam, Balaji and Feng, Wu{-chun}},
title = {{Statistical Power and Performance Modeling for Optimizing the Energy Efficiency of Scientific Computing}},
booktitle = {IEEE/ACM International Conference on Green Computing and Communications (GreenCom)},
year = {2010},
address = {Hangzhou, China},
month = dec,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5DF7A434-E446-453D-89B2-3ED39F2BC1A3}}
}

@article{balaji-cc10-global-io-paramedic,
author = {Balaji, Pavan and Feng, Wu{-chun} and Lin, Heshan and Archuleta, Jeremy and Matsuoka, S and Warren, A and Setubal, J and Lusk, E and Thakur, R and Foster, Ian and Katz, D and Jha, S and Shinpaugh, K and Coghlan, S and Reed, D},
title = {{Global-Scale Distributed I/O with ParaMEDIC}},
journal = {Concurrency and Computation: Practice and Experience},
year = {2010},
volume = {22},
number = {16},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/53CCD6FF-FCD2-46FB-A1A4-13035E58C490}}
}

@inproceedings{Yilmazer:uk,
author = {Yilmazer, Ayse and Kaeli, David},
title = {{HQL: A Scalable Synchronization Mechanism for GPUs}},
crossref = {ipdps},
address = {Boston},
rating = {0},
date-added = {2013-05-26T21:11:13GMT},
date-modified = {2014-07-05T17:43:45GMT},
url = {http://www.ece.neu.edu/~yilmazer/papers/hql.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Yilmazer/HQL_A_Scalable_Synchronization_Mechanism_for_GPUs__Yilmazer.pdf},
file = {{HQL_A_Scalable_Synchronization_Mechanism_for_GPUs__Yilmazer.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Yilmazer/HQL_A_Scalable_Synchronization_Mechanism_for_GPUs__Yilmazer.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/3F1EE1AA-402E-470C-8E7B-F064DDD1F751}}
}

@techreport{feng-elililly2002-greendestiny_talk,
author = {Feng, Wu{-chun}},
title = {{Green Destiny: A 240-Node Compute Cluster in One Cubic Meter}},
year = {2002},
month = sep,
annote = {NCSA at the University of Illinois at Urbana-Champaign with a broadcast over the Access Grid, October 2002, Rocky Mountain Institute Data Charrette, February 2003},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/FD806B33-98FE-4734-890E-3D5031E39B1B}}
}

@inproceedings{gardner-pam2002-magnet,
author = {Gardner, Mark K and Feng, Wu{-chun} and Hay, Jeffrey R},
title = {{Monitoring Protocol Traffic with a MAGNeT}},
booktitle = {Passive {\&} Active Measurement Workshop (PAM2002)},
year = {2002},
address = {Fort Collins, Colorado},
month = mar,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/6292EED5-FD36-4282-9A8B-8FD2D7FC02A3}}
}

@inproceedings{aji-hpcc12-mpiacc,
author = {Aji, Ashwin M and Dinan, James and Buntinas, Darius and Balaji, Pavan and Feng, Wu{-chun} and Bisset, Keith R and Thakur, Rajeev},
title = {{MPI-ACC: An Integrated and Extensible Approach to Data Movement in Accelerator-Based Systems}},
booktitle = {14th IEEE International Conference on High Performance Computing and Communications},
year = {2012},
address = {Liverpool, UK},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/355574D9-7362-4998-B77F-F0AD0B6EE687}}
}

@inproceedings{Wernsing:2010in,
author = {Wernsing, John Robert and Stitt, Greg},
title = {{Elastic computing: a framework for transparent, portable, and adaptive multi-core heterogeneous computing}},
booktitle = {LCTES '10: Proceedings of the ACM SIGPLAN/SIGBED 2010 conference on Languages, compilers, and tools for embedded systems},
year = {2010},
publisher = {ACM},
month = apr,
doi = {10.1145/1755888.1755906},
read = {Yes},
rating = {0},
date-added = {2013-06-10T13:07:15GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Over the past decade, system architectures have started on a clear trend towards increased parallelism and heterogeneity, often resulting in speedups of 10x to 100x. Despite numerous compiler and high-level synthesis studies, usage of such systems has},
url = {http://portal.acm.org/citation.cfm?id=1755888.1755906&coll=DL&dl=GUIDE&CFID=224628195&CFTOKEN=90755316},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Wernsing/Elastic_computing_a_framework_for_transparent_portable_and_adaptive_multi-core_heterogeneous_computing_2010_Wernsing.pdf},
file = {{Elastic_computing_a_framework_for_transparent_portable_and_adaptive_multi-core_heterogeneous_computing_2010_Wernsing.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Wernsing/Elastic_computing_a_framework_for_transparent_portable_and_adaptive_multi-core_heterogeneous_computing_2010_Wernsing.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1755888.1755906}}
}

@article{Waldspurger:2002vl,
author = {Waldspurger, CA},
title = {{Memory resource management in VMware ESX server}},
journal = {ACM SIGOPS Operating Systems Review},
year = {2002},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:16:47GMT},
date-modified = {2014-07-05T18:30:16GMT},
abstract = {VMware ESX Server is a thin software layer designed to multiplex hardware resources efficiently among virtual ma- chines running unmodified commodity operating systems. This paper introduces several novel ESX Server mechanisms and policies for managing memory . A ballooning ...},
url = {http://portal.acm.org/citation.cfm?id=844146},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2002/Waldspurger/Memory_resource_management_in_VMware_ESX_server_2002_Waldspurger.pdf},
file = {{Memory_resource_management_in_VMware_ESX_server_2002_Waldspurger.pdf:/Users/njustn/Dropbox/Papers2/Articles/2002/Waldspurger/Memory_resource_management_in_VMware_ESX_server_2002_Waldspurger.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DD345C90-BA6A-4B94-908E-A6EF70715C92}}
}

@inproceedings{hsu-lci2005-overheating,
author = {Hsu, Chung-hsing and Feng, Wu{-chun}},
title = {{Reducing Overheating-Induced Failures via Performance-Aware CPU Power Management}},
booktitle = {6th International Conference on Linux Clusters: The HPC Revolution 2005},
year = {2005},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/E7C4DBF8-449C-408C-8EB9-CFECD8F344EA}}
}

@inproceedings{feng03:optimizing_10gige,
author = {Feng, Wu{-chun} and Hurwitz, Justin Gus and Newman, Harvey and Ravot, Sylvain and Cottrell, Les R and Martin, Olivier and Coccetti, Fabrizio and Jin, Cheng and Wei, David and Low, Steven H},
title = {{Optimizing 10-Gigabit Ethernet for Networks of Workstations, Clusters and Grids: A Case Study}},
crossref = {supercomputing},
year = {2003},
address = {Phoenix, Arizona},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T20:58:04GMT},
uri = {\url{papers2://publication/uuid/06195E6C-53A0-4B77-81D5-78824E78061B}}
}

@inproceedings{dolbeau2007hmpp,
author = {Dolbeau, R and Bihan, S and Bodin, F},
title = {{HMPP: A Hybrid Multi-Core Parallel Programming Environment}},
booktitle = {GPGPU 2007: Workshop on General Purpose Processing on Graphics Processing Units},
year = {2007},
rating = {0},
date-added = {2014-07-03T15:31:11GMT},
date-modified = {2014-07-05T19:32:06GMT},
uri = {\url{papers2://publication/uuid/12C3C88D-87C7-4B8C-8D4A-EEF79D69BA00}}
}

@inproceedings{balaji-cluster2005-toe,
author = {Balaji, Pavan and Feng, Wu{-chun} and Gao, Qi and Noronha, Ranjit and Yu, Weikuan and Panda, Dhabaleswar K},
title = {{Head-to-TOE Evaluation of High-Performance Sockets over Protocol Offload Engines}},
booktitle = {7th IEEE International Conference on Cluster Computing (CLUSTER'05)},
year = {2005},
address = {Boston, Massachusetts},
month = sep,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B04CC25F-F169-4339-A383-AD11D769E100}}
}

@inproceedings{Fabeiro:2013hk,
author = {Fabeiro, Jorge F and Andrade, Diego and Fraguela, Basilio B},
title = {{OCLoptimizer: An Iterative Optimization Tool for OpenCL}},
booktitle = {Proceedings of the International Conference on Computational Science, ICCS 2013},
year = {2013},
pages = {1322--1331},
month = jan,
doi = {10.1016/j.procs.2013.05.299},
language = {English},
rating = {0},
date-added = {2013-06-12T15:57:39GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050913004420},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Fabeiro/OCLoptimizer_An_Iterative_Optimization_Tool_for_OpenCL_2013_Fabeiro.pdf},
file = {{OCLoptimizer_An_Iterative_Optimization_Tool_for_OpenCL_2013_Fabeiro.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Fabeiro/OCLoptimizer_An_Iterative_Optimization_Tool_for_OpenCL_2013_Fabeiro.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.procs.2013.05.299}}
}

@inproceedings{aji-part-camp-cf11,
author = {Aji, Ashwin M and Daga, Mayank and Feng, Wu{-chun}},
title = {{Bounding the Effect of Partition Camping in GPU Kernels}},
booktitle = {ACM International Conference on Computing Frontiers},
year = {2011},
address = {Ischia, Italy},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F7510345-3B61-43A0-9096-349EFABAABD0}}
}

@article{Krohn:2007te,
author = {Krohn, M and Kohler, E},
title = {{Events can make sense}},
journal = {2007 USENIX Annual Technical {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:00:14GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Tame is a new event-based system for managing concurrency in network applications. Code written with Tame abstractions does not suffer from the "stack-ripping" problem associated with other event libraries. Like threaded code, tamed code uses standard control flow, ...},
url = {http://portal.acm.org/citation.cfm?id=1364392},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Krohn/Events_can_make_sense_2007_Krohn.pdf},
file = {{Events_can_make_sense_2007_Krohn.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Krohn/Events_can_make_sense_2007_Krohn.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/0D648E94-8DC8-4D26-B5D1-84DFDB6EBC82}}
}

@inproceedings{feng-icccn2001-magnet,
author = {Feng, Wu{-chun} and Hay, Jeffrey R and Gardner, Mark K},
title = {{MAGNeT: Monitor for Application-Generated Network Traffic}},
booktitle = {10th International Conference on Computer Communication and Networking (ICCCN'01)},
year = {2001},
address = {Scottsdale, Arizona},
month = oct,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/E6087909-3440-4379-8EE5-76DD83A214DC}}
}

@misc{Reinders:2007uq,
title = {{Intel Threading Building Blocks}},
howpublished = {https://www.threadingbuildingblocks.org/},
year = {2007},
publisher = {https://www.threadingbuildingblocks.org/},
keywords = {ipdps11-omp-co},
read = {Yes},
rating = {0},
date-added = {2011-11-13T01:05:25GMT},
date-modified = {2014-07-05T21:17:13GMT},
url = {https://www.threadingbuildingblocks.org/},
uri = {\url{papers2://publication/uuid/6146C9B2-8DC8-428E-871C-01D55D143B13}}
}

@inproceedings{Mallon:2012er,
author = {Mallon, Damian Alvarez and Eicker, Norbert and Innocenti, Maria Elena and Lapenta, Giovanni and Lippert, Thomas and Suarez, Estela},
title = {{On the scalability of the clusters-booster concept}},
booktitle = {the Future HPC Systems},
year = {2012},
pages = {1--10},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/2322156.2322159},
isbn = {9781450314534},
rating = {0},
date-added = {2013-06-20T08:49:07GMT},
date-modified = {2014-03-21T11:56:14GMT},
url = {http://dl.acm.org/citation.cfm?doid=2322156.2322159},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Mallon/On_the_scalability_of_the_clusters-booster_concept_2012_Mallon-2.pdf},
file = {{On_the_scalability_of_the_clusters-booster_concept_2012_Mallon-2.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Mallon/On_the_scalability_of_the_clusters-booster_concept_2012_Mallon-2.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2322156.2322159}}
}

@article{Anonymous:wX8k418T,
author = {Ramos, Sabela and Hoefler, Torsten},
title = {{Modeling communication in cache-coherent SMP systems: a case-study with Xeon Phi}},
journal = {htor.inf.ethz.ch},
year = {2013},
pages = {97--108},
publisher = {ACM},
isbn = {1450319106},
read = {Yes},
rating = {0},
date-added = {2013-06-27T00:27:29GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://dl.acm.org/citation.cfm?id=2462916},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Ramos/Modeling_communication_in_cache-coherent_SMP_systems_a_case-study_with_Xeon_Phi_2013_Ramos.pdf},
file = {{Modeling_communication_in_cache-coherent_SMP_systems_a_case-study_with_Xeon_Phi_2013_Ramos.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Ramos/Modeling_communication_in_cache-coherent_SMP_systems_a_case-study_with_Xeon_Phi_2013_Ramos.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C17F24E3-5F13-4885-B2CF-5E5909EFE0B8}}
}

@inproceedings{Hong:2010kj,
author = {Hong, Chuntao and Chen, Dehao and Chen, Wenguang and Zheng, Weimin and Lin, Haibo},
title = {{MapCG: Writing Parallel Program Portable Between CPU and GPU}},
booktitle = {International Conference on Parallel Architectures and Compilation Techniques},
year = {2010},
publisher = {ACM},
month = sep,
doi = {10.1145/1854273.1854303},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:40:05GMT},
date-modified = {2014-07-05T20:33:17GMT},
abstract = {Graphics Processing Units (GPU) have been playing an important role in the general purpose computing market recently. The common approach to program GPU today is to write GPU specific code with low level GPU APIs such as CUDA. Although this approach},
url = {http://portal.acm.org/citation.cfm?id=1854273.1854303&coll=DL&dl=GUIDE&CFID=53310305&CFTOKEN=40547501},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Hong/MapCG_Writing_Parallel_Program_Portable_Between_CPU_and_GPU_2010_Hong-1.pdf},
file = {{MapCG_Writing_Parallel_Program_Portable_Between_CPU_and_GPU_2010_Hong-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Hong/MapCG_Writing_Parallel_Program_Portable_Between_CPU_and_GPU_2010_Hong-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1854273.1854303}}
}

@article{balaji-ieeemicro2006-ethernot,
author = {Balaji, Pavan and Feng, Wu{-chun} and Panda, Dhabaleswar K},
title = {{Bridging the Ethernet-Ethernot Performance Gap}},
journal = {IEEE Micro (Special Issue: High-Performance Interconnects)},
year = {2006},
volume = {26},
number = {3},
pages = {24--40},
month = may,
doi = {10.1109/MM.2006.48},
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {In the past decade, a wide array of interconnect technologies have entered the sys- tem-area network (SAN) environment--- notably InfiniBand (http://www.infinibandta. org), Myrinet,1 and QsNet.2 The success of these networks, dubbed Ethernots, depends primarily on their ...},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1650178},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Balaji/Bridging_the_Ethernet-Ethernot_Performance_Gap_2006_Balaji.pdf},
file = {{Bridging_the_Ethernet-Ethernot_Performance_Gap_2006_Balaji.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Balaji/Bridging_the_Ethernet-Ethernot_Performance_Gap_2006_Balaji.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/MM.2006.48}}
}

@techreport{ayyorgun-may2003-burstiness,
author = {Ayyorgun, S and Feng, Wu{-chun}},
title = {{A Probabilistic Definition of Burstiness Characterization}},
year = {2003},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/067CC0B7-9DF4-41C2-83A4-EAEE54F6AC27}}
}

@inproceedings{deOSandes:2011ji,
author = {de O Sandes, E.F and de Melo, A.C.M.A},
title = {{Smith-Waterman Alignment of Huge Sequences with GPU in Linear Space}},
crossref = {ipdps},
year = {2011},
pages = {1199--1211},
doi = {10.1109/IPDPS.2011.114},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:34:24GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {Cross-species chromosome alignments can reveal ancestral relationships and may be used to identify the peculiarities of the species. It is thus an important problem in Bioinformatics. So far, aligning huge sequences, such as whole chromosomes, with exact methods has been regarded as unfeasible, due to huge computing and memory requirements. However, high performance computing platforms such as GPUs are being able to change this scenario, making it possible to obtain the exact result for huge sequences in reasonable time. In this paper, we propose and evaluate a parallel algorithm that uses GPU to align huge sequences, executing the Smith-Waterman algorithm combined with Myers-Miller, with linear space complexity. In order to achieve that, we propose optimizations that are able to reduce significantly the amount of data processed and that enforce full parallelism most of the time. Using the GTX 285 Board, our algorithm was able to produce the optimal alignment between sequences composed of 33 Millions of Base Pairs (MBP) and 47 MBP in 18.5 hours.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=6012857&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28smith+waterman+alignment+linear+space+gpu%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/de_O_Sandes/Smith-Waterman_Alignment_of_Huge_Sequences_with_GPU_in_Linear_Space_2011_de_O_Sandes.pdf},
file = {{Smith-Waterman_Alignment_of_Huge_Sequences_with_GPU_in_Linear_Space_2011_de_O_Sandes.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/de_O_Sandes/Smith-Waterman_Alignment_of_Huge_Sequences_with_GPU_in_Linear_Space_2011_de_O_Sandes.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2011.114}}
}

@article{Anonymous:YSn-brKr,
title = {{Fast Hybrid Prediction of Heterogeneous Kernel Execution Times Using Historical Data}},
year = {2012},
pages = {1--10},
month = feb,
rating = {0},
date-added = {2012-02-06T15:47:57GMT},
date-modified = {2014-04-06T17:23:40GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Fast_Hybrid_Prediction_of_Heterogeneous_Kernel_Execution_Times_Using_Historical_Data_2012.pdf},
file = {{Fast_Hybrid_Prediction_of_Heterogeneous_Kernel_Execution_Times_Using_Historical_Data_2012.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Fast_Hybrid_Prediction_of_Heterogeneous_Kernel_Execution_Times_Using_Historical_Data_2012.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6129FE6E-B2AB-4A8E-8C9F-B2DD04E220E5}}
}

@article{Hirschberg:1975ce,
author = {Hirschberg, D. S.},
title = {{A linear space algorithm for computing maximal common subsequences}},
journal = {Commun. ACM},
year = {1975},
volume = {18},
number = {6},
pages = {341--343},
month = jun,
publisher = {ACM},
doi = {10.1145/360825.360861},
read = {Yes},
rating = {0},
date-added = {2012-02-06T15:48:00GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://portal.acm.org/citation.cfm?doid=360825.360861},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1975/Hirschberg/A_linear_space_algorithm_for_computing_maximal_common_subsequences_1975_Hirschberg.pdf},
file = {{A_linear_space_algorithm_for_computing_maximal_common_subsequences_1975_Hirschberg.pdf:/Users/njustn/Dropbox/Papers2/Articles/1975/Hirschberg/A_linear_space_algorithm_for_computing_maximal_common_subsequences_1975_Hirschberg.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/360825.360861}}
}

@article{Anonymous:pmFX8_xY,
title = {{Optimization of the parallel black-box fast multipole method on CUDA}},
year = {2012},
pages = {1--13},
month = feb,
rating = {0},
date-added = {2012-02-06T15:48:07GMT},
date-modified = {2014-03-21T11:56:19GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Optimization_of_the_parallel_black-box_fast_multipole_method_on_CUDA_2012.pdf},
file = {{Optimization_of_the_parallel_black-box_fast_multipole_method_on_CUDA_2012.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Optimization_of_the_parallel_black-box_fast_multipole_method_on_CUDA_2012.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A66157F3-FC58-4AEC-8EAA-A75E08893667}}
}

@article{Anonymous:ob8SbQtp,
title = {{GPU-Accelerated Monte Carlo Simulations of Dense Stellar Systems}},
year = {2012},
pages = {1--10},
month = feb,
rating = {0},
date-added = {2012-02-06T15:48:11GMT},
date-modified = {2014-03-21T11:56:18GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/GPU-Accelerated_Monte_Carlo_Simulations_of_Dense_Stellar_Systems_2012.pdf},
file = {{GPU-Accelerated_Monte_Carlo_Simulations_of_Dense_Stellar_Systems_2012.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/GPU-Accelerated_Monte_Carlo_Simulations_of_Dense_Stellar_Systems_2012.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A1BF126D-0B69-45E9-A2A4-238C6C955118}}
}

@article{Anonymous:BZ-goJLL,
author = {Gupta, K and Stuart, J.A and Owens, J D},
title = {{A study of Persistent Threads style GPU programming for GPGPU workloads}},
journal = {Innovative Parallel Computing},
year = {2012},
pages = {1--14},
doi = {10.1109/InPar.2012.6339596},
read = {Yes},
rating = {0},
date-added = {2012-02-06T15:48:15GMT},
date-modified = {2014-07-05T20:31:26GMT},
abstract = {In this paper, we characterize and analyze an increasingly popular style of programming for the GPU called Persistent Threads (PT). We present a concise formal definition for this programming style, and discuss the difference between the traditional GPU programming style (nonPT) and PT, why PT is attractive for some high-performance usage scenarios, and when using PT may or may not be appropriate. We identify limitations of the nonPT style and identify four primary use cases it could be useful in addressing-CPU-GPU synchronization, load balancing/irregular parallelism, producer-consumer locality, and global synchronization. Through micro-kernel benchmarks we show the PT approach can achieve up to an order-of-magnitude speedup over nonPT kernels, but can also result in performance loss in many cases. We conclude by discussing the hardware and software fundamentals that will influence the development of Persistent Threads as a programming style in future systems. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6339596&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Title%3A%22A+Study+of+Persistent+Threads+Style+GPU+Programming+for+GPGPU+Workloads%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Gupta/A_study_of_Persistent_Threads_style_GPU_programming_for_GPGPU_workloads_2012_Gupta.pdf},
file = {{A_study_of_Persistent_Threads_style_GPU_programming_for_GPGPU_workloads_2012_Gupta.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Gupta/A_study_of_Persistent_Threads_style_GPU_programming_for_GPGPU_workloads_2012_Gupta.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/InPar.2012.6339596}}
}

@article{Anonymous:0iwLggT4,
title = {{Efficient Parallel Merge Sort for Fixed and Variable Length Keys}},
year = {2011},
pages = {1--8},
month = dec,
read = {Yes},
rating = {0},
date-added = {2012-02-06T18:29:03GMT},
date-modified = {2014-03-21T11:56:20GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Unknown/Efficient_Parallel_Merge_Sort_for_Fixed_and_Variable_Length_Keys_2011.pdf},
file = {{Efficient_Parallel_Merge_Sort_for_Fixed_and_Variable_Length_Keys_2011.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Unknown/Efficient_Parallel_Merge_Sort_for_Fixed_and_Variable_Length_Keys_2011.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/D22C0B82-04F8-4127-A5A6-BE1DD738548E}}
}

@article{Zhang:2011wy,
author = {Zhang, Y and Owens, J D},
title = {{A quantitative performance analysis model for GPU architectures}},
journal = {High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on},
year = {2011},
pages = {382--393},
publisher = {IEEE},
isbn = {142449432X},
read = {Yes},
rating = {0},
date-added = {2012-02-07T19:04:51GMT},
date-modified = {2014-03-21T11:56:19GMT},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5749745},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Zhang/A_quantitative_performance_analysis_model_for_GPU_architectures_2011_Zhang.pdf},
file = {{A_quantitative_performance_analysis_model_for_GPU_architectures_2011_Zhang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Zhang/A_quantitative_performance_analysis_model_for_GPU_architectures_2011_Zhang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E368106E-3A3C-4D7B-9D17-FCEDE0243EA1}}
}

@inproceedings{gardner-ipdps2003-muse,
author = {Gardner, Mark K and Broxton, Michael and Engelhart, Adam and Feng, Wu{-chun}},
title = {{MUSE: A Software Oscilloscope for Clusters and Grids}},
crossref = {ipdps},
year = {2003},
address = {Nice, France},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/0611188D-C004-4A88-9BAA-4325B0C3A449}}
}

@article{feng-itpro-green,
author = {Feng, Wu{-chun} and Feng, Xizhou and Ge, Rong},
title = {{Green Supercomputing Comes of Age}},
journal = {IT Professional},
year = {2008},
volume = {10},
number = {1},
month = jan,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F3B025AB-B2D9-403B-B57E-317D508ECBC5}}
}

@inproceedings{ayyorgun-ciss2004-charecterization,
author = {Ayyorgun, Sami and Feng, Wu{-chun}},
title = {{A Deterministic Characterization of Network Traffic for Average Performance Guarantee}},
booktitle = {38th Annual Conference on Information Sciences and Systems (CISS'04)},
year = {2004},
address = {Princeton, New Jersey},
month = mar,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/3B8ACC40-7A2A-40F4-BD5A-DD4A3C221020}}
}

@inproceedings{brown-iticse10-cs-education-multicore,
author = {Brown, Richard and Shoop, Elizabeth and Adams, Joel and Clifton, Curtis and Gardner, Mark and Haupt, Michael and Hinsbeeck, Peter},
title = {{Strategies for Preparing Computer Science Students for the Multicore World}},
booktitle = {ITiCSE Proceedings of the 15th Annual Conference on Innovation and Technology in Computer Science Education},
year = {2010},
address = {Bilkent, Ankara, Turkey},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/7F10F8CB-4ABB-4F54-9E74-0E91A1F6974F}}
}

@inproceedings{gardner-iticse2010-k12,
author = {Gardner, Mark K and Feng, Wu{-chun}},
title = {{Broadening Accessibility to Computer Science for K-12 Education}},
booktitle = {ITiCSE Proceedings of the 15th Annual Conference on Innovation and Technology in Computer Science Education},
year = {2010},
address = {Ankara, Turkey},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/0FCAD98B-9B73-4F7D-A2FF-56ECC6820026}}
}

@article{feng-computer2007-green500,
author = {Feng, Wu{-chun} and Cameron, Kirk},
title = {{The Green500 List: Encouraging Sustainable Supercomputing}},
journal = {IEEE Computer},
year = {2007},
volume = {40},
number = {12},
month = dec,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T20:47:53GMT},
uri = {\url{papers2://publication/uuid/914BB8DC-9E99-4D12-8558-14D7DE99C945}}
}

@webpage{Anonymous:4XVZeoFQ,
title = {{Login to Off Campus Sign In}},
url = {http://www.cse.ohio-state.edu/~tavarage/papers/cgo10.pdf},
rating = {0},
date-added = {2013-07-07T21:34:23GMT},
date-modified = {2014-03-21T11:56:18GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Unknown/Login_to_Off_Campus_Sign_In-2.pdf},
file = {{Login_to_Off_Campus_Sign_In-2.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Unknown/Login_to_Off_Campus_Sign_In-2.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E175597A-8150-4E84-8231-76E87E1C5010}}
}

@inproceedings{gardner-ccgrid2003-magnet,
author = {Gardner, Mark K and Feng, Wu{-chun} and Broxton, Michael and Engelhart, Adam and Hurwitz, Justin Gus},
title = {{MAGNET: A Tool for Debugging, Analysis and Adaptation in Computing Systems}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2003},
address = {Tokyo, Japan},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T20:14:14GMT},
uri = {\url{papers2://publication/uuid/FB59FA58-5541-40B2-959A-A411FDEBF33D}}
}

@inproceedings{Shann:2000it,
author = {Shann, Chien-Hua and Huang, T L and Chen, Cheng},
title = {{A practical nonblocking queue algorithm using compare-and-swap}},
booktitle = {International Conference on Parallel and Distributed Systems},
year = {2000},
pages = {470--475},
annote = {Most similar I've found to my wait-free interface.  Must cite!},
keywords = {Important},
doi = {10.1109/ICPADS.2000.857731},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:00:33GMT},
date-modified = {2014-07-05T17:40:34GMT},
abstract = {Many nonblocking algorithms have been proposed for shared queues. Previous studies indicate that link-based algorithms perform best. However, these algorithms have a memory management problem: a dequeued node cannot be freed or reused without proper handling. The problem is usually overlooked; one just assumes the existence of a lower level mechanism, which takes care of all the details of a lower level mechanism, which takes care of all the details of handling the problem. Employing such a mechanism incurs significant overheads, and consequently the link-based queues may not perform as well as claimed. A new non-blocking queue algorithm based on a finite array is proposed. Compared with the link-based algorithms, the new algorithm provides the same degree of concurrency without being subject to the memory problem, hence suggests a good performance View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=857731&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22a+practical+nonblocking+queue+algorithm+using+compare+and+swap%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Shann/A_practical_nonblocking_queue_algorithm_using_compare-and-swap_2000_Shann.pdf},
file = {{A_practical_nonblocking_queue_algorithm_using_compare-and-swap_2000_Shann.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Shann/A_practical_nonblocking_queue_algorithm_using_compare-and-swap_2000_Shann.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPADS.2000.857731}}
}

@inproceedings{ayyorgun-infocom2005-qcomposer,
author = {Ayyorgun, Sami and Vanichpun, Sarut and Feng, Wu{-chun}},
title = {{Q-Composer and CpR: A Probabilistic Synthesizer and Regulator of Traffic}},
booktitle = {24th IEEE Conference on Computer Communications (INFOCOM'05)},
year = {2005},
address = {Miami, Florida},
month = mar,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/4A5BA781-AE02-4E02-A524-7309BE936596}}
}

@techreport{darling-sc2002-mpiblast_poster,
author = {Darling, Aaron E and Feng, Wu{-chun}},
title = {{mpiBLAST: Parallelization of BLAST for Computational Clusters}},
year = {2002},
address = {Baltimore, Maryland},
month = nov,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/6B26E552-DC18-4AFA-9FAD-7F7F529E1E2D}}
}

@inproceedings{hurwitz-hoti2003-10gige,
author = {Hurwitz, Justin Gus and Feng, Wu{-chun}},
title = {{Initial End-to-End Performance Evaluation of 10-Gigabit Ethernet}},
booktitle = {IEEE Hot Interconnects: A Symposium on High-Performance Interconnects},
year = {2003},
address = {Palo Alto, California},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F1E34006-6ACD-4B63-9B8D-5B33419A201E}}
}

@inproceedings{gardner-gw2004-globus,
author = {Gardner, Mark K and Deng, Wei and Markham, Stephen T and Mendes, Celso L and Feng, Wu{-chun} and Reed, Daniel A},
title = {{A High-Fidelity Software Oscilloscope for Globus}},
booktitle = {GlobusWorld 2004},
year = {2004},
address = {San Francisco, California},
month = jan,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5CBDEB78-B8AC-44EC-9804-9CDC3DE1BB0E}}
}

@inproceedings{brown-ic3n11-middleboxes,
author = {Brown, Eric and Gardner, Mark and Kalim, Umar and Feng, Wu{-chun}},
title = {{Restoring End-to-End Resilience in the Presence of Middleboxes}},
booktitle = {20th IEEE International Conference on Computer Communications and Networking (ICCCN)},
year = {2011},
address = {Maui, Hawaii},
month = aug,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/53AEDC06-F325-4FE5-A105-0FE6341C5008}}
}

@techreport{feng-temporal-data-mining-gpu-gems-2011,
author = {Feng, Wu{-chun} and Cao, Yong and Patnaik, Debprakash and Ramakrishnan, Naren},
title = {{Temporal Data Mining for Neuroscience}},
year = {2011},
month = feb,
annote = {Emerald Edition},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/02B55B54-B5B3-479D-914B-3177DC783F47}}
}

@inproceedings{gardner-icvci-virtual_eco,
author = {Gardner, Mark and Feng, Wu{-chun}},
title = {{Towards a Virtual Ecosystem for K-8 Education}},
booktitle = {International Conference on the Virtual Computing Initiative (ICVCI)},
year = {2008},
address = {Research Triangle Park, NC},
month = may,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F825EBA0-2D0C-441B-BB3A-5043EFB96679}}
}

@article{Hsu:2012vr,
author = {Hsu, CH and Kuehn, JA},
title = {{Towards Efficient Supercomputing: Searching for the Right Efficiency Metric}},
year = {2012},
read = {Yes},
rating = {0},
date-added = {2012-05-17T05:24:16GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {ABSTRACT Efficiency in supercomputing has traditionally focused on execution time. In early 2000's, the concept of total cost of ownership was re-introduced, with the introduction of efficiency measure to include aspects such as energy and space. Yet the ... 
},
url = {http://dl.acm.org/ft_gateway.cfm?id=2188309&ftid=1206028&dwn=1},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Hsu/Towards_Efficient_Supercomputing_Searching_for_the_Right_Efficiency_Metric_2012_Hsu.pdf},
file = {{Towards_Efficient_Supercomputing_Searching_for_the_Right_Efficiency_Metric_2012_Hsu.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Hsu/Towards_Efficient_Supercomputing_Searching_for_the_Right_Efficiency_Metric_2012_Hsu.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/DB9D3A85-7862-41C8-BBEE-F5E245784F5E}}
}

@inproceedings{ching-hpdc2006-s3asim,
author = {Ching, Avery and Feng, Wu{-chun} and Lin, Heshan and Ma, Xiaosong and Choudhary, Alok},
title = {{Exploring I/O Strategies for Parallel Sequence Database Search Tools with S3aSim}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {2006},
address = {Paris, France},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5D65E70F-1959-47AF-9F17-1C6B1A252DCF}}
}

@techreport{feng-ipdps2005-poweraware_talk,
author = {Feng, Wu{-chun}},
title = {{The Evolution of Power-Aware, High-Performance Clusters: From the Datacenter to the Desktop}},
year = {2005},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5C303CE2-10E8-455D-92B3-122AE2C8B562}}
}

@techreport{ayyorgun-june2003-loss,
author = {Ayyorgun, S and Cruz, R},
title = {{A Service Curve Model with Loss}},
year = {2003},
month = jun,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-03-21T11:56:17GMT},
uri = {\url{papers2://publication/uuid/F7152B9D-8C24-4FD7-9041-40F07F4D830E}}
}

@inproceedings{feng-pfhsn2002-drs,
author = {Feng, Wu{-chun} and Fisk, Michael E and Gardner, Mark K and Weigle, Eric},
title = {{Dynamic Right-Sizing: An Automated, Lightweight, and Scalable Technique for Enhancing Grid Performance}},
booktitle = {7th International IEEE Workshop on Protocols for High Speed Networks (PfHSN 2002)},
year = {2002},
address = {Berlin, Germany},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B3BE11E4-9DCA-4E68-B6D0-9D653A65766B}}
}

@techreport{feng-visitors2004-greendestiny_talk,
author = {Feng, Wu{-chun}},
title = {{Green Destiny: A 240-Node Compute Cluster in Five Square Feet}},
year = {2004},
month = oct,
annote = {Invited Talk},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/81C6A53C-39BE-4789-BA1B-CE989BB23164}}
}

@inproceedings{feng-milcom2002-security,
author = {Feng, Wu{-chun}},
title = {{Securing Wireless Communication in Heterogeneous Environments}},
booktitle = {IEEE Symposium on Military Communications (MILCOM 2002)},
year = {2002},
address = {Los Angeles, California},
month = oct,
annote = {(electronic version unavailable)},
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/275B09A7-88FC-4E5F-AB3E-5345F64B6593}}
}

@inproceedings{engelhard-ipdps2004-flowcontrol,
author = {Engelhart, Adam and Gardner, Mark K and Feng, Wu{-chun}},
title = {{Re-Architecting Flow-Control Adaptation for Grid Environments}},
crossref = {ipdps},
year = {2004},
address = {Santa Fe, New Mexico},
month = apr,
rating = {0},
date-added = {2013-01-16T16:44:59GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/65463B10-BE69-4658-8B20-8CFA9A8555AF}}
}

@inproceedings{feng-icppmns1999-corba,
author = {Feng, Wu{-chun}},
title = {{The Design of an Open Real-Time System Using CORBA}},
booktitle = {1st International Workshop on Multimedia Network Systems (MNS'99)},
year = {1999},
address = {Aizu, Japan},
month = sep,
annote = {[Based on research performed at UIUC]},
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/82DB3C69-AEFC-4EB0-84B3-FA97411EF831}}
}

@article{Lamport:1974wu,
author = {Lamport, Leslie},
title = {{A new solution of Dijkstra's concurrent programming problem}},
journal = {Communications of the ACM},
year = {1974},
volume = {17},
number = {8},
pages = {453--455},
annote = {Bakery lock paper},
publisher = {ACM},
keywords = {Important},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:14:56GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://dl.acm.org/citation.cfm?id=361093},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1974/Lamport/A_new_solution_of_Dijkstra's_concurrent_programming_problem_1974_Lamport.pdf},
file = {{A_new_solution_of_Dijkstra's_concurrent_programming_problem_1974_Lamport.pdf:/Users/njustn/Dropbox/Papers2/Articles/1974/Lamport/A_new_solution_of_Dijkstra's_concurrent_programming_problem_1974_Lamport.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/3B92F793-03D3-4447-B229-72F2875C1238}}
}

@inproceedings{daga-icpads11-archopt,
author = {Daga, Mayank and Scogland, Thomas R W and Feng, Wu{-chun}},
title = {{Architecture-Aware Mapping and Optimization on a 1600-Core GPU}},
booktitle = {International Conference on Parallel and Distributed Systems},
year = {2011},
pages = {316--323},
publisher = { IEEE Computer Society},
address = {Tainan, Taiwan},
doi = {10.1109/ICPADS.2011.29},
read = {Yes},
rating = {0},
date-added = {2012-05-19T23:59:48GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {The graphics processing unit (GPU) continues to make in-roads as a computational accelerator for high-performance computing (HPC). However, despite its increasing popularity, mapping and optimizing GPU code remains a difficult task, it is a multi-dimensional problem that requires deep technical knowledge of GPU architecture. Although substantial literature exists on how to map and optimize GPU performance on the more mature NVIDIA CUDA architecture, the converse is true for OpenCL on an AMD GPU, such as the 1600-core AMD Radeon HD 5870 GPU. Consequently, we present and evaluate architecture-aware mapping and optimizations for the AMD GPU. The most prominent of which include (i) explicit use of registers, (ii) use of vector types, (iii) removal of branches, and (iv) use of image memory for global data. We demonstrate the efficacy of our AMD GPU mapping and optimizations by applying each in isolation as well as in concert to a large-scale, molecular modeling application called GEM. Via these AMD-specific GPU optimizations, our optimized OpenCL implementation on an AMD Radeon HD 5870 delivers more than a four-fold improvement in performance over the basic OpenCL implementation. In addition, it outperforms our optimized CUDA version on an NVIDIA GTX280 by 12\%. Overall, we achieve a speedup of 371-fold over a serial but hand-tuned SSE version of our molecular modeling application, and in turn, a 46-fold speedup over an ideal scaling on an 8-core CPU. View full abstract},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6121293},
uri = {\url{papers2://publication/doi/10.1109/ICPADS.2011.29}}
}

@inproceedings{feng-icpe12-opencl-13-dwarfs,
author = {Feng, Wu{-chun} and Lin, Heshan and Scogland, Thomas R W and Zhang, Jing},
title = {{OpenCL and the 13 Dwarfs: a Work in Progress}},
booktitle = {Proceedings of the third joint WOSP/SIPEW international conference on Performance Engineering},
year = {2012},
publisher = {ACM},
address = {Boston, MA},
month = apr,
doi = {10.1145/2188286.2188341},
rating = {0},
date-added = {2012-05-20T00:00:04GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {In the past, evaluating the architectural innovation of parallel computing devices relied on a benchmark suite based on existing programs, e.g., EEMBC or SPEC. However, with the growing ubiquity of parallel computing devices, we argue that it is unclear},
url = {http://portal.acm.org/citation.cfm?id=2188286.2188341&coll=DL&dl=GUIDE&CFID=104167694&CFTOKEN=96950902},
uri = {\url{papers2://publication/doi/10.1145/2188286.2188341}}
}

@inproceedings{feng-cluster2002-beowulf,
author = {Feng, Wu{-chun} and Warren, Michael and Weigle, Eric},
title = {{The Bladed Beowulf: A Cost-Effective Alternative to Traditional Beowulfs}},
booktitle = {IEEE International Conference on Cluster Computing (IEEE Cluster 2002)},
year = {2002},
address = {Chicago, Illinois},
month = sep,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/EAD14D5C-BF0A-4E65-B831-64877B2F95C1}}
}

@inproceedings{datta-sc2006-lambdagrid,
author = {Datta, Pallab and Feng, Wu{-chun} and Sharma, Sushant},
title = {{End-System Aware, Rate-Adaptive Protocol for Network Transport in LambdaGrid Environments}},
crossref = {supercomputing},
year = {2006},
address = {Tampa, FL},
month = nov,
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {Next-generation e-Science applications will require the abil- ity to transfer information at high data rates between dis- tributed computing centers and data repositories. A Lambda - Grid offers dedicated, optical, circuit-switched, point-to- point connections that can be reserved ...},
url = {http://portal.acm.org/citation.cfm?id=1188572},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Datta/End-System_Aware_Rate-Adaptive_Protocol_for_Network_Transport_in_LambdaGrid_Environments_2006_Datta.pdf},
file = {{End-System_Aware_Rate-Adaptive_Protocol_for_Network_Transport_in_LambdaGrid_Environments_2006_Datta.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Datta/End-System_Aware_Rate-Adaptive_Protocol_for_Network_Transport_in_LambdaGrid_Environments_2006_Datta.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/A9C455D7-54EA-4810-9F76-9EC7737ADECC}}
}

@inproceedings{feng-lasci2001-packetspacing,
author = {Feng, Annette C and Feng, Wu{-chun} and Belford, Geneva G},
title = {{Packet Spacing: An Enabling Mechanism for the Delivery of Multimedia Content in Computational Grids}},
booktitle = {2nd Los Alamos Computer Science Institute Symposium (LACSI 2001)},
year = {2001},
address = {Santa Fe, New Mexico},
month = oct,
annote = {(Invited for publication in Journal of Supercomputing)},
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/34D934CC-B762-4AC2-9A5C-983EB1714FB9}}
}

@inproceedings{feng-saint2003-renovegas,
author = {Feng, Wu{-chun} and Vanichpun, Sarut},
title = {{Enabling Compatibility Between TCP Reno and TCP Vegas}},
booktitle = {IEEE Symposium on Applications and the Internet (SAINT 2003)},
year = {2003},
pages = {301--308},
address = {Orlando, Florida},
month = jan,
doi = {10.1109/SAINT.2003.1183063},
read = {Yes},
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {Page 1. Enabling  Compatibility  Between  TCP  Reno and TCP  Vegas * W. Feng Computer {\&} Computational Sciences Division Los Alamos National Laboratory feng@lanl.gov S. Vanichpun Dept. of Electrical {\&} Computer Engineering ...},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/SAINT.2003.1183063},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2003/Feng/Enabling_Compatibility_Between_TCP_Reno_and_TCP_Vegas_2003_Feng.pdf},
file = {{Enabling_Compatibility_Between_TCP_Reno_and_TCP_Vegas_2003_Feng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2003/Feng/Enabling_Compatibility_Between_TCP_Reno_and_TCP_Vegas_2003_Feng.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SAINT.2003.1183063}}
}

@inproceedings{feng-icpp07-cpumiser,
author = {Ge, Rong and Feng, Xizhou and Feng, Wu{-chun} and Cameron, Kirk W},
title = {{CPU MISER: A Performance-Directed, Run-Time System for Power-Aware Clusters}},
booktitle = {International Conference on Parallel Processing},
year = {2007},
address = {Xi'an China},
month = sep,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/7945CDE0-7331-49E6-A25D-34630B1F6494}}
}

@inproceedings{feng-icn2002-security,
author = {Feng, Wu{-chun} and Al-Muhtadi, Jalal},
title = {{A General Security Infrastructure for Wireless Communication}},
booktitle = {IEEE International Conference on Networks (ICN 2002)},
year = {2002},
address = {Atlanta, Georgia},
month = aug,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/554C4332-7A26-4D47-8B26-43A08CC70969}}
}

@article{feng-jsc2002-packetspacing,
author = {Feng, Annette C and Kapadia, Apu C and Feng, Wu{-chun} and Belford, Geneva G},
title = {{Packet Spacing: An Enabling Mechanism for the Delivery of Multimedia Content in Computational Grids}},
journal = {Journal of Supercomputing},
year = {2002},
volume = {23},
number = {1},
month = aug,
annote = {(extended version)},
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/5B83F37F-7CDD-42C3-ABB0-4FBF36498C5D}}
}

@inproceedings{feng-msescience-radiology,
author = {Feng, Wu{-chun}},
title = {{Real-Time Transcription of Radiology Dictation: A Case Study for Multimedia Tablet PCs}},
booktitle = {Microsoft eScience Workshop},
year = {2006},
address = {Baltimore, Maryland},
month = oct,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/B1B05F21-65D3-4C24-AC66-A4A9576A3B2B}}
}

@inproceedings{datta-ccgrid2006-lambdagrid,
author = {Datta, Pallab and Sharma, Sushant and Feng, Wu{-chun}},
title = {{A Feedback Mechanism for Network Scheduling in LambdaGrids}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2006},
address = {Singapore},
month = may,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T20:14:14GMT},
uri = {\url{papers2://publication/uuid/688D493C-19D2-406A-BCDF-295AD8FE50E4}}
}

@inproceedings{Stuart:2009jx,
author = {Stuart, J.A and Owens, J D},
title = {{Message passing on data-parallel architectures}},
crossref = {ipdps},
year = {2009},
pages = {1--12},
doi = {10.1109/IPDPS.2009.5161065},
rating = {0},
date-added = {2011-11-12T21:35:05GMT},
date-modified = {2014-07-05T18:28:29GMT},
abstract = {This paper explores the challenges in implementing a message passing interface usable on systems with data-parallel processors. As a case study, we design and implement the ldquoDCGNrdquo API on NVIDIA GPUs that is similar to MPI and allows full access to the underlying architecture. We introduce the notion of data-parallel thread-groups as a way to map resources to MPI ranks. We use a method that also allows the data-parallel processors to run autonomously from user-written CPU code. In order to facilitate communication, we use a sleep-based polling system to store and retrieve messages. Unlike previous systems, our method provides both performance and flexibility. By running a test suite of applications with different communication requirements, we find that a tolerable amount of overhead is incurred, somewhere between one and five percent depending on the application, and indicate the locations where this overhead accumulates. We conclude that with innovations in chipsets and drivers, this overhead will be mitigated and provide similar performance to typical CPU-based MPI implementations while providing fully-dynamic communication.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5161065&openedRefinements%3D*%26filter%3DAND%28NOT%284283010803%29%29%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All%26queryText%3D%28message+passing+on+data+parallel+architectures%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Stuart/Message_passing_on_data-parallel_architectures_2009_Stuart.pdf},
file = {{Message_passing_on_data-parallel_architectures_2009_Stuart.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Stuart/Message_passing_on_data-parallel_architectures_2009_Stuart.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2009.5161065}}
}

@inproceedings{Ryoo:2008jt,
author = {Ryoo, Shane and Rodrigues, Christopher I and Baghsorkhi, Sara S and Stone, Sam S and Kirk, David B and Hwu, Wen-mei W},
title = {{Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming - PPoPP '08}},
booktitle = {Symposium on Principles and Practice of Parallel Programming},
year = {2008},
pages = {73},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/1345206.1345220},
isbn = {9781595937957},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:19:14GMT},
date-modified = {2014-07-05T17:36:15GMT},
url = {http://portal.acm.org/citation.cfm?doid=1345206.1345220},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Ryoo/Proceedings_of_the_13th_ACM_SIGPLAN_Symposium_on_Principles_and_practice_of_parallel_programming_-_PPoPP_'08_2008_Ryoo.pdf},
file = {{Proceedings_of_the_13th_ACM_SIGPLAN_Symposium_on_Principles_and_practice_of_parallel_programming_-_PPoPP_'08_2008_Ryoo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Ryoo/Proceedings_of_the_13th_ACM_SIGPLAN_Symposium_on_Principles_and_practice_of_parallel_programming_-_PPoPP_'08_2008_Ryoo.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1345206.1345220}}
}

@inproceedings{fisk-lasci2001-drs,
author = {Fisk, Michael E and Feng, Wu{-chun}},
title = {{Dynamic Right-Sizing in TCP}},
booktitle = {2nd Annual Los Alamos Computer Science Institute Symposium (LACSI 2001)},
year = {2001},
address = {Santa Fe, New Mexico},
month = oct,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/F2DBFCF5-DE53-4857-A87F-51F548A5ECE0}}
}

@article{Che:2007uf,
author = {Che, S and Meng, J and Sheaffer, JW},
title = {{A performance study of general purpose applications on graphics processors}},
journal = {{\ldots} Workshop on General Purpose {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:19:36GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Graphic processors (GPUs), with many light-weight data-parallel cores, can provide substantial parallel com- putational power to accelerate general purpose applica- tions. To best utilize the GPU's parallel computing re- sources, it is crucial to understand how GPU architectures ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.3025&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Che/A_performance_study_of_general_purpose_applications_on_graphics_processors_2007_Che.pdf},
file = {{A_performance_study_of_general_purpose_applications_on_graphics_processors_2007_Che.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Che/A_performance_study_of_general_purpose_applications_on_graphics_processors_2007_Che.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6D7C765E-74FC-4439-B172-5E3095A9BA41}}
}

@article{gilbert-sgs10-terabase,
author = {Gilbert, Jack and Meyer, Folker and Antonopoulos, Dion and Balaji, Pavan and Brown, C Titus and Brown, Christopher T and Desai, Narayan and Eisen, Jonathan A and Evers, Dirk and Field, Dawn and Feng, Wu{-chun} and Huson, Daniel and Jansson, Janet and Knight, Rob and Knight, James and Kolker, Eugene and Konstantindis, Kostas and Kostka, Joel and Kyrpides, Nikos and Mackelprang, Rachel and McHardy, Alice and Quince, Christopher and Raes, Jeroen and Sczyrba, Alexander and Shade, Ashley and Stevens, Rick},
title = {{The Terabase Metagenomics Workshop and the Vision of an Earth Microbiome Project}},
journal = {Standards in Genomic Sciences},
year = {2010},
volume = {3},
number = {3},
month = dec,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/23AD34A2-9CFD-4ADA-A46A-D04FF473DEC6}}
}

@inproceedings{gans-pp06-signature_talk,
author = {Gans, Jason D and Feng, Wu{-chun} and Wolinsky, Murray},
title = {{Whole Genome, Physics-Based Sequence Alignment for Pathogen Signature Design}},
booktitle = {12th SIAM Conference on Parallel Processing for Scientific Computing},
year = {2006},
address = {San Francisco, California},
month = feb,
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/4382144E-3FEC-47C2-9A85-296FDDE28EDA}}
}

@inproceedings{hsu-hppac2005-metric,
author = {Hsu, Chung-hsing and Feng, Wu{-chun} and Archuleta, Jeremy S},
title = {{Towards Efficient Supercomputing: A Quest for the Right Metric}},
crossref = {hppac},
year = {2005},
address = {Denver, Colorado},
month = apr,
annote = {Presentation},
rating = {0},
date-added = {2013-01-16T16:45:00GMT},
date-modified = {2014-07-05T17:55:52GMT},
uri = {\url{papers2://publication/uuid/127DC663-EA8E-4D3A-BF59-D14262D80284}}
}

@inproceedings{deSupinski:1999dy,
author = {de Supinski, B R and Karonis, N T High Performance Distributed Computing 1999 Proceedings The Eighth International Symposium on},
title = {{Accurately measuring MPI broadcasts in a computational grid}},
booktitle = {International Symposium on High Performance Distributed Computing},
year = {1999},
pages = {29--37},
doi = {10.1109/HPDC.1999.805279},
rating = {0},
date-added = {2013-01-16T20:49:07GMT},
date-modified = {2014-07-05T17:42:14GMT},
abstract = {An MPI library's implementation of broadcast communication can significantly affect the performance of applications built with that library. In order to choose between similar implementations or to evaluate available libraries, accurate measurements of broadcast performance are required. As we demonstrate, existing methods for measuring broadcast performance are either inaccurate or inadequate. Fortunately, we have designed an accurate method for measuring broadcast performance, even in a challenging grid environment. Measuring broadcast performance is not easy. Simply sending one broadcast after another allows them to proceed through the network concurrently, thus resulting in inaccurate per broadcast timings. Existing methods either fail to eliminate this pipelining effect or eliminate it by introducing overheads that are as difficult to measure as the performance of the broadcast itself. This problem becomes even more challenging in grid environments. Latencies along different links can vary significantly. Thus, an algorithm's performance is difficult to predict from it's communication pattern. Even when accurate prediction is possible, the pattern is often unknown. Our method introduces a measurable overhead to eliminate the pipelining effect, regardless of variations in link latencies View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=805279&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Accurately+Measuring+MPI+Broadcasts+in+a+Computational+Grid%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1999/de_Supinski/Accurately_measuring_MPI_broadcasts_in_a_computational_grid_1999_de_Supinski.pdf},
file = {{Accurately_measuring_MPI_broadcasts_in_a_computational_grid_1999_de_Supinski.pdf:/Users/njustn/Dropbox/Papers2/Articles/1999/de_Supinski/Accurately_measuring_MPI_broadcasts_in_a_computational_grid_1999_de_Supinski.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/HPDC.1999.805279}}
}

@article{Chang:2008ta,
author = {Chang, F and Dean, J and Ghemawat, S},
title = {{Bigtable: A distributed storage system for structured data}},
journal = {ACM Transactions on {\ldots}},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:00:59GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {This article was originally published as an award paper in the Proceedings of the 7th Symposium on Operating Systems Design and Implementation [Chang et al. 2006]. It is being republished here with minor modifications and clarifications. Authors' address: Google Inc., 1600 ...},
url = {http://portal.acm.org/citation.cfm?id=1365816},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Chang/Bigtable_A_distributed_storage_system_for_structured_data_2008_Chang.pdf},
file = {{Bigtable_A_distributed_storage_system_for_structured_data_2008_Chang.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Chang/Bigtable_A_distributed_storage_system_for_structured_data_2008_Chang.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2DEA0F2E-6452-483D-8D9E-2B297EC5D826}}
}

@inproceedings{Scogland:2012br,
author = {Scogland, Thomas R W and Rountree, Barry and Feng, Wu{-chun} and de Supinski, Bronis R},
title = {{Heterogeneous Task Scheduling for Accelerated OpenMP}},
crossref = {ipdps},
year = {2012},
pages = {144--155},
publisher = { IEEE Computer Society},
month = may,
doi = {10.1109/IPDPS.2012.23},
read = {Yes},
rating = {0},
date-added = {2013-01-16T21:10:11GMT},
date-modified = {2014-07-05T21:32:05GMT},
abstract = {Heterogeneous systems with CPUs and computational accelerators such as GPUs, FPGAs or the upcoming Intel MIC are becoming mainstream. In these systems, peak performance includes the performance of not just the CPUs but also all available accelerators. In spite of this fact, the majority of programming models for heterogeneous computing focus on only one of these. With the development of Accelerated Open MP for GPUs, both from PGI and Cray, we have a clear path to extend traditional Open MP applications incrementally to use GPUs. The extensions are geared toward switching from CPU parallelism to GPU parallelism. However they do not preserve the former while adding the latter. Thus computational potential is wasted since either the CPU cores or the GPU cores are left idle. Our goal is to create a runtime system that can intelligently divide an accelerated Open MP region across all available resources automatically. This paper presents our proof-of-concept runtime system for dynamic task scheduling across CPUs and GPUs. Further, we motivate the addition of this system into the proposed Open MP for Accelerators standard. Finally, we show that this option can produce as much as a two-fold performance improvement over using either the CPU or GPU alone. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6267831&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Title%3A%22Heterogeneous+Task+Scheduling+for+Accelerated+OpenMP%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Scogland/Heterogeneous_Task_Scheduling_for_Accelerated_OpenMP_2012_Scogland.pdf},
file = {{Heterogeneous_Task_Scheduling_for_Accelerated_OpenMP_2012_Scogland.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Scogland/Heterogeneous_Task_Scheduling_for_Accelerated_OpenMP_2012_Scogland.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2012.23}}
}

@article{lamport-modules,
author = {Lamport, Leslie},
title = {{Specifying Concurrent Program Modules}},
journal = {ACM Transactions on Programming Languages and Systems},
year = {1983},
volume = {5},
number = {2},
pages = {190--222},
month = apr,
annote = {Lamport's queue, uses the tail - m ==head approach, very similar but not resilient to integer rollover.  Almost identical to non-blocking queue in "most similar" paper.},
keywords = {Important},
doi = {10.1145/69624.357207},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:20:06GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://portal.acm.org/citation.cfm?doid=69624.357207},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1983/Lamport/Specifying_Concurrent_Program_Modules_1983_Lamport.pdf},
file = {{Specifying_Concurrent_Program_Modules_1983_Lamport.pdf:/Users/njustn/Dropbox/Papers2/Articles/1983/Lamport/Specifying_Concurrent_Program_Modules_1983_Lamport.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/69624.357207}}
}

@inproceedings{Gidenstam:2010ui,
author = {Gidenstam, Anders and Sundell, H{\aa}kan and Tsigas, Philippas},
title = {{Efficient Lock-Free Queues that Mind the Cache}},
booktitle = {3rd Swedish Workshop on Multi-core Computing (MCC 2010)},
year = {2010},
month = jul,
annote = {Fastest},
keywords = {nocite},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:25:26GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://www.par.univie.ac.at/project/peppher/publications/Published/mcc10lfq.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Gidenstam/Efficient_Lock-Free_Queues_that_Mind_the_Cache_2010_Gidenstam.pdf},
file = {{Efficient_Lock-Free_Queues_that_Mind_the_Cache_2010_Gidenstam.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Gidenstam/Efficient_Lock-Free_Queues_that_Mind_the_Cache_2010_Gidenstam.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/220F5FFC-F711-4359-81E0-F55F0E726B1F}}
}

@inproceedings{Bircsak:2000fk,
author = {Bircsak, J and Craig, P and Crowell, R and Cvetanovic, Z and Harris, J and Nelson, C A and Offner, C D},
title = {{Extending OpenMP For NUMA Machines}},
crossref = {supercomputing},
year = {2000},
pages = {48},
doi = {10.1109/SC.2000.10019},
read = {Yes},
rating = {0},
date-added = {2013-10-30T17:45:26GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {This paper describes extensions to OpenMP that implemen data placemen features needed for NUMA architectures. OpenMP is a collection of compiler directives and library routines used to write portable parallel programs for shared-memory architectures. Writing efficient parallel programs for NUMA architectures, which have characteristics of both shared-memory and distributed-memory architectures, requires that a programmer control the placement of data in memory and the placement of computations that operate on that data. Optimal performance is obtained when computations occur on processors that have fast access to the data needed by those computations. OpenMP-designed for shared-memory architectures-does not by itself address these issues. The extensions to OpenMP Fortran presented here have been mainly taken from High Performance Fortran. The paper describes some of the techniques that the Compaq Fortran compiler uses to generate efficient code based on these extensions. I also describes some additional compiler optimizations, and concludes with some preliminary results. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1592761&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_DOI%3A10.1109%2FSC.2000.10019%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2000/Bircsak/Extending_OpenMP_For_NUMA_Machines_2000_Bircsak.pdf},
file = {{Extending_OpenMP_For_NUMA_Machines_2000_Bircsak.pdf:/Users/njustn/Dropbox/Papers2/Articles/2000/Bircsak/Extending_OpenMP_For_NUMA_Machines_2000_Bircsak.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SC.2000.10019}}
}

@inproceedings{balaji-igcc13-green500,
author = {Subramaniam, Balaji and Saunders, Winston and Scogland, Thomas R W and Feng, Wu{-chun}},
title = {{Trends in energy-efficient computing: A perspective from the Green500}},
booktitle = {International Green Computing Conference (IGCC)},
year = {2013},
pages = {1--8},
doi = {10.1109/IGCC.2013.6604520},
rating = {0},
date-added = {2013-11-03T02:28:47GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {A recent study shows that computation per kilowatt-hour has doubled every 1.57 years, akin to Moore's Law. While this trend is encouraging, its implications to high-performance computing (HPC) are not yet clear. For instance, DARPA's target of a 20-MW exaflop system will require a 56.8-fold performance improvement with only a 2.4-fold increase in power consumption, which seems unachievable in light of the above trend. To provide a more comprehensive perspective, we analyze current trends in energy efficiency from the Green500 and project expectations for the near future. Specifically, we first provide an analysis of energy efficiency trends in HPC systems from the Green500. We then model and forecast the energy efficiency of future HPC systems. Next, we present exascalar - a holistic metric to measure the distance from the exaflop goal. Finally, we discuss our efforts to standardize power measurement methodologies in order to provide the community with reliable and accurate efficiency data. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6604520&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Title%3A%22Trends+in+Energy-Efficient+Computing%3A+A+Perspective+from+the+Green500%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Subramaniam/Trends_in_energy-efficient_computing_A_perspective_from_the_Green500_2013_Subramaniam.pdf},
file = {{Trends_in_energy-efficient_computing_A_perspective_from_the_Green500_2013_Subramaniam.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Subramaniam/Trends_in_energy-efficient_computing_A_perspective_from_the_Green500_2013_Subramaniam.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IGCC.2013.6604520}}
}

@article{Kalim:vg,
author = {Kalim, U and Brown, E and Gardner, M},
title = {{Enabling Renewed Innovation in TCP by Establishing an Isolation Boundary}},
journal = {synergy.cs.vt.edu},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:35:40GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {ABSTRACT The growth of the Internet has ushered in and established the ``Information Age.'' However, its success has also ar- guably increased the difficulty of incorporating innovative changes that are needed to develop further functionality for next-generation networked ...},
url = {http://synergy.cs.vt.edu/pubs/papers/kalim-pfldnet2010-ibo.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Kalim/Enabling_Renewed_Innovation_in_TCP_by_Establishing_an_Isolation_Boundary__Kalim.pdf},
file = {{Enabling_Renewed_Innovation_in_TCP_by_Establishing_an_Isolation_Boundary__Kalim.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Kalim/Enabling_Renewed_Innovation_in_TCP_by_Establishing_an_Isolation_Boundary__Kalim.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/B7A95DBE-97E9-4B71-B19D-7345DB57C474}}
}

@incollection{Feng:2013fs,
author = {Feng, Wu{-chun} and Cameron, Kirk and Scogland, Thomas R W},
title = {{The Green500 List: A look back to look forward}},
booktitle = {Contemporary High Performance Computing
From Petascale toward Exascale},
year = {2013},
editor = {Vetter, Jeffrey S},
pages = {31--41},
publisher = {Chapman and Hall/CRC},
month = jan,
annote = {doi:10.1201/b14677-5},
doi = {doi:10.1201/b14677-5},
isbn = {978-1-4665-6834-1},
rating = {0},
date-added = {2013-11-03T02:38:14GMT},
date-modified = {2014-07-05T17:55:52GMT},
url = {http://dx.doi.org/10.1201/b14677-5},
uri = {\url{papers2://publication/doi/doi:10.1201/b14677-5}}
}

@book{Anonymous:2013uc,
title = {{Contemporary High Performance Computing
From Petascale toward Exascale}},
publisher = {Chapman and Hall/CRC},
year = {2013},
month = jan,
isbn = {978-1-4665-6834-1},
issn = {4665-6834},
rating = {0},
date-added = {2013-11-03T02:38:14GMT},
date-modified = {2014-03-21T11:56:19GMT},
uri = {\url{papers2://publication/uuid/67E81CB9-EE91-497E-AEAF-87CD72E7D0FF}}
}

@article{Scogland:2012el,
author = {Scogland, Thomas R W and Subramaniam, Balaji and Feng, Wu{-chun}},
title = {{The Green500 List: Escapades to Exascale}},
journal = {Computer Science-Research and Development},
year = {2012},
pages = {1--9},
publisher = {Springer-Verlag},
doi = {10.1007/s00450-012-0212-6},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-01-16T22:27:47GMT},
date-modified = {2014-07-05T17:55:52GMT},
abstract = {Abstract Energy efficiency is now a top priority. The first four years of the Green500 have seen the importance of energy efficiency in supercomputing grow from an afterthought to the forefront of innovation as we approach a point where systems become increasingly ... 
},
url = {http://link.springer.com.ezproxy.lib.vt.edu:8080/article/10.1007/s00450-012-0212-6/fulltext.html},
uri = {\url{papers2://publication/doi/10.1007/s00450-012-0212-6}}
}

@incollection{Muller:fu,
author = {M{\"u}ller, Matthias S and Baron, John and Brantley, William C and Feng, Huiyu and Hackenberg, Daniel and Henschel, Robert and Jost, Gabriele and Molka, Daniel and Parrott, Chris and Robichaux, Joe and Shelepugin, Pavel and van Waveren, Matthijs and Whitney, Brian and Kumaran, Kalyan},
title = {{SPEC OMP2012 --- An Application Benchmark Suite for Parallel Systems Using OpenMP}},
booktitle = {Lecture Notes in Computer Science},
pages = {223--236},
publisher = {Springer Berlin Heidelberg},
doi = {10.1007/978-3-642-30961-8_17},
isbn = {978-3-642-30961-8},
read = {Yes},
rating = {0},
date-added = {2013-11-05T18:15:09GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://link.springer.com.ezproxy.lib.vt.edu:8080/chapter/10.1007/978-3-642-30961-8_17},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-30961-8_17}}
}

@inproceedings{Yoshii:bu,
author = {Yoshii, Kazutomo and Iskra, Kamil and Gupta, Rinku and Beckman, Pete and Vishwanath, Venkatram and Yu, Chenjie and Coghlan, Susan},
title = {{Evaluating Power-Monitoring Capabilities on IBM Blue Gene/P and Blue Gene/Q}},
booktitle = {2012 IEEE International Conference on Cluster Computing (CLUSTER)},
pages = {36--44},
publisher = {IEEE},
doi = {10.1109/CLUSTER.2012.62},
isbn = {978-1-4673-2422-9},
read = {Yes},
rating = {0},
date-added = {2013-11-05T18:20:30GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6337854},
uri = {\url{papers2://publication/doi/10.1109/CLUSTER.2012.62}}
}

@article{Dua:ur,
author = {Du, Peng and Weber, Rick and Luszczek, Piotr and Tomov, Stanimire and Peterson, Gregory and Dongarra, Jack},
title = {{From CUDA to OpenCL: Towards a performance-portable solution for multi-platform GPU programming}},
journal = {Parallel Computing},
year = {2012},
volume = {38},
number = {8},
month = aug,
publisher = { Elsevier Science Publishers B. V},
keywords = {ipdps11-omp-co},
doi = {10.1016/j.parco.2011.10.002},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:42:01GMT},
date-modified = {2014-07-05T20:17:49GMT},
abstract = {In this work, we evaluate OpenCL as a programming tool for developing performance-portable applications for GPGPU. While the Khronos group developed OpenCL with programming portability in mind, performance is not necessarily portable. OpenCL has required},
url = {http://portal.acm.org/citation.cfm?id=2318325.2318445&coll=DL&dl=GUIDE&CFID=503059456&CFTOKEN=23607131},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Du/From_CUDA_to_OpenCL_Towards_a_performance-portable_solution_for_multi-platform_GPU_programming_2012_Du.pdf},
file = {{From_CUDA_to_OpenCL_Towards_a_performance-portable_solution_for_multi-platform_GPU_programming_2012_Du.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Du/From_CUDA_to_OpenCL_Towards_a_performance-portable_solution_for_multi-platform_GPU_programming_2012_Du.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.parco.2011.10.002}}
}

@article{Stratton:2012hw,
author = {Stratton, J A and Anssari, N and Rodrigues, C and Sung, I-Jui and Obeid, N and Chang, Liwen and Liu, G D and Hwu, W},
title = {{Optimization and architecture effects on GPU computing workload performance}},
journal = {Innovative Parallel Computing},
year = {2012},
pages = {1--10},
month = oct,
doi = {10.1109/InPar.2012.6339605},
read = {Yes},
rating = {0},
date-added = {2013-02-04T16:29:30GMT},
date-modified = {2014-07-05T20:31:26GMT},
abstract = {It is unquestionable that successive hardware generations have significantly improved GPU computing workload performance over the last several years. Moore's law and DRAM scaling have respectively increased single-chip peak instruction throughput by 3X and off-chip bandwidth by 2.2X from NVIDIA's GeForce 8800 GTX in November 2006 to its GeForce GTX 580 in November 2010. However, raw capability numbers typically underestimate the improvements in real application performance over the same time period, due to significant architectural feature improvements. To demonstrate the effects of architecture features and optimizations over time, we conducted experiments on a set of benchmarks from diverse application domains for multiple GPU architecture generations to understand how much performance has truly been improving for those workloads. First, we demonstrate that certain architectural features make a huge difference in the performance of unoptimized code, such as the inclusion of a general cache which can improve performance by 2-4 in some situations. Second, we describe what optimization patterns have been most essential and widely applicable for improving performance for GPU computing workloads across all architecture generations. Some important optimization patterns included data layout transformation, converting scatter accesses to gather accesses, GPU workload regularization, and granularity coarsening, each of which improved performance on some benchmark by over 20\%, sometimes by a factor of more than 5. While hardware improvements to baseline unoptimized code can reduce the speedup magnitude, these patterns remain important for even the most recent GPUs. Finally, we identify which added architectural features created significant new optimization opportunities, such as increased register file capacity or reduced bandwidth penalties for misaligned accesses, which increase performance by 2 or more in the optimized versions of relevant b- nchmarks. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6339605&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Title%3A%22Optimization+and+Architecture+Effects+on+GPU+Computing+Workload+Performance%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Stratton/Optimization_and_architecture_effects_on_GPU_computing_workload_performance_2012_Stratton.pdf},
file = {{Optimization_and_architecture_effects_on_GPU_computing_workload_performance_2012_Stratton.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Stratton/Optimization_and_architecture_effects_on_GPU_computing_workload_performance_2012_Stratton.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/InPar.2012.6339605}}
}

@article{Anandakrishnan:2010gk,
author = {Anandakrishnan, Ramu and Scogland, Thomas R W and Fenley, Andrew T and Gordon, John C and Feng, Wu{-chun} and Onufriev, Alexey V},
title = {{Accelerating Electrostatic Surface Potential Calculation with Multi-scale Approximation on Graphics Processing Units}},
journal = {Journal of Molecular Graphics and Modelling},
year = {2010},
volume = {28},
number = {8},
pages = {904--910},
month = jun,
keywords = {ipdps11-omp-co},
doi = {10.1016/j.jmgm.2010.04.001},
language = {English},
read = {Yes},
rating = {0},
date-added = {2012-05-20T00:02:19GMT},
date-modified = {2014-07-05T17:55:51GMT},
abstract = {Tools that compute and visualize biomolecular electrostatic surface potential have been used extensively for studying biomolecular function. However, determining the surface potential for large biomolecules on a typical desktop computer can take days or longer ... 
},
url = {http://www.sciencedirect.com/science/article/pii/S1093326310000537},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Anandakrishnan/Accelerating_Electrostatic_Surface_Potential_Calculation_with_Multi-scale_Approximation_on_Graphics_Processing_Units_2010_Anandakrishnan.pdf},
file = {{Accelerating_Electrostatic_Surface_Potential_Calculation_with_Multi-scale_Approximation_on_Graphics_Processing_Units_2010_Anandakrishnan.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Anandakrishnan/Accelerating_Electrostatic_Surface_Potential_Calculation_with_Multi-scale_Approximation_on_Graphics_Processing_Units_2010_Anandakrishnan.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.jmgm.2010.04.001}}
}

@article{GrauerGray:ur,
author = {Grauer-Gray, S and Xu, Lifan and Searles, R and Ayalasomayajula, S and Cavazos, J},
title = {{Auto-Tuning a High-Level Language Targeted to GPU Codes}},
journal = {Innovative Parallel Computing},
year = {2012},
pages = {1--10},
doi = {10.1109/InPar.2012.6339595},
read = {Yes},
rating = {0},
date-added = {2012-05-21T23:49:43GMT},
date-modified = {2014-07-05T20:31:26GMT},
abstract = {Determining the best set of optimizations to apply to a kernel to be executed on the graphics processing unit (GPU) is a challenging problem. There are large sets of possible optimization configurations that can be applied, and many applications have multiple kernels. Each kernel may require a specific configuration to achieve the best performance, and moving an application to new hardware often requires a new optimization configuration for each kernel. In this work, we apply optimizations to GPU code using HMPP, a high-level directive-based language and source-to-source compiler that can generate CUDA / OpenCL code. However, programming with high-level languages may mean a loss of performance compared to using low-level languages. Our work shows that it is possible to improve the performance of a high-level language by using auto-tuning. We perform auto-tuning on a large optimization space on GPU kernels, focusing on loop permutation, loop unrolling, tiling, and specifying which loop(s) to parallelize, and show results on convolution kernels, codes in the PolyBench suite, and an implementation of belief propagation for stereo vision. The results show that our auto-tuned HMPP-generated implementations are significantly faster than the default HMPP implementation and can meet or exceed the performance of manually coded CUDA / OpenCL implementations. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6339595&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28p_Title%3A%22Auto-tuning+a+High-Level+Language+Targeted+to+GPU+Codes%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Grauer-Gray/Auto-Tuning_a_High-Level_Language_Targeted_to_GPU_Codes_2012_Grauer-Gray.pdf},
file = {{Auto-Tuning_a_High-Level_Language_Targeted_to_GPU_Codes_2012_Grauer-Gray.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Grauer-Gray/Auto-Tuning_a_High-Level_Language_Targeted_to_GPU_Codes_2012_Grauer-Gray.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/InPar.2012.6339595}}
}

@article{Anonymous:ZO1hVJVO,
title = {{Projecting GPU Performance by Modeling CPU Code Skeletons}},
year = {2011},
pages = {1--12},
month = jul,
rating = {0},
date-added = {2012-06-01T02:50:26GMT},
date-modified = {2014-03-21T11:56:14GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Unknown/Projecting_GPU_Performance_by_Modeling_CPU_Code_Skeletons_2011.pdf},
file = {{Projecting_GPU_Performance_by_Modeling_CPU_Code_Skeletons_2011.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Unknown/Projecting_GPU_Performance_by_Modeling_CPU_Code_Skeletons_2011.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/64ED6154-954E-47A9-8439-FE528070E753}}
}

@article{Ryoo:2007wk,
author = {Ryoo, S and Rodrigues, C and Stone, S},
title = {{Program optimization study on a 128-core GPU}},
journal = {The First Workshop on {\ldots}},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:20:14GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Abstract--- The newest generations of graphics processing unit ( GPU ) architecture, such as the NVIDIA GeForce 8-series, feature new interfaces that improve programmability and gener- ality over previous GPU generations. Using NVIDIA's Compute Unified Device Architecture ( ...},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.902&rep=rep1&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Ryoo/Program_optimization_study_on_a_128-core_GPU_2007_Ryoo.pdf},
file = {{Program_optimization_study_on_a_128-core_GPU_2007_Ryoo.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Ryoo/Program_optimization_study_on_a_128-core_GPU_2007_Ryoo.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/3326AD24-FB96-4075-98D0-43F5D30DABF2}}
}

@article{Gidenstam:2010bk,
author = {Gidenstam, Anders and Sundell, H{\aa}kan and Tsigas, Philippas},
title = {{Cache-aware lock-free queues for multiple producers/consumers and weak memory consistency}},
journal = {Lecture Notes in Computer Science},
year = {2010},
pages = {302--317},
publisher = {Springer},
doi = {10.1007/978-3-642-17653-1_23},
isbn = {3642176526},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:36:34GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://link.springer.com/chapter/10.1007/978-3-642-17653-1_23},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Gidenstam/Cache-aware_lock-free_queues_for_multiple_producersconsumers_and_weak_memory_consistency_2010_Gidenstam.pdf},
file = {{Cache-aware_lock-free_queues_for_multiple_producersconsumers_and_weak_memory_consistency_2010_Gidenstam.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Gidenstam/Cache-aware_lock-free_queues_for_multiple_producersconsumers_and_weak_memory_consistency_2010_Gidenstam.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1007/978-3-642-17653-1_23}}
}

@inproceedings{Kogge:2011uv,
author = {Kogge, P M and Dysart, T J},
title = {{Using the TOP500 to trace and project technology and architecture trends}},
crossref = {supercomputing},
year = {2011},
rating = {0},
date-added = {2013-02-06T03:35:52GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {The TOP500 is a treasure trove of information on the leading edge of high performance computing. It was used in the 2008 DARPA Exascale technology report to isolate out the effects of architecture and technology on high performance computing, and lay the groundwork to project how current systems might mature through the coming years. Two particular classes of architectures were identified: "heavyweight" (based on high end commodity microprocessors) and "lightweight," (primarily BlueGene variants), and projections made on performance, concurrency, memory capacity, and power. This paper updates those projections, and adds a third class of "heterogeneous" architectures (leveraging the emerging class of GPU-like chips) to the mix. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6114423&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22Using+the+TOP500+to+trace+and+project+technology+and+architecture+trends%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Kogge/Using_the_TOP500_to_trace_and_project_technology_and_architecture_trends_2011_Kogge.pdf},
file = {{Using_the_TOP500_to_trace_and_project_technology_and_architecture_trends_2011_Kogge.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Kogge/Using_the_TOP500_to_trace_and_project_technology_and_architecture_trends_2011_Kogge.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/815A9780-DDC6-4A6F-B843-0A051C84E050}}
}

@inproceedings{Haque:2010gt,
author = {Haque, Imran S and Pande, Vijay S},
title = {{Hard Data on Soft Errors: A Large-Scale Assessment of Real-World Error Rates in GPGPU}},
booktitle = {IEEE/ACM International Symposium on Cluster Computing and the Grid},
year = {2010},
pages = {691--696},
doi = {10.1109/CCGRID.2010.84},
read = {Yes},
rating = {0},
date-added = {2011-04-19T13:37:54GMT},
date-modified = {2014-07-05T20:14:14GMT},
abstract = {Graphics processing units (GPUs) are gaining widespread use in high-performance computing because of their performance advantages relative to CPUs. However, the reliability of GPUs is largely unproven. In particular, current GPUs lack error checking and correcting (ECC) in their memory subsystems. The impact of this design has not been previously measured at a large enough scale to quantify soft error events. We present MemtestG80, our software for assessing memory error rates on NVIDIA graphics cards. Furthermore, we present a large-scale assessment of GPU error rate, conducted by running MemtestG80 on over 50,000 hosts on the Folding@home distributed computing network. Our control experiments on consumer-grade and dedicated-GPGPU hardware in a controlled environment found no errors. However, our survey on Folding@home finds that, in their installed environments, two-thirds of tested GPUs exhibit a detectable, pattern-sensitive rate of memory soft errors. We show that these errors persist after controlling for over clocking and environmental proxies for temperature, but depend strongly on board architecture.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=5493404&queryText%3D%28hard+data+on+soft+errors%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Haque/Hard_Data_on_Soft_Errors_A_Large-Scale_Assessment_of_Real-World_Error_Rates_in_GPGPU_2010_Haque.pdf},
file = {{Hard_Data_on_Soft_Errors_A_Large-Scale_Assessment_of_Real-World_Error_Rates_in_GPGPU_2010_Haque.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Haque/Hard_Data_on_Soft_Errors_A_Large-Scale_Assessment_of_Real-World_Error_Rates_in_GPGPU_2010_Haque.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/CCGRID.2010.84}}
}

@article{Cameron:2006gw,
author = {Cameron, Michael and Williams, Hugh E and Cannane, Adam},
title = {{A Deterministic Finite Automaton for Faster Protein Hit Detection in BLAST}},
journal = {Journal of Computational Biology},
year = {2006},
volume = {13},
number = {4},
pages = {965--978},
month = may,
doi = {10.1089/cmb.2006.13.965},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:38:50GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {BLAST is the most popular bioinformatics tool and is used to run millions of queries each day. However, evaluating such queries is slow, taking typically minutes on modern workstations. Therefore, continuing evolution of BLAST-by improving its algorithms and ...},
url = {http://www.liebertonline.com/doi/abs/10.1089/cmb.2006.13.965},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2006/Cameron/A_Deterministic_Finite_Automaton_for_Faster_Protein_Hit_Detection_in_BLAST_2006_Cameron.pdf},
file = {{A_Deterministic_Finite_Automaton_for_Faster_Protein_Hit_Detection_in_BLAST_2006_Cameron.pdf:/Users/njustn/Dropbox/Papers2/Articles/2006/Cameron/A_Deterministic_Finite_Automaton_for_Faster_Protein_Hit_Detection_in_BLAST_2006_Cameron.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1089/cmb.2006.13.965}}
}

@article{Kaashoek:1997wt,
author = {Kaashoek, MF and Engler, DR and Ganger, GR},
title = {{Application performance and flexibility on exokernel systems}},
journal = {{\ldots} on Operating systems {\ldots}},
year = {1997},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:01:34GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {Application  Performance and Hexibility on Exokernel  Systems  ... It evaluates the exokemel architecture by measuring end-to-end application  performance on Xok, an exo - kernel for Intel x86-based computers, and by comparing Xok's performance to the performance of two ...},
url = {http://portal.acm.org/citation.cfm?id=266644},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1997/Kaashoek/Application_performance_and_flexibility_on_exokernel_systems_1997_Kaashoek.pdf},
file = {{Application_performance_and_flexibility_on_exokernel_systems_1997_Kaashoek.pdf:/Users/njustn/Dropbox/Papers2/Articles/1997/Kaashoek/Application_performance_and_flexibility_on_exokernel_systems_1997_Kaashoek.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F635B317-6080-4746-8B2D-9C6B52D1738B}}
}

@article{linearizability,
author = {Herlihy, Maurice P and Wing, Jeannette M},
title = {{Linearizability: A correctness condition for concurrent objects}},
journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
year = {1990},
volume = {12},
number = {3},
pages = {463--492},
annote = {Must include proof of this property},
publisher = {ACM},
keywords = {Important},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:40:58GMT},
date-modified = {2014-03-21T11:56:16GMT},
url = {http://dl.acm.org/citation.cfm?id=78972},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1990/Herlihy/Linearizability_A_correctness_condition_for_concurrent_objects_1990_Herlihy.pdf},
file = {{Linearizability_A_correctness_condition_for_concurrent_objects_1990_Herlihy.pdf:/Users/njustn/Dropbox/Papers2/Articles/1990/Herlihy/Linearizability_A_correctness_condition_for_concurrent_objects_1990_Herlihy.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E5266152-B099-4891-9EB4-DC7D30805B4E}}
}

@article{Dean:2008ua,
author = {Dean, J},
title = {{MapReduce: Simplified Data Processing on Large Clusters}},
journal = {Communications of the ACM},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:43:04GMT},
date-modified = {2014-07-05T20:46:04GMT},
abstract = {1 Introduction Prior to our development of MapReduce , the authors and many others at Google implemented hundreds of special-purpose computations that process large amounts of raw data, such as crawled documents, Web request logs, etc., to compute various kinds of ...},
url = {http://portal.acm.org/citation.cfm?id=1327492},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Dean/MapReduce_Simplified_Data_Processing_on_Large_Clusters_2008_Dean-1.pdf},
file = {{MapReduce_Simplified_Data_Processing_on_Large_Clusters_2008_Dean-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Dean/MapReduce_Simplified_Data_Processing_on_Large_Clusters_2008_Dean-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5064A70E-E077-4B4B-B713-9EEA5DA9FCEB}}
}

@article{Phothilimthana:2013vh,
author = {Phothilimthana, P M and Ansel, J and Ragan-Kelley, J},
title = {{Portable Performance on Heterogeneous Architectures}},
year = {2013},
rating = {0},
date-added = {2013-02-09T18:52:21GMT},
date-modified = {2014-03-21T11:56:14GMT},
abstract = {Abstract Trends in both consumer and high performance computing are bringing not only more cores, but also increased heterogeneity among the computational resources within a single machine. In many machines, one of the greatest computational resources is now ... 
},
url = {http://people.csail.mit.edu/jrk/pbgpu-asplos13.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Phothilimthana/Portable_Performance_on_Heterogeneous_Architectures_2013_Phothilimthana.pdf},
file = {{Portable_Performance_on_Heterogeneous_Architectures_2013_Phothilimthana.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Phothilimthana/Portable_Performance_on_Heterogeneous_Architectures_2013_Phothilimthana.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/50517811-7A39-41D2-9D3F-53B14A6B3070}}
}

@article{Shi:2009tv,
author = {Shi, G and Enos, J and Showerman, M},
title = {{On testing GPU memory for hard and soft errors}},
journal = {Proc Symposium on {\ldots}},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-04-19T13:56:56GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Abstract---NVIDIA GPUs are becoming increasingly popular in scientific computation as a way to accelerate the execution of computationally demanding codes. The graphics memory used in GPUs is not protected against soft errors that may be caused by cosmic radiation and ...},
url = {http://saahpc.ncsa.illinois.edu/09/papers/Shi_paper.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Shi/On_testing_GPU_memory_for_hard_and_soft_errors_2009_Shi.pdf},
file = {{On_testing_GPU_memory_for_hard_and_soft_errors_2009_Shi.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Shi/On_testing_GPU_memory_for_hard_and_soft_errors_2009_Shi.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/1EA39A6C-D076-4546-9F73-B045949D0606}}
}

@article{Dean:2010cw,
author = {Dean, Jeffrey and Ghemawat, Sanjay},
title = {{MapReduce: A Flexible Data Processing Tool}},
journal = {Communications of the ACM},
year = {2010},
volume = {53},
number = {1},
pages = {72--77},
month = jan,
publisher = {ACM},
keywords = {ipdps11-omp-co},
doi = {10.1145/1629175.1629198},
language = {English},
read = {Yes},
rating = {0},
date-added = {2011-11-12T20:43:08GMT},
date-modified = {2014-07-05T20:47:22GMT},
abstract = {MapReduce automatically parallelizes and executes the program on a large cluster of commodity machines. The runtime system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and ...},
url = {http://portal.acm.org/citation.cfm?doid=1629175.1629198},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Dean/MapReduce_A_Flexible_Data_Processing_Tool_2010_Dean.pdf},
file = {{MapReduce_A_Flexible_Data_Processing_Tool_2010_Dean.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Dean/MapReduce_A_Flexible_Data_Processing_Tool_2010_Dean.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1629175.1629198}}
}

@inproceedings{Odajima:cw,
author = {Odajima, Tetsuya and Boku, Taisuke and Hanawa, Toshihiro and Lee, Jinpil and Sato, Mitsuhisa},
title = {{GPU/CPU Work Sharing with Parallel Language XcalableMP-dev for Parallelized Accelerated Computing}},
booktitle = {2012 41st International Conference on Parallel Processing Workshops (ICPPW)},
pages = {97--106},
publisher = {IEEE},
doi = {10.1109/ICPPW.2012.16},
isbn = {978-0-7695-4795-4},
rating = {0},
date-added = {2013-11-18T07:19:15GMT},
date-modified = {2014-04-06T17:24:04GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6337468},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Odajima/GPUCPU_Work_Sharing_with_Parallel_Language_XcalableMP-dev_for_Parallelized_Accelerated_Computing__Odajima.pdf},
file = {{GPUCPU_Work_Sharing_with_Parallel_Language_XcalableMP-dev_for_Parallelized_Accelerated_Computing__Odajima.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Odajima/GPUCPU_Work_Sharing_with_Parallel_Language_XcalableMP-dev_for_Parallelized_Accelerated_Computing__Odajima.pdf:application/pdf;GPUCPU_Work_Sharing_with_Parallel_Language_XcalableMP-dev_for_Parallelized_Accelerated_Computing__Odajima.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Odajima/GPUCPU_Work_Sharing_with_Parallel_Language_XcalableMP-dev_for_Parallelized_Accelerated_Computing__Odajima.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ICPPW.2012.16}}
}

@inproceedings{Nieh:2001tj,
author = {Nieh, J and Vaill, C},
title = {{Virtual-time round-robin: An O (1) proportional share scheduler}},
booktitle = {Proceedings of the 2001 USENIX Annual {\ldots}},
year = {2001},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:02:44GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Proportional share resource management provides a flexible and useful abstraction for multiplexing time -shared resources. However, previous proportional share mechanisms have either weak proportional sharing accuracy or high scheduling overhead. We present Virtual - Time ...},
url = {http://www.usenix.org/event/usenix01/full_papers/nieh/nieh_html/},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2001/Nieh/Virtual-time_round-robin_An_O_(1)_proportional_share_scheduler_2001_Nieh.pdf},
file = {{Virtual-time_round-robin_An_O_(1)_proportional_share_scheduler_2001_Nieh.pdf:/Users/njustn/Dropbox/Papers2/Articles/2001/Nieh/Virtual-time_round-robin_An_O_(1)_proportional_share_scheduler_2001_Nieh.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/2DD86CA1-1367-4CD8-BEC1-166804E8DD42}}
}

@inproceedings{scogland:7Hpt64iV,
author = {Scogland, Thomas R W and Rountree, Barry and Feng, Wu{-chun} and de Supinski, Bronis R},
title = {{CoreTSAR: Adaptive Worksharing for Heterogeneous Systems}},
booktitle = {International Supercomputing Conference},
year = {2014},
address = {Leipzig},
month = jun,
rating = {0},
date-added = {2013-11-28T17:47:38GMT},
date-modified = {2014-07-05T21:09:08GMT},
uri = {\url{papers2://publication/uuid/EC7A6DEB-8895-4531-A7F5-7DE664595DD5}}
}

@article{Kogge:2008ww,
author = {Kogge, P and Bergman, K and Borkar, S and Campbell, D and Carson, W and Dally, W and Denneau, M and Franzon, P and Harrod, W and Hill, K and {Others}},
title = {{Exascale computing study: Technology challenges in achieving exascale systems}},
journal = {Vol. TR-2008-13 (2008)},
year = {2008},
volume = {TR-2008-13},
read = {Yes},
rating = {0},
date-added = {2012-02-12T20:25:10GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {... CiteULike is a free online bibliography manager. Register and you can start organising your references online. Tags. Exascale  computing  study : Technology challenges in achieving exascale systems. ... 
},
url = {http://www.citeulike.org/group/11430/article/6638217},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Kogge/Exascale_computing_study_Technology_challenges_in_achieving_exascale_systems_2008_Kogge.pdf},
file = {{Exascale_computing_study_Technology_challenges_in_achieving_exascale_systems_2008_Kogge.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Kogge/Exascale_computing_study_Technology_challenges_in_achieving_exascale_systems_2008_Kogge.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/540CD868-7926-4A2F-B731-2BB56D3D0A71}}
}

@article{Rowstron:2001wn,
author = {Rowstron, A},
title = {{Pastry: Scalable, decentralized object location, and routing for large-scale peer-to-peer systems}},
journal = {{\ldots} 2001: IFIP/ACM International Conference on {\ldots}},
year = {2001},
rating = {0},
date-added = {2011-04-01T13:16:31GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Abstract. This paper presents the design and evaluation of Pastry , a scalable , dis- tributed object location and routing substrate for wide-area peer-to-peer applica- tions. Pastry performs application-level routing and object location in a potentially very large overlay network of ...},
url = {http://www.springerlink.com/index/7y5mjjep0hqlctv6.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2001/Rowstron/Pastry_Scalable_decentralized_object_location_and_routing_for_large-scale_peer-to-peer_systems_2001_Rowstron.pdf},
file = {{Pastry_Scalable_decentralized_object_location_and_routing_for_large-scale_peer-to-peer_systems_2001_Rowstron.pdf:/Users/njustn/Dropbox/Papers2/Articles/2001/Rowstron/Pastry_Scalable_decentralized_object_location_and_routing_for_large-scale_peer-to-peer_systems_2001_Rowstron.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/12B92692-0476-4A82-BE21-63825DAF38D8}}
}

@inproceedings{Meng:2011iv,
author = {Meng, Jiayuan and Morozov, Vitali A and Kumaran, Kalyan and Vishwanath, Venkatram and Uram, Thomas D},
title = {{GROPHECY: GPU performance projection from CPU code skeletons}},
crossref = {supercomputing},
year = {2011},
publisher = {ACM},
month = nov,
doi = {10.1145/2063384.2063402},
read = {Yes},
rating = {0},
date-added = {2012-06-01T03:07:01GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {We propose GROPHECY, a GPU performance projection framework that can estimate the performance benefit of GPU acceleration without actual GPU programming or hardware. Users need only to skeletonize pieces of CPU code that are targets for},
url = {http://portal.acm.org/citation.cfm?id=2063384.2063402&coll=DL&dl=GUIDE&CFID=85625252&CFTOKEN=81567615},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Meng/GROPHECY_GPU_performance_projection_from_CPU_code_skeletons_2011_Meng.pdf},
file = {{GROPHECY_GPU_performance_projection_from_CPU_code_skeletons_2011_Meng.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Meng/GROPHECY_GPU_performance_projection_from_CPU_code_skeletons_2011_Meng.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2063384.2063402}}
}

@techreport{Henzinger:2012uz,
author = {Henzinger, Thomas A and Sezgin, Ali and Campus, Am},
title = {{How Free is Your Linearizable Concurrent Data Structure?}},
year = {2012},
number = {IST-2013-123-v1+1},
publisher = {Institute of Science and Technology Austria},
read = {Yes},
rating = {0},
date-added = {2013-07-21T14:59:05GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {https://repository.ist.ac.at/123/2/main-concur2013.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Reports/2012/Henzinger/How_Free_is_Your_Linearizable_Concurrent_Data_Structure_2012_Henzinger.pdf},
file = {{How_Free_is_Your_Linearizable_Concurrent_Data_Structure_2012_Henzinger.pdf:/Users/njustn/Dropbox/Papers2/Reports/2012/Henzinger/How_Free_is_Your_Linearizable_Concurrent_Data_Structure_2012_Henzinger.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6567C98B-7C24-4FFE-BD41-749565B6165D}}
}

@article{Hardy:2009kk,
author = {Hardy, David J and Stone, John E and Schulten, Klaus},
title = {{Multilevel summation of electrostatic potentials using graphics processing units}},
journal = {Parallel Computing},
year = {2009},
volume = {35},
number = {3},
pages = {164--177},
month = mar,
publisher = {Elsevier B.V.},
doi = {10.1016/j.parco.2008.12.005},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:20:56GMT},
date-modified = {2014-03-21T11:56:17GMT},
url = {http://dx.doi.org/10.1016/j.parco.2008.12.005},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Hardy/Multilevel_summation_of_electrostatic_potentials_using_graphics_processing_units_2009_Hardy.pdf},
file = {{Multilevel_summation_of_electrostatic_potentials_using_graphics_processing_units_2009_Hardy.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Hardy/Multilevel_summation_of_electrostatic_potentials_using_graphics_processing_units_2009_Hardy.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.parco.2008.12.005}}
}

@article{Harish:2007vq,
author = {Harish, P},
title = {{Accelerating large graph algorithms on the GPU using CUDA}},
journal = {High Performance Computing--HiPC 2007},
year = {2007},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:21:17GMT},
date-modified = {2014-03-21T11:56:17GMT},
abstract = {Abstract. Large graphs involving millions of vertices are common in many prac- tical applications and are challenging to process. Practical-time implementations using high-end computers are reported but are accessible only to a few. Graphics Processing Units (GPUs) of today ...},
url = {http://www.springerlink.com/index/Y4816X2Q7475V93N.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2007/Harish/Accelerating_large_graph_algorithms_on_the_GPU_using_CUDA_2007_Harish.pdf},
file = {{Accelerating_large_graph_algorithms_on_the_GPU_using_CUDA_2007_Harish.pdf:/Users/njustn/Dropbox/Papers2/Articles/2007/Harish/Accelerating_large_graph_algorithms_on_the_GPU_using_CUDA_2007_Harish.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/BA2839AB-FB02-4959-BF92-617612AD414B}}
}

@inproceedings{Haas:2013he,
author = {Haas, Andreas and Lippautz, Michael and Henzinger, Thomas A and Payer, Hannes and Sokolova, Ana and Kirsch, Christoph M and Sezgin, Ali},
title = {{Distributed queues in shared memory: multicore performance and scalability through quantitative relaxation}},
booktitle = {ACM International Conference on Computing Frontiers},
year = {2013},
pages = {1},
publisher = {ACM Press},
address = {New York, New York, USA},
doi = {10.1145/2482767.2482789},
isbn = {9781450320535},
read = {Yes},
rating = {0},
date-added = {2013-07-21T15:01:57GMT},
date-modified = {2014-03-21T12:05:26GMT},
url = {http://dl.acm.org/citation.cfm?doid=2482767.2482789},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Haas/Distributed_queues_in_shared_memory_multicore_performance_and_scalability_through_quantitative_relaxation_2013_Haas.pdf},
file = {{Distributed_queues_in_shared_memory_multicore_performance_and_scalability_through_quantitative_relaxation_2013_Haas.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Haas/Distributed_queues_in_shared_memory_multicore_performance_and_scalability_through_quantitative_relaxation_2013_Haas.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2482767.2482789}}
}

@inproceedings{CharmppOOPSLA93,
author = {Kale, L.V. and Krishnan, S.},
title = {{CHARM++: A Portable Concurrent Object Oriented System Based on C++}},
booktitle = {ACM SIGPLAN Conference on Object Oriented Programming, Systems, Languages, and Applications},
year = {1993},
editor = {Paepcke, A.},
pages = {91--108},
publisher = {ACM Press},
month = sep,
keywords = {ipdps11-omp-co},
rating = {0},
date-added = {2011-11-13T01:11:49GMT},
date-modified = {2014-07-05T20:36:25GMT},
url = {http://charm.cs.illinois.edu/newPapers/93-02/paper.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1993/Kale/CHARM++_A_Portable_Concurrent_Object_Oriented_System_Based_on_C++_1993_Kale.pdf},
file = {{CHARM++_A_Portable_Concurrent_Object_Oriented_System_Based_on_C++_1993_Kale.pdf:/Users/njustn/Dropbox/Papers2/Articles/1993/Kale/CHARM++_A_Portable_Concurrent_Object_Oriented_System_Based_on_C++_1993_Kale.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/881131A8-FE6C-4FFC-A819-6535D7195EB9}}
}

@article{Hong:2009vg,
author = {Hong, S},
title = {{An Analytical Model For a GPU Architecture With Memory-Level and Thread-Level Parallelism Awareness}},
journal = {ACM SIGARCH Computer Architecture News},
year = {2009},
read = {Yes},
rating = {0},
date-added = {2011-11-12T21:39:30GMT},
date-modified = {2014-07-05T20:23:15GMT},
abstract = {An Analytical  Model for a GPU  Architecture with Memory-level and Thread-level Parallelism Awareness ... 1. To the best of our knowledge, we propose the first analytical  model for the GPU architecture . This can be easily extended to other multithreaded architectures as well. ...},
url = {http://portal.acm.org/citation.cfm?id=1555775},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Hong/An_Analytical_Model_For_a_GPU_Architecture_With_Memory-Level_and_Thread-Level_Parallelism_Awareness_2009_Hong-1.pdf},
file = {{An_Analytical_Model_For_a_GPU_Architecture_With_Memory-Level_and_Thread-Level_Parallelism_Awareness_2009_Hong-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Hong/An_Analytical_Model_For_a_GPU_Architecture_With_Memory-Level_and_Thread-Level_Parallelism_Awareness_2009_Hong-1.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/E43DF99B-7F14-4778-A59F-6C356B647847}}
}

@article{Mamidala:2008bq,
author = {Mamidala, A.R and Kumar, R and De, D and Panda, D.K},
title = {{MPI Collectives on Modern Multicore Clusters: Performance Optimizations and Communication Characteristics}},
journal = {Cluster Computing and the Grid, 2008. CCGRID '08. 8th IEEE International Symposium on},
year = {2008},
pages = {130--137},
doi = {10.1109/CCGRID.2008.87},
read = {Yes},
rating = {0},
date-added = {2011-04-20T02:48:02GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {The advances in multicore technology and modern interconnects is rapidly accelerating the number of cores deployed in today's commodity clusters. A majority of parallel applications written in MPI employ collective operations in their communication kernels. Optimization of these operations on the multicore platforms is the key to obtaining good performance speed-ups. However, designing these operations on the modern multicores is a non-trivial task. Modern multicores such as Intel's Clovertown and AMD's Opteron feature various architectural attributes resulting in interesting ramifications. For example, Clovertown deploys shared 12 caches for a pair of cores whereas in Opteron, 12 caches are exclusive to a core. Understanding the impact of these architectures on communication performance is crucial to designing efficient collective algorithms. In this paper, we systematically evaluate these architectures and use these insights to develop efficient collective operations such as MPI_Bcast, MPI_Allgather, MPI_Allreduce and MPI_Alltoall. Further, we characterize the behavior of these collective algorithms on multicores especially when concurrent network and intra-node communications occur. We also evaluate the benefits of the proposed intra-node MPI_Allreduce over Opteron multicores and compare it with Intel Clovertown systems. The optimizations proposed in this paper reduce the latency of MPI-Bcast and MPI_Allgather by 1.9 and 4.0 times, respectively on 512 cores. For MPI_Allreduce, our optimizations improve the performance by as much as 33\% on the multicores. Further, we observe up to three times improvement in performance for matrix multiplication benchmark on 512 cores.},
url = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=4534211&queryText%3D%28mpi+collectives+on+modern+multicore+clusters%29%26openedRefinements%3D*%26matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch+All},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Mamidala/MPI_Collectives_on_Modern_Multicore_Clusters_Performance_Optimizations_and_Communication_Characteristics_2008_Mamidala.pdf},
file = {{MPI_Collectives_on_Modern_Multicore_Clusters_Performance_Optimizations_and_Communication_Characteristics_2008_Mamidala.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Mamidala/MPI_Collectives_on_Modern_Multicore_Clusters_Performance_Optimizations_and_Communication_Characteristics_2008_Mamidala.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/CCGRID.2008.87}}
}

@article{Anonymous:2012hg,
title = {{Locality Principle Revisited: A Probability-Based Quantitative Approach}},
year = {2012},
pages = {1--15},
month = apr,
doi = {10.1109/IPDPS.2012.93},
rating = {0},
date-added = {2012-06-01T03:20:49GMT},
date-modified = {2014-03-21T11:56:17GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Locality_Principle_Revisited_A_Probability-Based_Quantitative_Approach_2012.pdf},
file = {{Locality_Principle_Revisited_A_Probability-Based_Quantitative_Approach_2012.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Locality_Principle_Revisited_A_Probability-Based_Quantitative_Approach_2012.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2012.93}}
}

@article{Anonymous:2012hr,
title = {{Evaluating the Impact of TLB Misses on Future HPC Systems}},
year = {2012},
pages = {1--12},
month = apr,
doi = {10.1109/IPDPS.2012.94},
rating = {0},
date-added = {2012-06-01T03:24:19GMT},
date-modified = {2014-03-21T11:56:19GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Evaluating_the_Impact_of_TLB_Misses_on_Future_HPC_Systems_2012.pdf},
file = {{Evaluating_the_Impact_of_TLB_Misses_on_Future_HPC_Systems_2012.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Evaluating_the_Impact_of_TLB_Misses_on_Future_HPC_Systems_2012.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/IPDPS.2012.94}}
}

@article{Basaran:2013jm,
author = {Basaran, Can and Kang, Kyoung-Don},
title = {{Grex: An efficient MapReduce Framework for Graphics Processing Units}},
journal = {Journal of parallel and Distributed Computing},
year = {2013},
month = jan,
doi = {10.1016/j.jpdc.2013.01.004},
language = {English},
read = {Yes},
rating = {0},
date-added = {2013-02-09T19:11:41GMT},
date-modified = {2014-07-05T20:46:22GMT},
abstract = {Abstract In this paper, we present a new MapReduce framework , called Grex , designed to leverage general purpose graphics processing units (GPUs) for parallel data processing . Grex provides several new features. First, it supports a parallel split method to tokenize ... 
},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0743731513000051},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2013/Basaran/Grex_An_efficient_MapReduce_Framework_for_Graphics_Processing_Units_2013_Basaran-1.pdf},
file = {{Grex_An_efficient_MapReduce_Framework_for_Graphics_Processing_Units_2013_Basaran-1.pdf:/Users/njustn/Dropbox/Papers2/Articles/2013/Basaran/Grex_An_efficient_MapReduce_Framework_for_Graphics_Processing_Units_2013_Basaran-1.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1016/j.jpdc.2013.01.004}}
}

@inproceedings{Li:cf,
author = {Li, Min and Hsiao, Michael S},
title = {{FSimGP^2: An Efficient Fault Simulator with GPGPU}},
booktitle = {2010 19th Asian Test Symposium (ATS)},
pages = {15--20},
publisher = {IEEE},
doi = {10.1109/ATS.2010.12},
isbn = {978-1-4244-8841-4},
read = {Yes},
rating = {0},
date-added = {2011-04-24T01:05:00GMT},
date-modified = {2014-03-21T11:56:15GMT},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5692213},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/Unknown/Li/FSimGP%5E2_An_Efficient_Fault_Simulator_with_GPGPU__Li.pdf},
file = {{FSimGP^2_An_Efficient_Fault_Simulator_with_GPGPU__Li.pdf:/Users/njustn/Dropbox/Papers2/Articles/Unknown/Li/FSimGP^2_An_Efficient_Fault_Simulator_with_GPGPU__Li.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/ATS.2010.12}}
}

@article{Lamport:1978tr,
author = {Lamport, L},
title = {{Time, clocks, and the ordering of events in a distributed system}},
journal = {Communications of the ACM},
year = {1978},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:03:45GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events . A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events . The use of the ...},
url = {http://portal.acm.org/citation.cfm?id=359563},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1978/Lamport/Time_clocks_and_the_ordering_of_events_in_a_distributed_system_1978_Lamport.pdf},
file = {{Time_clocks_and_the_ordering_of_events_in_a_distributed_system_1978_Lamport.pdf:/Users/njustn/Dropbox/Papers2/Articles/1978/Lamport/Time_clocks_and_the_ordering_of_events_in_a_distributed_system_1978_Lamport.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/C4A1F21B-8A04-43B2-9E0E-31313D6C92E8}}
}

@article{Wirth:1995io,
author = {Wirth, N},
title = {{A plea for lean software}},
journal = {IEEE Computer},
year = {1995},
volume = {28},
number = {2},
pages = {64--68},
doi = {10.1109/2.348001},
read = {Yes},
rating = {0},
date-added = {2012-06-13T03:17:23GMT},
date-modified = {2014-07-05T20:47:53GMT},
abstract = {Software's girth has surpassed its functionality, largely because hardware advances make this possible. The way to streamline software lies in disciplined methodologies and a return to the essentials. The paper discusses some causes of ``fat software'' and considers the Oberon system whose primary goal was to show that software can be developed with a fraction of the memory capacity and processor power usually required, without sacrificing flexibility, functionality, or user convenience View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=348001&contentType=Journals+%26+Magazines&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28%22A+plea+for+lean+software%22%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1995/Wirth/A_plea_for_lean_software_1995_Wirth.pdf},
file = {{A_plea_for_lean_software_1995_Wirth.pdf:/Users/njustn/Dropbox/Papers2/Articles/1995/Wirth/A_plea_for_lean_software_1995_Wirth.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/2.348001}}
}

@article{Cederman:2012wz,
author = {Cederman, D and Chatterjee, B and Tsigas, P},
title = {{Understanding the Performance of Concurrent Data Structures on Graphics Processors}},
journal = {Euro-Par 2012 Parallel Processing},
year = {2012},
read = {Yes},
rating = {0},
date-added = {2013-02-10T02:00:51GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {In this paper we revisit the design of concurrent data structures --specifically queues--and examine their performance portability with regard to the move from conventional CPUs to graphics processors . We have looked at both lock-based and lock-free algorithms and ... 
},
url = {http://www.springerlink.com/index/1P7PGV73P15272R6.pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Cederman/Understanding_the_Performance_of_Concurrent_Data_Structures_on_Graphics_Processors_2012_Cederman.pdf},
file = {{Understanding_the_Performance_of_Concurrent_Data_Structures_on_Graphics_Processors_2012_Cederman.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Cederman/Understanding_the_Performance_of_Concurrent_Data_Structures_on_Graphics_Processors_2012_Cederman.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/EEBECDEE-B741-4132-BF9D-B2A887BE6E2F}}
}

@misc{Anonymous:2012tz,
title = {{MPI: A Message-Passing Interface Standard}},
author = {{Message Passing Interface Forum}},
howpublished = {http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf},
month = sep,
year = {2012},
publisher = {http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf},
rating = {0},
date-added = {2014-07-03T16:54:53GMT},
date-modified = {2014-07-05T21:24:21GMT},
url = {http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf},
uri = {\url{papers2://publication/uuid/5C805BDC-97F5-4D7D-B7A8-0D12D06CABB2}}
}

@inproceedings{Kruchten:2011dw,
author = {Kruchten, Philippe},
title = {{A plea for lean software process models}},
booktitle = {ICSSP '11: Proceedings of the 2011 International Conference on Software and Systems Process},
year = {2011},
publisher = {ACM},
month = may,
doi = {10.1145/1987875.1987919},
read = {Yes},
rating = {0},
date-added = {2012-06-13T03:17:37GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Over the last 30 years we have tried very hard the rich process models approach, and we have not been extremely successful at it. Maybe we should try "lean and mean" software process models, rather than making them "richer." At minimum, we should try},
url = {http://portal.acm.org/citation.cfm?id=1987875.1987919&coll=DL&dl=GUIDE&CFID=110443506&CFTOKEN=83308825},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Kruchten/A_plea_for_lean_software_process_models_2011_Kruchten.pdf},
file = {{A_plea_for_lean_software_process_models_2011_Kruchten.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Kruchten/A_plea_for_lean_software_process_models_2011_Kruchten.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1987875.1987919}}
}

@article{Perkel:2009hx,
author = {Perkel, J M},
title = {{Sanger Who? Sequencing the Next Generation}},
journal = {Science},
year = {2009},
volume = {10},
pages = {275--279},
month = jan,
doi = {10.1126/science.opms.p0800033},
read = {Yes},
rating = {0},
date-added = {2013-12-02T18:26:15GMT},
date-modified = {2014-03-21T11:56:20GMT},
url = {http://www.sciencemag.org/site/products/lst_20090410.xhtml},
uri = {\url{papers2://publication/doi/10.1126/science.opms.p0800033}}
}

@inproceedings{Becchi:2010jy,
author = {Becchi, Michela and Byna, Surendra and Cadambi, Srihari and Chakradhar, Srimat},
title = {{Data-aware scheduling of legacy kernels on heterogeneous platforms with distributed memory}},
booktitle = {ACM Symposium on Parallelism in Algorithms and Architectures},
year = {2010},
publisher = {ACM},
month = jun,
doi = {10.1145/1810479.1810498},
rating = {0},
date-added = {2012-03-18T18:43:35GMT},
date-modified = {2014-07-05T17:45:25GMT},
abstract = {In this paper, we describe a runtime to automatically enhance the performance of applications running on heterogeneous platforms consisting of a multi-core (CPU) and a throughput-oriented many-core (GPU). The CPU and GPU are connected by a non-coherent},
url = {http://portal.acm.org/citation.cfm?id=1810479.1810498&coll=DL&dl=GUIDE&CFID=90548637&CFTOKEN=74695659},
uri = {\url{papers2://publication/doi/10.1145/1810479.1810498}}
}

@inproceedings{Lee:2010bg,
author = {Lee, Seyong},
title = {{OpenMPC: Extended OpenMP Programming and Tuning for GPUs}},
crossref = {supercomputing},
year = {2010},
pages = {1--11},
publisher = { IEEE Computer Society},
doi = {10.1109/SC.2010.36},
read = {Yes},
rating = {0},
date-added = {2012-06-13T04:08:53GMT},
date-modified = {2014-07-05T20:58:04GMT},
abstract = {General-Purpose Graphics Processing Units (GPGPUs) are promising parallel platforms for high performance computing. The CUDA (Compute Unified Device Architecture) programming model provides improved programmability for general computing on GPGPUs. However, its unique execution model and memory model still pose significant challenges for developers of efficient GPGPU code. This paper proposes a new programming interface, called OpenMPC, which builds on OpenMP to provide an abstraction of the complex CUDA programming model and offers high-level controls of the involved parameters and optimizations. We have developed a fully automatic compilation and user-assisted tuning system supporting OpenMPC. In addition to a range of compiler transformations and optimizations, the system includes tuning capabilities for generating, pruning, and navigating the search space of compilation variants. Our results demonstrate that OpenMPC offers both programmability and tunability. Our system achieves 88\% of the performance of the hand-coded CUDA programs. View full abstract},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5644879&contentType=Conference+Publications&matchBoolean%3Dtrue%26rowsPerPage%3D30%26searchField%3DSearch_All%26queryText%3D%28openmpc%29},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Lee/OpenMPC_Extended_OpenMP_Programming_and_Tuning_for_GPUs_2010_Lee.pdf},
file = {{OpenMPC_Extended_OpenMP_Programming_and_Tuning_for_GPUs_2010_Lee.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Lee/OpenMPC_Extended_OpenMP_Programming_and_Tuning_for_GPUs_2010_Lee.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1109/SC.2010.36}}
}

@article{Anonymous:bGrIrSYX,
title = {{Synchronization on GPUs: Performance Curse or Blessing?}},
year = {2012},
pages = {1--15},
month = jan,
read = {Yes},
rating = {0},
date-added = {2012-03-23T15:52:39GMT},
date-modified = {2014-03-21T11:56:16GMT},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Synchronization_on_GPUs_Performance_Curse_or_Blessing_2012.pdf},
file = {{Synchronization_on_GPUs_Performance_Curse_or_Blessing_2012.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Unknown/Synchronization_on_GPUs_Performance_Curse_or_Blessing_2012.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/6C6AC8AD-2617-41AF-B2FF-42C0CEF39756}}
}

@inproceedings{Jablin:2011ct,
author = {Jablin, Thomas B and Prabhu, Prakash and Jablin, James A and Johnson, Nick P and Beard, Stephen R and August, David I},
title = {{Automatic CPU-GPU communication management and optimization}},
booktitle = {Conference on Programming Language Design and Implementation},
year = {2011},
publisher = {ACM},
month = jun,
doi = {10.1145/1993498.1993516},
read = {Yes},
rating = {0},
date-added = {2012-03-25T18:17:51GMT},
date-modified = {2014-07-06T22:01:24GMT},
abstract = {The performance benefits of GPU parallelism can be enormous, but unlocking this performance potential is challenging. The applicability and performance of GPU parallelizations is limited by the complexities of CPU-GPU communication. To address these},
url = {http://portal.acm.org/citation.cfm?id=1993498.1993516&coll=DL&dl=GUIDE&CFID=73918170&CFTOKEN=16683680},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2011/Jablin/Automatic_CPU-GPU_communication_management_and_optimization_2011_Jablin.pdf},
file = {{Automatic_CPU-GPU_communication_management_and_optimization_2011_Jablin.pdf:/Users/njustn/Dropbox/Papers2/Articles/2011/Jablin/Automatic_CPU-GPU_communication_management_and_optimization_2011_Jablin.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1993498.1993516}}
}

@article{Page:1999wg,
author = {Page, L and Brin, S and Motwani, R},
title = {{The PageRank Citation Ranking: Bringing Order to the Web.}},
year = {1999},
read = {Yes},
rating = {0},
date-added = {2011-04-01T13:19:00GMT},
date-modified = {2014-03-21T11:56:19GMT},
abstract = {Abstract The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank , a method ...},
url = {http://ilpubs.stanford.edu:8090/422},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1999/Page/The_PageRank_Citation_Ranking_Bringing_Order_to_the_Web._1999_Page.pdf},
file = {{The_PageRank_Citation_Ranking_Bringing_Order_to_the_Web._1999_Page.pdf:/Users/njustn/Dropbox/Papers2/Articles/1999/Page/The_PageRank_Citation_Ranking_Bringing_Order_to_the_Web._1999_Page.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/F8F11817-D85E-483D-8C4C-4C8EA98E0AE5}}
}

@inproceedings{Luk:2009gf,
author = {Luk, Chi-Keung and Hong, Sunpyo and Kim, Hyesoon},
title = {{Qilin: Exploiting Parallelism on Heterogeneous Multiprocessors with Adaptive Mapping}},
booktitle = {MICRO 42: Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture},
year = {2009},
publisher = {ACM},
month = dec,
keywords = {ipdps11-omp-co},
doi = {10.1145/1669112.1669121},
read = {Yes},
rating = {0},
date-added = {2011-04-02T13:46:23GMT},
date-modified = {2014-07-05T20:58:33GMT},
abstract = {Heterogeneous multiprocessors are increasingly important in the multi-core era due to their potential for high performance and energy efficiency. In order for software to fully realize this potential, the step that maps computations to processing elements},
url = {http://portal.acm.org/citation.cfm?id=1669121},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2009/Luk/Qilin_Exploiting_Parallelism_on_Heterogeneous_Multiprocessors_with_Adaptive_Mapping_2009_Luk-2.pdf},
file = {{Qilin_Exploiting_Parallelism_on_Heterogeneous_Multiprocessors_with_Adaptive_Mapping_2009_Luk-2.pdf:/Users/njustn/Dropbox/Papers2/Articles/2009/Luk/Qilin_Exploiting_Parallelism_on_Heterogeneous_Multiprocessors_with_Adaptive_Mapping_2009_Luk-2.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1669112.1669121}}
}

@inproceedings{Katz:2008wm,
author = {Katz, GJ},
title = {{All-pairs shortest-paths for large graphs on the GPU}},
booktitle = {Proceedings of the 23rd ACM SIGGRAPH/ {\ldots}},
year = {2008},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:22:21GMT},
date-modified = {2014-03-21T11:56:20GMT},
abstract = {Abstract The all - pairs shortest -path problem is an intricate part in numerous practical applications. We describe a shared memory cache efficient GPU implementation to solve transitive closure and the all - pairs shortest -path problem on directed graphs for large datasets. The ...},
url = {http://portal.acm.org/citation.cfm?id=1413966},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Katz/All-pairs_shortest-paths_for_large_graphs_on_the_GPU_2008_Katz.pdf},
file = {{All-pairs_shortest-paths_for_large_graphs_on_the_GPU_2008_Katz.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Katz/All-pairs_shortest-paths_for_large_graphs_on_the_GPU_2008_Katz.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/FEE38D8D-F9C3-469B-82E3-6BA566D4A2D1}}
}

@inproceedings{Lauderdale:2012jb,
author = {Lauderdale, Christopher and Khan, Rishi},
title = {{Towards a codelet-based runtime for exascale computing: position paper}},
booktitle = {EXADAPT '12: Proceedings of the 2nd International Workshop on Adaptive Self-Tuning Computing Systems for the Exaflop Era},
year = {2012},
publisher = {ACM},
month = mar,
doi = {10.1145/2185475.2185478},
read = {Yes},
rating = {0},
date-added = {2012-07-08T19:01:19GMT},
date-modified = {2014-03-21T11:56:18GMT},
abstract = {Computing systems have reached the performance limits attainable by increasing clock rates and complexity, and are now using increased thread-level parallelism and heterogeneity instead. Existing software typically deals poorly with large-scale or heterogeneous},
url = {http://portal.acm.org/citation.cfm?id=2185475.2185478&coll=DL&dl=GUIDE&CFID=94493267&CFTOKEN=32790641},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2012/Lauderdale/Towards_a_codelet-based_runtime_for_exascale_computing_position_paper_2012_Lauderdale.pdf},
file = {{Towards_a_codelet-based_runtime_for_exascale_computing_position_paper_2012_Lauderdale.pdf:/Users/njustn/Dropbox/Papers2/Articles/2012/Lauderdale/Towards_a_codelet-based_runtime_for_exascale_computing_position_paper_2012_Lauderdale.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/2185475.2185478}}
}

@inproceedings{Ravi:2010hw,
author = {Ravi, Vignesh T and Ma, Wenjing and Chiu, David and Agrawal, Gagan},
title = {{Compiler and runtime support for enabling generalized reduction computations on heterogeneous parallel configurations}},
booktitle = {ACM International Conference on Supercomputing},
year = {2010},
publisher = {ACM},
month = jun,
doi = {10.1145/1810085.1810106},
read = {Yes},
rating = {0},
date-added = {2012-07-09T01:53:23GMT},
date-modified = {2014-07-05T17:44:21GMT},
abstract = {A trend that has materialized, and has given rise to much attention, is of the increasingly heterogeneous computing platforms. Presently, it has become very common for a desktop or a notebook computer to come equipped with both a multi-core CPU and a},
url = {http://dl.acm.org/ft_gateway.cfm?id=1810106&type=pdf},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2010/Ravi/Compiler_and_runtime_support_for_enabling_generalized_reduction_computations_on_heterogeneous_parallel_configurations_2010_Ravi.pdf},
file = {{Compiler_and_runtime_support_for_enabling_generalized_reduction_computations_on_heterogeneous_parallel_configurations_2010_Ravi.pdf:/Users/njustn/Dropbox/Papers2/Articles/2010/Ravi/Compiler_and_runtime_support_for_enabling_generalized_reduction_computations_on_heterogeneous_parallel_configurations_2010_Ravi.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/1810085.1810106}}
}

@article{Evequoz:2008vl,
author = {Evequoz, Claude},
title = {{Non-blocking concurrent fifo queues with single word synchronization primitives}},
year = {2008},
pages = {397--405},
publisher = {IEEE},
isbn = {0769533744},
read = {Yes},
rating = {0},
date-added = {2013-07-21T15:21:52GMT},
date-modified = {2014-03-21T11:56:18GMT},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4625874},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/2008/Evequoz/Non-blocking_concurrent_fifo_queues_with_single_word_synchronization_primitives_2008_Evequoz.pdf},
file = {{Non-blocking_concurrent_fifo_queues_with_single_word_synchronization_primitives_2008_Evequoz.pdf:/Users/njustn/Dropbox/Papers2/Articles/2008/Evequoz/Non-blocking_concurrent_fifo_queues_with_single_word_synchronization_primitives_2008_Evequoz.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/5CCC6D7C-0739-436D-8AFE-B2E8471F09CB}}
}

@inproceedings{ms-queue,
author = {Michael, Maged M and Scott, Michael L},
title = {{Simple, fast, and practical non-blocking and blocking concurrent queue algorithms}},
booktitle = {ACM Symposium on Principles of Distributed Computing},
year = {1996},
publisher = {ACM},
month = may,
doi = {10.1145/248052.248106},
read = {Yes},
rating = {0},
date-added = {2013-02-10T17:59:28GMT},
date-modified = {2014-07-05T17:39:37GMT},
abstract = {Keywords},
url = {http://portal.acm.org/citation.cfm?id=248052.248106&coll=DL&dl=ACM&CFID=235641177&CFTOKEN=70799411},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1996/Michael/Simple_fast_and_practical_non-blocking_and_blocking_concurrent_queue_algorithms_1996_Michael.pdf},
file = {{Simple_fast_and_practical_non-blocking_and_blocking_concurrent_queue_algorithms_1996_Michael.pdf:/Users/njustn/Dropbox/Papers2/Articles/1996/Michael/Simple_fast_and_practical_non-blocking_and_blocking_concurrent_queue_algorithms_1996_Michael.pdf:application/pdf}},
uri = {\url{papers2://publication/doi/10.1145/248052.248106}}
}

@misc{opencl,
title = {{The OpenCL Specification}},
month = nov,
year = {2012},
publisher = {Khronos OpenCL Working Group},
howpublished = {\url{https://www.khronos.org/registry/cl/specs/opencl-1.2.pdf}},
rating = {0},
date-added = {2014-07-03T17:13:00GMT},
date-modified = {2014-07-04T05:14:51GMT},
uri = {\url{papers2://publication/uuid/68B177D3-6D7B-4C3A-B9EA-AB2FDC248313}}
}

@article{Savage:1997tv,
author = {Savage, S and Burrows, M and Nelson, G},
title = {{Eraser: A dynamic data race detector for multithreaded programs}},
journal = {ACM Transactions on {\ldots}},
year = {1997},
read = {Yes},
rating = {0},
date-added = {2011-04-09T02:04:25GMT},
date-modified = {2014-03-21T11:56:16GMT},
abstract = {1. INTRODUCTION Multithreading has become a common programming technique. Most com- mercial operating systems support threads, and popular applications like Microsoft Word and Netscape Navigator are multithreaded . ... An earlier version of this article appeared ...},
url = {http://portal.acm.org/citation.cfm?id=265927},
local-url = {file://localhost/Users/njustn/Dropbox/Papers2/Articles/1997/Savage/Eraser_A_dynamic_data_race_detector_for_multithreaded_programs_1997_Savage.pdf},
file = {{Eraser_A_dynamic_data_race_detector_for_multithreaded_programs_1997_Savage.pdf:/Users/njustn/Dropbox/Papers2/Articles/1997/Savage/Eraser_A_dynamic_data_race_detector_for_multithreaded_programs_1997_Savage.pdf:application/pdf}},
uri = {\url{papers2://publication/uuid/57ACEF88-C121-4FC8-B7F5-D8E65DBEB74D}}
}


%%proceedings

@proceedings{ipdps,
  title = {International Parallel and Distributed Processing Symposium},
  booktitle = {International Parallel and Distributed Processing Symposium},
}

@proceedings{ipdpsw,
  title = {International Parallel {\&} Distributed Processing Symposium, Workshops and Phd Forum (IPDPSW)},
  booktitle = {International Parallel {\&} Distributed Processing Symposium, Workshops and Phd Forum (IPDPSW)}
}

@proceedings{supercomputing,
  title = {International Conference for High Performance Computing, Networking, Storage and Analysis (SuperComputing)},
  booktitle = {International Conference for High Performance Computing, Networking, Storage and Analysis (SuperComputing)}
}

@proceedings{hppac,
  title = {Workshop on High-Performance, Power-Aware Computing (IPDPSW: HPPAC)},
  booktitle = {Workshop on High-Performance, Power-Aware Computing (IPDPSW: HPPAC)},
}
